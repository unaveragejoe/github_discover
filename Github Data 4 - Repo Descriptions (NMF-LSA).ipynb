{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:48:31.989412Z",
     "start_time": "2019-03-27T01:48:30.926126Z"
    }
   },
   "outputs": [],
   "source": [
    "from github import Github\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pickle\n",
    "import pprint\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "import os\n",
    "import requests\n",
    "import time as time\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "import urllib\n",
    "import math\n",
    "\n",
    "ua = UserAgent()\n",
    "\n",
    "g = Github(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:48:42.579247Z",
     "start_time": "2019-03-27T01:48:42.572320Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:48:43.835459Z",
     "start_time": "2019-03-27T01:48:43.820436Z"
    }
   },
   "outputs": [],
   "source": [
    "repo_desc_df = pd.read_pickle('repo_descriptions_df.pkl')\n",
    "repo_desc_df.columns = ['id', 'description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:48:44.560483Z",
     "start_time": "2019-03-27T01:48:44.542005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>843222</td>\n",
       "      <td>scikit-learn: machine learning in Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33462633</td>\n",
       "      <td>Jupyter notebooks from the scikit-learn video ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25257051</td>\n",
       "      <td>PySpark + Scikit-learn = Sparkit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104967369</td>\n",
       "      <td>:book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38441254</td>\n",
       "      <td>Automated Machine Learning with scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>54307265</td>\n",
       "      <td>Scikit-learn tutorial at SciPy2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42127722</td>\n",
       "      <td>Materials for my scikit-learn tutorial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60101534</td>\n",
       "      <td>scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15534429</td>\n",
       "      <td>Source code for the \"Learning scikit-learn: Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31682513</td>\n",
       "      <td>Scikit-Learn tutorial material for Scipy 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                        description\n",
       "0     843222           scikit-learn: machine learning in Python\n",
       "1   33462633  Jupyter notebooks from the scikit-learn video ...\n",
       "2   25257051             PySpark + Scikit-learn = Sparkit-learn\n",
       "3  104967369              :book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£\n",
       "4   38441254       Automated Machine Learning with scikit-learn\n",
       "5   54307265                 Scikit-learn tutorial at SciPy2016\n",
       "6   42127722             Materials for my scikit-learn tutorial\n",
       "7   60101534                          scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ\n",
       "8   15534429  Source code for the \"Learning scikit-learn: Ma...\n",
       "9   31682513      Scikit-Learn tutorial material for Scipy 2015"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_desc_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:48:45.634641Z",
     "start_time": "2019-03-27T01:48:45.628926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7014"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repo_desc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:48:46.886857Z",
     "start_time": "2019-03-27T01:48:46.876217Z"
    }
   },
   "outputs": [],
   "source": [
    "repo_desc_df['description'] = repo_desc_df['description'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:48:47.670937Z",
     "start_time": "2019-03-27T01:48:47.665960Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = repo_desc_df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:48:48.691432Z",
     "start_time": "2019-03-27T01:48:48.688127Z"
    }
   },
   "outputs": [],
   "source": [
    "# Try tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:06:55.767914Z",
     "start_time": "2019-03-27T02:06:55.758091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7014, 7385)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', lowercase=True)\n",
    "doc_word = vectorizer.fit_transform(sample)\n",
    "doc_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:06:56.087768Z",
     "start_time": "2019-03-27T02:06:56.080619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x7385 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:06:56.209749Z",
     "start_time": "2019-03-27T02:06:56.185565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00440</th>\n",
       "      <th>01783v1</th>\n",
       "      <th>02456</th>\n",
       "      <th>02755</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>0636920034391</th>\n",
       "      <th>08835</th>\n",
       "      <th>...</th>\n",
       "      <th>ÏûêÎ£å</th>\n",
       "      <th>ÏûêÎ£åÎì§ÏùÑ</th>\n",
       "      <th>ÏûêÎ£åÎ™®Ïùå</th>\n",
       "      <th>ÏûêÏó∞Ïñ¥Ï≤òÎ¶¨</th>\n",
       "      <th>ÌÖêÏÑúÌîåÎ°úÎ°ú</th>\n",
       "      <th>ÌååÏù¥Ïç¨python</th>\n",
       "      <th>ÌååÏù¥Ïç¨ÏùÑ</th>\n",
       "      <th>Ìå®Ïä§Ìä∏Ï∫†ÌçºÏä§</th>\n",
       "      <th>ÌïúÎààÏóê</th>\n",
       "      <th>ùì∑ùì≠ùìªùìÆùîÄ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scikit-learn: machine learning in Python</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jupyter notebooks from the scikit-learn video series</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PySpark + Scikit-learn = Sparkit-learn</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Automated Machine Learning with scikit-learn</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scikit-learn tutorial at SciPy2016</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Materials for my scikit-learn tutorial</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source code for the \"Learning scikit-learn: Machine Learning in Python\"</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scikit-Learn tutorial material for Scipy 2015</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 7385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    00440  01783v1  02456  \\\n",
       "description                                                                 \n",
       "scikit-learn: machine learning in Python                0        0      0   \n",
       "Jupyter notebooks from the scikit-learn video s...      0        0      0   \n",
       "PySpark + Scikit-learn = Sparkit-learn                  0        0      0   \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                   0        0      0   \n",
       "Automated Machine Learning with scikit-learn            0        0      0   \n",
       "Scikit-learn tutorial at SciPy2016                      0        0      0   \n",
       "Materials for my scikit-learn tutorial                  0        0      0   \n",
       "scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ                               0        0      0   \n",
       "Source code for the \"Learning scikit-learn: Mac...      0        0      0   \n",
       "Scikit-Learn tutorial material for Scipy 2015           0        0      0   \n",
       "\n",
       "                                                    02755  03  04  05  06  \\\n",
       "description                                                                 \n",
       "scikit-learn: machine learning in Python                0   0   0   0   0   \n",
       "Jupyter notebooks from the scikit-learn video s...      0   0   0   0   0   \n",
       "PySpark + Scikit-learn = Sparkit-learn                  0   0   0   0   0   \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                   0   0   0   0   0   \n",
       "Automated Machine Learning with scikit-learn            0   0   0   0   0   \n",
       "Scikit-learn tutorial at SciPy2016                      0   0   0   0   0   \n",
       "Materials for my scikit-learn tutorial                  0   0   0   0   0   \n",
       "scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ                               0   0   0   0   0   \n",
       "Source code for the \"Learning scikit-learn: Mac...      0   0   0   0   0   \n",
       "Scikit-Learn tutorial material for Scipy 2015           0   0   0   0   0   \n",
       "\n",
       "                                                    0636920034391  08835  \\\n",
       "description                                                                \n",
       "scikit-learn: machine learning in Python                        0      0   \n",
       "Jupyter notebooks from the scikit-learn video s...              0      0   \n",
       "PySpark + Scikit-learn = Sparkit-learn                          0      0   \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                           0      0   \n",
       "Automated Machine Learning with scikit-learn                    0      0   \n",
       "Scikit-learn tutorial at SciPy2016                              0      0   \n",
       "Materials for my scikit-learn tutorial                          0      0   \n",
       "scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ                                       0      0   \n",
       "Source code for the \"Learning scikit-learn: Mac...              0      0   \n",
       "Scikit-Learn tutorial material for Scipy 2015                   0      0   \n",
       "\n",
       "                                                    ...    ÏûêÎ£å  ÏûêÎ£åÎì§ÏùÑ  ÏûêÎ£åÎ™®Ïùå  \\\n",
       "description                                         ...                     \n",
       "scikit-learn: machine learning in Python            ...     0     0     0   \n",
       "Jupyter notebooks from the scikit-learn video s...  ...     0     0     0   \n",
       "PySpark + Scikit-learn = Sparkit-learn              ...     0     0     0   \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£               ...     0     0     0   \n",
       "Automated Machine Learning with scikit-learn        ...     0     0     0   \n",
       "Scikit-learn tutorial at SciPy2016                  ...     0     0     0   \n",
       "Materials for my scikit-learn tutorial              ...     0     0     0   \n",
       "scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ                           ...     0     0     0   \n",
       "Source code for the \"Learning scikit-learn: Mac...  ...     0     0     0   \n",
       "Scikit-Learn tutorial material for Scipy 2015       ...     0     0     0   \n",
       "\n",
       "                                                    ÏûêÏó∞Ïñ¥Ï≤òÎ¶¨  ÌÖêÏÑúÌîåÎ°úÎ°ú  ÌååÏù¥Ïç¨python  \\\n",
       "description                                                                   \n",
       "scikit-learn: machine learning in Python                0      0          0   \n",
       "Jupyter notebooks from the scikit-learn video s...      0      0          0   \n",
       "PySpark + Scikit-learn = Sparkit-learn                  0      0          0   \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                   0      0          0   \n",
       "Automated Machine Learning with scikit-learn            0      0          0   \n",
       "Scikit-learn tutorial at SciPy2016                      0      0          0   \n",
       "Materials for my scikit-learn tutorial                  0      0          0   \n",
       "scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ                               0      0          0   \n",
       "Source code for the \"Learning scikit-learn: Mac...      0      0          0   \n",
       "Scikit-Learn tutorial material for Scipy 2015           0      0          0   \n",
       "\n",
       "                                                    ÌååÏù¥Ïç¨ÏùÑ  Ìå®Ïä§Ìä∏Ï∫†ÌçºÏä§  ÌïúÎààÏóê  ùì∑ùì≠ùìªùìÆùîÄ  \n",
       "description                                                                   \n",
       "scikit-learn: machine learning in Python               0       0    0      0  \n",
       "Jupyter notebooks from the scikit-learn video s...     0       0    0      0  \n",
       "PySpark + Scikit-learn = Sparkit-learn                 0       0    0      0  \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                  0       0    0      0  \n",
       "Automated Machine Learning with scikit-learn           0       0    0      0  \n",
       "Scikit-learn tutorial at SciPy2016                     0       0    0      0  \n",
       "Materials for my scikit-learn tutorial                 0       0    0      0  \n",
       "scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ                              0       0    0      0  \n",
       "Source code for the \"Learning scikit-learn: Mac...     0       0    0      0  \n",
       "Scikit-Learn tutorial material for Scipy 2015          0       0    0      0  \n",
       "\n",
       "[10 rows x 7385 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have to convert `.toarray()` because the vectorizer returns a sparse matrix.\n",
    "# For a big corpus, we would skip the dataframe and keep the output sparse.\n",
    "pd.DataFrame(doc_word.toarray(), index=sample, columns=vectorizer.get_feature_names()).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:06:57.045491Z",
     "start_time": "2019-03-27T02:06:56.552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24072609075921425"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  SVD\n",
    "lsa = TruncatedSVD(8)\n",
    "doc_topic = lsa.fit_transform(doc_word)\n",
    "lsa.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:06:57.053616Z",
     "start_time": "2019-03-27T02:06:56.856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.32678427e-04,  2.18445298e-04,  5.04917437e-04, ...,\n",
       "         1.20774703e-09,  9.09224978e-09,  2.56239374e-04],\n",
       "       [-2.33397435e-04,  3.65169781e-05, -4.02721700e-04, ...,\n",
       "         4.94548013e-09,  2.26115553e-07, -1.31036372e-04],\n",
       "       [-8.43232779e-05,  7.31373394e-07, -2.10113456e-04, ...,\n",
       "        -7.53941790e-09, -9.13148807e-08,  3.00289468e-05],\n",
       "       ...,\n",
       "       [-8.63836898e-05,  8.30359657e-05, -1.67463033e-04, ...,\n",
       "         1.56839726e-09, -5.32033116e-08,  4.32773016e-05],\n",
       "       [-3.56223417e-05,  3.31428743e-04,  2.03025683e-05, ...,\n",
       "         1.32122879e-08, -7.13338700e-08,  2.96093519e-06],\n",
       "       [-2.41922947e-04,  3.38173494e-03,  9.36227903e-04, ...,\n",
       "        -6.38902306e-08, -4.95994757e-07, -9.63388182e-05]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:06:57.921292Z",
     "start_time": "2019-03-27T02:06:57.312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00440</th>\n",
       "      <th>01783v1</th>\n",
       "      <th>02456</th>\n",
       "      <th>02755</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>0636920034391</th>\n",
       "      <th>08835</th>\n",
       "      <th>...</th>\n",
       "      <th>ÏûêÎ£å</th>\n",
       "      <th>ÏûêÎ£åÎì§ÏùÑ</th>\n",
       "      <th>ÏûêÎ£åÎ™®Ïùå</th>\n",
       "      <th>ÏûêÏó∞Ïñ¥Ï≤òÎ¶¨</th>\n",
       "      <th>ÌÖêÏÑúÌîåÎ°úÎ°ú</th>\n",
       "      <th>ÌååÏù¥Ïç¨python</th>\n",
       "      <th>ÌååÏù¥Ïç¨ÏùÑ</th>\n",
       "      <th>Ìå®Ïä§Ìä∏Ï∫†ÌçºÏä§</th>\n",
       "      <th>ÌïúÎààÏóê</th>\n",
       "      <th>ùì∑ùì≠ùìªùìÆùîÄ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>component_1</th>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_2</th>\n",
       "      <td>-0.000233</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_3</th>\n",
       "      <td>-0.000084</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000210</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>-0.000710</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_4</th>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000095</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>-0.000344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_5</th>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_6</th>\n",
       "      <td>-0.000086</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_7</th>\n",
       "      <td>-0.000036</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_8</th>\n",
       "      <td>-0.000242</td>\n",
       "      <td>0.003382</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000328</td>\n",
       "      <td>-0.000420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows √ó 7385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                00440   01783v1     02456     02755        03        04  \\\n",
       "component_1  0.000233  0.000218  0.000505  0.000005  0.000008  0.000251   \n",
       "component_2 -0.000233  0.000037 -0.000403  0.000014  0.000013 -0.000219   \n",
       "component_3 -0.000084  0.000001 -0.000210  0.000003 -0.000006 -0.000088   \n",
       "component_4 -0.000071 -0.000143 -0.000240 -0.000003  0.000010 -0.000095   \n",
       "component_5  0.000639  0.000239  0.001337  0.000019  0.000040  0.000752   \n",
       "component_6 -0.000086  0.000083 -0.000167  0.000025  0.000008 -0.000093   \n",
       "component_7 -0.000036  0.000331  0.000020  0.000031 -0.000002 -0.000028   \n",
       "component_8 -0.000242  0.003382  0.000936  0.000003 -0.000017 -0.000054   \n",
       "\n",
       "                   05        06  0636920034391     08835    ...      ÏûêÎ£å  \\\n",
       "component_1  0.000099  0.000004       0.000062  0.000059    ...     0.0   \n",
       "component_2  0.000714  0.000012       0.000365  0.000428    ...     0.0   \n",
       "component_3 -0.000710 -0.000004      -0.000191  0.000635    ...    -0.0   \n",
       "component_4 -0.000130  0.000007       0.000618 -0.000344    ...     0.0   \n",
       "component_5  0.000092  0.000011       0.000122  0.000233    ...    -0.0   \n",
       "component_6 -0.000064 -0.000003      -0.000070 -0.000001    ...     0.0   \n",
       "component_7  0.000061  0.000008       0.000010 -0.000029    ...     0.0   \n",
       "component_8  0.001724 -0.000052      -0.000328 -0.000420    ...    -0.0   \n",
       "\n",
       "                 ÏûêÎ£åÎì§ÏùÑ      ÏûêÎ£åÎ™®Ïùå     ÏûêÏó∞Ïñ¥Ï≤òÎ¶¨     ÌÖêÏÑúÌîåÎ°úÎ°ú  ÌååÏù¥Ïç¨python      ÌååÏù¥Ïç¨ÏùÑ  \\\n",
       "component_1  0.000006  0.000000  0.000000  0.000001   0.000006  0.000000   \n",
       "component_2  0.000010  0.000000  0.000000  0.000002   0.000010  0.000000   \n",
       "component_3 -0.000012 -0.000000 -0.000000 -0.000002  -0.000012 -0.000000   \n",
       "component_4  0.000010 -0.000001 -0.000001 -0.000004   0.000010 -0.000001   \n",
       "component_5 -0.000004  0.000000  0.000000 -0.000000  -0.000004  0.000000   \n",
       "component_6  0.000003 -0.000000 -0.000000 -0.000001   0.000003 -0.000000   \n",
       "component_7  0.000010 -0.000000 -0.000000 -0.000001   0.000010 -0.000000   \n",
       "component_8 -0.000026 -0.000000 -0.000000 -0.000014  -0.000026 -0.000000   \n",
       "\n",
       "             Ìå®Ïä§Ìä∏Ï∫†ÌçºÏä§       ÌïúÎààÏóê     ùì∑ùì≠ùìªùìÆùîÄ  \n",
       "component_1     0.0  0.000000  0.000256  \n",
       "component_2     0.0  0.000000 -0.000131  \n",
       "component_3    -0.0 -0.000000  0.000030  \n",
       "component_4     0.0 -0.000001  0.000045  \n",
       "component_5    -0.0  0.000000 -0.000621  \n",
       "component_6     0.0 -0.000000  0.000043  \n",
       "component_7     0.0 -0.000000  0.000003  \n",
       "component_8    -0.0 -0.000000 -0.000096  \n",
       "\n",
       "[8 rows x 7385 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = pd.DataFrame(lsa.components_.round(6),\n",
    "             index = [\"component_1\",\"component_2\",\"component_3\",\"component_4\",\"component_5\",\"component_6\", \"component_7\", \"component_8\"],\n",
    "             columns = vectorizer.get_feature_names())\n",
    "topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:06:59.284163Z",
     "start_time": "2019-03-27T02:06:59.278903Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:07:05.114509Z",
     "start_time": "2019-03-27T02:07:05.089051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "learning, machine, deep, python, learn, scikit, using, code, jupyter, tensorflow\n",
      "\n",
      "Topic  1\n",
      "python, learn, scikit, jupyter, notebooks, notebook, using, data, code, library\n",
      "\n",
      "Topic  2\n",
      "learn, scikit, machine, using, compatible, models, tutorial, pandas, regression, classification\n",
      "\n",
      "Topic  3\n",
      "python, library, machine, julia, api, code, client, mysql, package, published\n",
      "\n",
      "Topic  4\n",
      "deep, python, learn, scikit, julia, using, tensorflow, reinforcement, keras, neural\n",
      "\n",
      "Topic  5\n",
      "julia, package, library, language, interface, machine, kubernetes, data, programming, wrapper\n",
      "\n",
      "Topic  6\n",
      "kubernetes, cluster, using, docker, clusters, deploy, service, running, application, cloud\n",
      "\n",
      "Topic  7\n",
      "using, data, model, tensorflow, analysis, science, neural, project, network, classification\n"
     ]
    }
   ],
   "source": [
    "display_topics(lsa, vectorizer.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:48:55.560783Z",
     "start_time": "2019-03-27T01:48:55.520323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_2</th>\n",
       "      <th>component_3</th>\n",
       "      <th>component_4</th>\n",
       "      <th>component_5</th>\n",
       "      <th>component_6</th>\n",
       "      <th>component_7</th>\n",
       "      <th>component_8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scikit-learn: machine learning in Python</th>\n",
       "      <td>1.62</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jupyter notebooks from the scikit-learn video series</th>\n",
       "      <td>0.38</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-1.23</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PySpark + Scikit-learn = Sparkit-learn</th>\n",
       "      <td>0.38</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.50</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Automated Machine Learning with scikit-learn</th>\n",
       "      <td>1.45</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.06</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scikit-learn tutorial at SciPy2016</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.01</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Materials for my scikit-learn tutorial</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.02</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source code for the \"Learning scikit-learn: Machine Learning in Python\"</th>\n",
       "      <td>2.48</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scikit-Learn tutorial material for Scipy 2015</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.02</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Simplified interface for TensorFlow (mimicking Scikit Learn) for Deep Learning</th>\n",
       "      <td>1.41</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.87</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tutorial on scikit-learn and IPython for parallel machine learning</th>\n",
       "      <td>1.48</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.04</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scikit-learn integration package for Apache Spark</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Machine Learning with Text in scikit-learn</th>\n",
       "      <td>1.46</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.06</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hidden Markov Models in Python, with scikit-learn like API</th>\n",
       "      <td>0.47</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Materials for my Pycon 2015 scikit-learn tutorial.</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.02</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Some sample IPython notebooks for scikit-learn</th>\n",
       "      <td>0.32</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dive into Machine Learning with Python Jupyter notebook and scikit-learn!</th>\n",
       "      <td>1.71</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scikit-Learn, NLTK, Spacy, Gensim, Textblob and more</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.01</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Julia implementation of the scikit-learn API</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.97</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A scikit-learn compatible neural network library that wraps pytorch</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.01</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scikit-learn compatible tools using theano</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.04</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scikit-learn tutorials for the Scipy 2013 conference</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scikit-learn compatible projects</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.01</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scikit-Learn tutorials</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scikit-learn inspired API for CRFsuite</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Repository containing files for my PyCon 2014 scikit-learn tutorial.</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Applied Machine Learning in Python with scikit-learn</th>\n",
       "      <td>1.63</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scikit-Learn Tutorial for PyData Seattle 2015</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.02</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scikit-learn style model finetuning for NLP</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Curated list of Linguistic Resources for doing NLP &amp; CL on Spanish</th>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>List of projects related to Natural Language Processing (NLP) that make a geek smile for they exist</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP course at Chulalongkorn University</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Some frequently used NLP blocks I implemented</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP Sandbox</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vietnamese NLP Toolkit for Node</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toy Python implementation of http://www-nlp.stanford.edu/projects/glove/</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tensorflowÂÆûÊàòÁªÉ‰π†ÔºåÂåÖÊã¨Âº∫ÂåñÂ≠¶‰π†„ÄÅÊé®ËçêÁ≥ªÁªü„ÄÅnlpÁ≠â</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Learning Chinese Word Segment</th>\n",
       "      <td>1.10</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLPCC 2016 ÂæÆÂçöÂàÜËØçËØÑÊµãÈ°πÁõÆ</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Âêå‰πâËØçË°®ÔºåÂèç‰πâËØçË°®ÔºåÂê¶ÂÆöËØçË°®</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Áà¨Ëô´‰∏éÊú∫Âô®Â≠¶‰π†</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP Education Tools by YuZhen(www.yuzhenkeji.com)</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP reading group at the University of Arizona</th>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in progress</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lectures for Udemy - INLP</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A NLP library for Russian language</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Study E-Book(ComputerVision DeepLearning MachineLearning Math NLP Python ReinforcementLearning)</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python implementation of TextRank for text document NLP parsing and summarization</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üí´  Models for the spaCy Natural Language Processing (NLP) library</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"End-To-End Memory Networks\" in Tensorflow</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deprecated in favor of https://github.com/facebook/duckling</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A very brief introduction to Natural Language Processing programming in Python</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time-NLPÁöÑpython3ÁâàÊú¨ ‰∏≠ÊñáÊó∂Èó¥Ë°®ËææËØçËΩ¨Êç¢</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A companion repository for the \"Writing code for NLP Research\" Tutorial at EMNLP 2018</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bi-directional Attention Flow (BiDAF) network is a multi-stage hierarchical process that represents context at different levels of granularity and uses a bi-directional attention flow mechanism to achieve a query-aware context representation without early summarization.</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tensorflow Tutorial files and Implementations of various Deep NLP and CV Models.</th>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7014 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    component_1  component_2  \\\n",
       "description                                                                    \n",
       "scikit-learn: machine learning in Python                   1.62         1.09   \n",
       "Jupyter notebooks from the scikit-learn video s...         0.38         1.35   \n",
       "PySpark + Scikit-learn = Sparkit-learn                     0.38         1.18   \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                      0.27         0.80   \n",
       "Automated Machine Learning with scikit-learn               1.45         0.51   \n",
       "Scikit-learn tutorial at SciPy2016                         0.27         0.81   \n",
       "Materials for my scikit-learn tutorial                     0.28         0.81   \n",
       "scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ                                  0.12         0.38   \n",
       "Source code for the \"Learning scikit-learn: Mac...         2.48         0.91   \n",
       "Scikit-Learn tutorial material for Scipy 2015              0.29         0.83   \n",
       "Simplified interface for TensorFlow (mimicking ...         1.41         0.34   \n",
       "Tutorial on scikit-learn and IPython for parall...         1.48         0.58   \n",
       "Scikit-learn integration package for Apache Spark          0.28         0.83   \n",
       "Machine Learning with Text in scikit-learn                 1.46         0.53   \n",
       "Hidden Markov Models in Python, with scikit-lea...         0.47         1.42   \n",
       "Materials for my Pycon 2015 scikit-learn tutorial.         0.29         0.82   \n",
       "Some sample IPython notebooks for scikit-learn             0.32         1.03   \n",
       "Dive into Machine Learning with Python Jupyter ...         1.71         1.57   \n",
       "Scikit-Learn, NLTK, Spacy, Gensim, Textblob and...         0.25         0.79   \n",
       "Julia implementation of the scikit-learn API               0.30         0.89   \n",
       "A scikit-learn compatible neural network librar...         0.33         0.85   \n",
       "Scikit-learn compatible tools using theano                 0.36         0.94   \n",
       "Scikit-learn tutorials for the Scipy 2013 confe...         0.27         0.80   \n",
       "scikit-learn compatible projects                           0.27         0.80   \n",
       "Scikit-Learn tutorials                                     0.27         0.78   \n",
       "scikit-learn inspired API for CRFsuite                     0.26         0.82   \n",
       "Repository containing files for my PyCon 2014 s...         0.31         0.85   \n",
       "Applied Machine Learning in Python with scikit-...         1.63         1.09   \n",
       "Scikit-Learn Tutorial for PyData Seattle 2015              0.28         0.82   \n",
       "Scikit-learn style model finetuning for NLP                0.29         0.80   \n",
       "...                                                         ...          ...   \n",
       "Curated list of Linguistic Resources for doing ...         0.07        -0.02   \n",
       "                                                           0.00         0.00   \n",
       "List of projects related to Natural Language Pr...         0.11         0.03   \n",
       "Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ                                                     0.00        -0.00   \n",
       "NLP course at Chulalongkorn University                     0.07         0.01   \n",
       "Some frequently used NLP blocks I implemented              0.04         0.02   \n",
       "NLP Sandbox                                                0.02         0.00   \n",
       "Vietnamese NLP Toolkit for Node                            0.03         0.00   \n",
       "Toy Python implementation of http://www-nlp.sta...         0.25         0.64   \n",
       "tensorflowÂÆûÊàòÁªÉ‰π†ÔºåÂåÖÊã¨Âº∫ÂåñÂ≠¶‰π†„ÄÅÊé®ËçêÁ≥ªÁªü„ÄÅnlpÁ≠â                           -0.00         0.00   \n",
       "Deep Learning Chinese Word Segment                         1.10        -0.47   \n",
       "NLPCC 2016 ÂæÆÂçöÂàÜËØçËØÑÊµãÈ°πÁõÆ                                        0.01         0.00   \n",
       "Âêå‰πâËØçË°®ÔºåÂèç‰πâËØçË°®ÔºåÂê¶ÂÆöËØçË°®                                            -0.00         0.00   \n",
       "Áà¨Ëô´‰∏éÊú∫Âô®Â≠¶‰π†                                                   -0.00         0.00   \n",
       "NLP Education Tools by YuZhen(www.yuzhenkeji.com)          0.05         0.04   \n",
       "NLP reading group at the University of Arizona             0.04        -0.00   \n",
       "in progress                                                0.00         0.00   \n",
       "Lectures for Udemy - INLP                                  0.01         0.00   \n",
       "A NLP library for Russian language                         0.08         0.07   \n",
       "Study E-Book(ComputerVision DeepLearning Machin...         0.24         0.60   \n",
       "Python implementation of TextRank for text docu...         0.23         0.64   \n",
       "üí´  Models for the spaCy Natural Language Proces...         0.14         0.09   \n",
       "\"End-To-End Memory Networks\" in Tensorflow                 0.08         0.02   \n",
       "Deprecated in favor of https://github.com/faceb...         0.02         0.05   \n",
       "A very brief introduction to Natural Language P...         0.24         0.65   \n",
       "Time-NLPÁöÑpython3ÁâàÊú¨ ‰∏≠ÊñáÊó∂Èó¥Ë°®ËææËØçËΩ¨Êç¢                               0.01         0.00   \n",
       "A companion repository for the \"Writing code fo...         0.16         0.12   \n",
       "Bi-directional Attention Flow (BiDAF) network i...         0.03         0.03   \n",
       "                                                           0.00         0.00   \n",
       "Tensorflow Tutorial files and Implementations o...         0.49        -0.14   \n",
       "\n",
       "                                                    component_3  component_4  \\\n",
       "description                                                                    \n",
       "scikit-learn: machine learning in Python                   0.83         0.30   \n",
       "Jupyter notebooks from the scikit-learn video s...         0.15        -1.23   \n",
       "PySpark + Scikit-learn = Sparkit-learn                     1.50        -0.69   \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                      0.98        -0.44   \n",
       "Automated Machine Learning with scikit-learn               1.06        -0.41   \n",
       "Scikit-learn tutorial at SciPy2016                         1.01        -0.48   \n",
       "Materials for my scikit-learn tutorial                     1.02        -0.48   \n",
       "scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ                                  0.49        -0.23   \n",
       "Source code for the \"Learning scikit-learn: Mac...         0.75         0.32   \n",
       "Scikit-Learn tutorial material for Scipy 2015              1.02        -0.49   \n",
       "Simplified interface for TensorFlow (mimicking ...         0.87        -0.58   \n",
       "Tutorial on scikit-learn and IPython for parall...         1.04        -0.47   \n",
       "Scikit-learn integration package for Apache Spark          0.98        -0.45   \n",
       "Machine Learning with Text in scikit-learn                 1.06        -0.41   \n",
       "Hidden Markov Models in Python, with scikit-lea...         0.79         0.28   \n",
       "Materials for my Pycon 2015 scikit-learn tutorial.         1.02        -0.49   \n",
       "Some sample IPython notebooks for scikit-learn             0.63        -0.78   \n",
       "Dive into Machine Learning with Python Jupyter ...         0.11        -0.38   \n",
       "Scikit-Learn, NLTK, Spacy, Gensim, Textblob and...         1.01        -0.46   \n",
       "Julia implementation of the scikit-learn API               0.97        -0.37   \n",
       "A scikit-learn compatible neural network librar...         1.01        -0.41   \n",
       "Scikit-learn compatible tools using theano                 1.04        -0.54   \n",
       "Scikit-learn tutorials for the Scipy 2013 confe...         0.99        -0.47   \n",
       "scikit-learn compatible projects                           1.01        -0.46   \n",
       "Scikit-Learn tutorials                                     0.98        -0.46   \n",
       "scikit-learn inspired API for CRFsuite                     1.00        -0.42   \n",
       "Repository containing files for my PyCon 2014 s...         1.00        -0.48   \n",
       "Applied Machine Learning in Python with scikit-...         0.83         0.30   \n",
       "Scikit-Learn Tutorial for PyData Seattle 2015              1.02        -0.49   \n",
       "Scikit-learn style model finetuning for NLP                1.00        -0.46   \n",
       "...                                                         ...          ...   \n",
       "Curated list of Linguistic Resources for doing ...        -0.02         0.00   \n",
       "                                                          -0.00        -0.00   \n",
       "List of projects related to Natural Language Pr...        -0.03         0.03   \n",
       "Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ                                                    -0.00         0.00   \n",
       "NLP course at Chulalongkorn University                    -0.04        -0.01   \n",
       "Some frequently used NLP blocks I implemented             -0.01         0.01   \n",
       "NLP Sandbox                                               -0.00         0.01   \n",
       "Vietnamese NLP Toolkit for Node                           -0.01         0.01   \n",
       "Toy Python implementation of http://www-nlp.sta...        -0.23         0.74   \n",
       "tensorflowÂÆûÊàòÁªÉ‰π†ÔºåÂåÖÊã¨Âº∫ÂåñÂ≠¶‰π†„ÄÅÊé®ËçêÁ≥ªÁªü„ÄÅnlpÁ≠â                           -0.00         0.00   \n",
       "Deep Learning Chinese Word Segment                        -0.14        -0.10   \n",
       "NLPCC 2016 ÂæÆÂçöÂàÜËØçËØÑÊµãÈ°πÁõÆ                                       -0.00        -0.01   \n",
       "Âêå‰πâËØçË°®ÔºåÂèç‰πâËØçË°®ÔºåÂê¶ÂÆöËØçË°®                                             0.00         0.00   \n",
       "Áà¨Ëô´‰∏éÊú∫Âô®Â≠¶‰π†                                                   -0.00        -0.00   \n",
       "NLP Education Tools by YuZhen(www.yuzhenkeji.com)         -0.01         0.03   \n",
       "NLP reading group at the University of Arizona            -0.01         0.01   \n",
       "in progress                                               -0.00         0.00   \n",
       "Lectures for Udemy - INLP                                 -0.01         0.00   \n",
       "A NLP library for Russian language                        -0.02         0.10   \n",
       "Study E-Book(ComputerVision DeepLearning Machin...        -0.25         0.74   \n",
       "Python implementation of TextRank for text docu...        -0.22         0.74   \n",
       "üí´  Models for the spaCy Natural Language Proces...         0.00         0.10   \n",
       "\"End-To-End Memory Networks\" in Tensorflow                 0.01        -0.05   \n",
       "Deprecated in favor of https://github.com/faceb...        -0.01         0.01   \n",
       "A very brief introduction to Natural Language P...        -0.26         0.75   \n",
       "Time-NLPÁöÑpython3ÁâàÊú¨ ‰∏≠ÊñáÊó∂Èó¥Ë°®ËææËØçËΩ¨Êç¢                              -0.00        -0.00   \n",
       "A companion repository for the \"Writing code fo...        -0.06         0.03   \n",
       "Bi-directional Attention Flow (BiDAF) network i...         0.00        -0.01   \n",
       "                                                          -0.00        -0.00   \n",
       "Tensorflow Tutorial files and Implementations o...        -0.06        -0.14   \n",
       "\n",
       "                                                    component_5  component_6  \\\n",
       "description                                                                    \n",
       "scikit-learn: machine learning in Python                  -0.33        -0.11   \n",
       "Jupyter notebooks from the scikit-learn video s...         0.10        -0.06   \n",
       "PySpark + Scikit-learn = Sparkit-learn                     0.31        -0.05   \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                      0.21        -0.04   \n",
       "Automated Machine Learning with scikit-learn              -0.47         0.01   \n",
       "Scikit-learn tutorial at SciPy2016                         0.22        -0.02   \n",
       "Materials for my scikit-learn tutorial                     0.23        -0.02   \n",
       "scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ                                  0.10        -0.02   \n",
       "Source code for the \"Learning scikit-learn: Mac...        -0.36        -0.09   \n",
       "Scikit-Learn tutorial material for Scipy 2015              0.23        -0.02   \n",
       "Simplified interface for TensorFlow (mimicking ...         0.98        -0.08   \n",
       "Tutorial on scikit-learn and IPython for parall...        -0.45         0.02   \n",
       "Scikit-learn integration package for Apache Spark          0.23         0.10   \n",
       "Machine Learning with Text in scikit-learn                -0.44         0.01   \n",
       "Hidden Markov Models in Python, with scikit-lea...         0.38        -0.11   \n",
       "Materials for my Pycon 2015 scikit-learn tutorial.         0.23        -0.02   \n",
       "Some sample IPython notebooks for scikit-learn             0.15        -0.05   \n",
       "Dive into Machine Learning with Python Jupyter ...        -0.42        -0.14   \n",
       "Scikit-Learn, NLTK, Spacy, Gensim, Textblob and...         0.21        -0.04   \n",
       "Julia implementation of the scikit-learn API               0.34         0.96   \n",
       "A scikit-learn compatible neural network librar...         0.32         0.05   \n",
       "Scikit-learn compatible tools using theano                 0.32        -0.01   \n",
       "Scikit-learn tutorials for the Scipy 2013 confe...         0.22        -0.03   \n",
       "scikit-learn compatible projects                           0.22        -0.03   \n",
       "Scikit-Learn tutorials                                     0.21        -0.03   \n",
       "scikit-learn inspired API for CRFsuite                     0.22        -0.02   \n",
       "Repository containing files for my PyCon 2014 s...         0.22        -0.00   \n",
       "Applied Machine Learning in Python with scikit-...        -0.34        -0.11   \n",
       "Scikit-Learn Tutorial for PyData Seattle 2015              0.23        -0.02   \n",
       "Scikit-learn style model finetuning for NLP                0.26        -0.03   \n",
       "...                                                         ...          ...   \n",
       "Curated list of Linguistic Resources for doing ...         0.05        -0.00   \n",
       "                                                           0.00         0.00   \n",
       "List of projects related to Natural Language Pr...         0.13         0.09   \n",
       "Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ                                                     0.00        -0.00   \n",
       "NLP course at Chulalongkorn University                     0.02         0.00   \n",
       "Some frequently used NLP blocks I implemented              0.03         0.00   \n",
       "NLP Sandbox                                                0.03        -0.00   \n",
       "Vietnamese NLP Toolkit for Node                            0.03         0.01   \n",
       "Toy Python implementation of http://www-nlp.sta...         0.20        -0.07   \n",
       "tensorflowÂÆûÊàòÁªÉ‰π†ÔºåÂåÖÊã¨Âº∫ÂåñÂ≠¶‰π†„ÄÅÊé®ËçêÁ≥ªÁªü„ÄÅnlpÁ≠â                            0.00        -0.00   \n",
       "Deep Learning Chinese Word Segment                         0.68        -0.09   \n",
       "NLPCC 2016 ÂæÆÂçöÂàÜËØçËØÑÊµãÈ°πÁõÆ                                        0.00         0.00   \n",
       "Âêå‰πâËØçË°®ÔºåÂèç‰πâËØçË°®ÔºåÂê¶ÂÆöËØçË°®                                             0.00        -0.00   \n",
       "Áà¨Ëô´‰∏éÊú∫Âô®Â≠¶‰π†                                                    0.00        -0.00   \n",
       "NLP Education Tools by YuZhen(www.yuzhenkeji.com)          0.05         0.01   \n",
       "NLP reading group at the University of Arizona             0.03         0.01   \n",
       "in progress                                                0.00         0.00   \n",
       "Lectures for Udemy - INLP                                 -0.00        -0.00   \n",
       "A NLP library for Russian language                         0.09         0.15   \n",
       "Study E-Book(ComputerVision DeepLearning Machin...         0.17        -0.11   \n",
       "Python implementation of TextRank for text docu...         0.20        -0.08   \n",
       "üí´  Models for the spaCy Natural Language Proces...         0.16         0.18   \n",
       "\"End-To-End Memory Networks\" in Tensorflow                 0.12         0.01   \n",
       "Deprecated in favor of https://github.com/faceb...         0.02         0.01   \n",
       "A very brief introduction to Natural Language P...         0.21         0.02   \n",
       "Time-NLPÁöÑpython3ÁâàÊú¨ ‰∏≠ÊñáÊó∂Èó¥Ë°®ËææËØçËΩ¨Êç¢                               0.00         0.01   \n",
       "A companion repository for the \"Writing code fo...         0.04         0.05   \n",
       "Bi-directional Attention Flow (BiDAF) network i...         0.03         0.03   \n",
       "                                                           0.00         0.00   \n",
       "Tensorflow Tutorial files and Implementations o...         0.85        -0.03   \n",
       "\n",
       "                                                    component_7  component_8  \n",
       "description                                                                   \n",
       "scikit-learn: machine learning in Python                  -0.09        -0.31  \n",
       "Jupyter notebooks from the scikit-learn video s...        -0.09        -0.44  \n",
       "PySpark + Scikit-learn = Sparkit-learn                    -0.07        -0.35  \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                     -0.05        -0.25  \n",
       "Automated Machine Learning with scikit-learn              -0.05        -0.25  \n",
       "Scikit-learn tutorial at SciPy2016                        -0.04        -0.27  \n",
       "Materials for my scikit-learn tutorial                    -0.04        -0.28  \n",
       "scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ                                 -0.03        -0.10  \n",
       "Source code for the \"Learning scikit-learn: Mac...        -0.07        -0.47  \n",
       "Scikit-Learn tutorial material for Scipy 2015             -0.04        -0.29  \n",
       "Simplified interface for TensorFlow (mimicking ...        -0.09        -0.23  \n",
       "Tutorial on scikit-learn and IPython for parall...        -0.05        -0.31  \n",
       "Scikit-learn integration package for Apache Spark         -0.02        -0.24  \n",
       "Machine Learning with Text in scikit-learn                -0.05        -0.22  \n",
       "Hidden Markov Models in Python, with scikit-lea...        -0.04        -0.24  \n",
       "Materials for my Pycon 2015 scikit-learn tutorial.        -0.04        -0.29  \n",
       "Some sample IPython notebooks for scikit-learn            -0.07        -0.39  \n",
       "Dive into Machine Learning with Python Jupyter ...        -0.11        -0.35  \n",
       "Scikit-Learn, NLTK, Spacy, Gensim, Textblob and...        -0.05        -0.22  \n",
       "Julia implementation of the scikit-learn API              -0.08        -0.27  \n",
       "A scikit-learn compatible neural network librar...        -0.02        -0.10  \n",
       "Scikit-learn compatible tools using theano                 0.06         0.61  \n",
       "Scikit-learn tutorials for the Scipy 2013 confe...        -0.05        -0.25  \n",
       "scikit-learn compatible projects                          -0.05        -0.23  \n",
       "Scikit-Learn tutorials                                    -0.05        -0.24  \n",
       "scikit-learn inspired API for CRFsuite                    -0.01        -0.21  \n",
       "Repository containing files for my PyCon 2014 s...        -0.01        -0.31  \n",
       "Applied Machine Learning in Python with scikit-...        -0.09        -0.31  \n",
       "Scikit-Learn Tutorial for PyData Seattle 2015             -0.04        -0.28  \n",
       "Scikit-learn style model finetuning for NLP               -0.04        -0.12  \n",
       "...                                                         ...          ...  \n",
       "Curated list of Linguistic Resources for doing ...         0.02        -0.02  \n",
       "                                                           0.00         0.00  \n",
       "List of projects related to Natural Language Pr...        -0.00         0.01  \n",
       "Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ                                                    -0.00        -0.00  \n",
       "NLP course at Chulalongkorn University                    -0.00        -0.03  \n",
       "Some frequently used NLP blocks I implemented              0.01         0.02  \n",
       "NLP Sandbox                                               -0.00         0.00  \n",
       "Vietnamese NLP Toolkit for Node                            0.02         0.00  \n",
       "Toy Python implementation of http://www-nlp.sta...        -0.03        -0.07  \n",
       "tensorflowÂÆûÊàòÁªÉ‰π†ÔºåÂåÖÊã¨Âº∫ÂåñÂ≠¶‰π†„ÄÅÊé®ËçêÁ≥ªÁªü„ÄÅnlpÁ≠â                            0.00        -0.00  \n",
       "Deep Learning Chinese Word Segment                        -0.05        -0.12  \n",
       "NLPCC 2016 ÂæÆÂçöÂàÜËØçËØÑÊµãÈ°πÁõÆ                                       -0.00        -0.01  \n",
       "Âêå‰πâËØçË°®ÔºåÂèç‰πâËØçË°®ÔºåÂê¶ÂÆöËØçË°®                                             0.00        -0.00  \n",
       "Áà¨Ëô´‰∏éÊú∫Âô®Â≠¶‰π†                                                   -0.00        -0.00  \n",
       "NLP Education Tools by YuZhen(www.yuzhenkeji.com)          0.02        -0.01  \n",
       "NLP reading group at the University of Arizona            -0.00         0.00  \n",
       "in progress                                               -0.00         0.00  \n",
       "Lectures for Udemy - INLP                                 -0.00        -0.00  \n",
       "A NLP library for Russian language                        -0.00         0.01  \n",
       "Study E-Book(ComputerVision DeepLearning Machin...        -0.04        -0.08  \n",
       "Python implementation of TextRank for text docu...        -0.03        -0.02  \n",
       "üí´  Models for the spaCy Natural Language Proces...        -0.00         0.03  \n",
       "\"End-To-End Memory Networks\" in Tensorflow                 0.01         0.13  \n",
       "Deprecated in favor of https://github.com/faceb...         0.04        -0.04  \n",
       "A very brief introduction to Natural Language P...        -0.05        -0.05  \n",
       "Time-NLPÁöÑpython3ÁâàÊú¨ ‰∏≠ÊñáÊó∂Èó¥Ë°®ËææËØçËΩ¨Êç¢                               0.00         0.01  \n",
       "A companion repository for the \"Writing code fo...         0.04        -0.13  \n",
       "Bi-directional Attention Flow (BiDAF) network i...         0.05         0.10  \n",
       "                                                           0.00         0.00  \n",
       "Tensorflow Tutorial files and Implementations o...         0.01         0.01  \n",
       "\n",
       "[7014 rows x 8 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vt = pd.DataFrame(doc_topic.round(2),\n",
    "             index = sample,\n",
    "             columns = [\"component_1\",\"component_2\",\"component_3\",\"component_4\",\"component_5\",\"component_6\", \"component_7\", \"component_8\"])\n",
    "Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:48:56.571455Z",
     "start_time": "2019-03-27T01:48:56.559976Z"
    }
   },
   "outputs": [],
   "source": [
    "# cosine_similarity((dtm_lsa[0], dtm_lsa[1])).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:48:57.348520Z",
     "start_time": "2019-03-27T01:48:57.334178Z"
    }
   },
   "outputs": [],
   "source": [
    "# cosine_similarity((dtm_lsa[0], dtm_lsa[1])).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:48:57.964319Z",
     "start_time": "2019-03-27T01:48:57.950053Z"
    }
   },
   "outputs": [],
   "source": [
    "# cosine_similarity((dtm_lsa[0], dtm_lsa[6])).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:48:59.560644Z",
     "start_time": "2019-03-27T01:48:59.408318Z"
    }
   },
   "outputs": [],
   "source": [
    "# NMF\n",
    "nmf_model = NMF(8)\n",
    "doc_topic = nmf_model.fit_transform(doc_word)\n",
    "# ex_label = [e[:30]+\"...\" for e in sample]\n",
    "ex_label = [e for e in sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             scikit-learn: machine learning in Python\n",
       "1    Jupyter notebooks from the scikit-learn video ...\n",
       "2               PySpark + Scikit-learn = Sparkit-learn\n",
       "3                :book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£\n",
       "4         Automated Machine Learning with scikit-learn\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vt.reset_index()['description'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:16:34.110441Z",
     "start_time": "2019-03-27T02:16:34.061637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machine_learning</th>\n",
       "      <th>scikit_learn</th>\n",
       "      <th>jupyter_notebook</th>\n",
       "      <th>python_library</th>\n",
       "      <th>nlp</th>\n",
       "      <th>julia_package</th>\n",
       "      <th>kubernetes</th>\n",
       "      <th>deep_learning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scikit-learn: machine learning in Python</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jupyter notebooks from the scikit-learn video series</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PySpark + Scikit-learn = Sparkit-learn</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Automated Machine Learning with scikit-learn</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scikit-learn tutorial at SciPy2016</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Materials for my scikit-learn tutorial</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source code for the \"Learning scikit-learn: Machine Learning in Python\"</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scikit-Learn tutorial material for Scipy 2015</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Simplified interface for TensorFlow (mimicking Scikit Learn) for Deep Learning</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tutorial on scikit-learn and IPython for parallel machine learning</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scikit-learn integration package for Apache Spark</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Machine Learning with Text in scikit-learn</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hidden Markov Models in Python, with scikit-learn like API</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Materials for my Pycon 2015 scikit-learn tutorial.</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Some sample IPython notebooks for scikit-learn</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dive into Machine Learning with Python Jupyter notebook and scikit-learn!</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scikit-Learn, NLTK, Spacy, Gensim, Textblob and more</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Julia implementation of the scikit-learn API</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A scikit-learn compatible neural network library that wraps pytorch</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scikit-learn compatible tools using theano</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scikit-learn tutorials for the Scipy 2013 conference</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scikit-learn compatible projects</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scikit-Learn tutorials</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scikit-learn inspired API for CRFsuite</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Repository containing files for my PyCon 2014 scikit-learn tutorial.</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Applied Machine Learning in Python with scikit-learn</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scikit-Learn Tutorial for PyData Seattle 2015</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scikit-learn style model finetuning for NLP</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Curated list of Linguistic Resources for doing NLP &amp; CL on Spanish</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>List of projects related to Natural Language Processing (NLP) that make a geek smile for they exist</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP course at Chulalongkorn University</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Some frequently used NLP blocks I implemented</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP Sandbox</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vietnamese NLP Toolkit for Node</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toy Python implementation of http://www-nlp.stanford.edu/projects/glove/</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tensorflowÂÆûÊàòÁªÉ‰π†ÔºåÂåÖÊã¨Âº∫ÂåñÂ≠¶‰π†„ÄÅÊé®ËçêÁ≥ªÁªü„ÄÅnlpÁ≠â</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Learning Chinese Word Segment</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLPCC 2016 ÂæÆÂçöÂàÜËØçËØÑÊµãÈ°πÁõÆ</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Âêå‰πâËØçË°®ÔºåÂèç‰πâËØçË°®ÔºåÂê¶ÂÆöËØçË°®</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Áà¨Ëô´‰∏éÊú∫Âô®Â≠¶‰π†</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP Education Tools by YuZhen(www.yuzhenkeji.com)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP reading group at the University of Arizona</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in progress</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lectures for Udemy - INLP</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A NLP library for Russian language</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Study E-Book(ComputerVision DeepLearning MachineLearning Math NLP Python ReinforcementLearning)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python implementation of TextRank for text document NLP parsing and summarization</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üí´  Models for the spaCy Natural Language Processing (NLP) library</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"End-To-End Memory Networks\" in Tensorflow</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deprecated in favor of https://github.com/facebook/duckling</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A very brief introduction to Natural Language Processing programming in Python</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time-NLPÁöÑpython3ÁâàÊú¨ ‰∏≠ÊñáÊó∂Èó¥Ë°®ËææËØçËΩ¨Êç¢</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A companion repository for the \"Writing code for NLP Research\" Tutorial at EMNLP 2018</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bi-directional Attention Flow (BiDAF) network is a multi-stage hierarchical process that represents context at different levels of granularity and uses a bi-directional attention flow mechanism to achieve a query-aware context representation without early summarization.</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tensorflow Tutorial files and Implementations of various Deep NLP and CV Models.</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7014 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    machine_learning  \\\n",
       "scikit-learn: machine learning in Python                        0.17   \n",
       "Jupyter notebooks from the scikit-learn video s...              0.00   \n",
       "PySpark + Scikit-learn = Sparkit-learn                          0.00   \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                           0.00   \n",
       "Automated Machine Learning with scikit-learn                    0.17   \n",
       "Scikit-learn tutorial at SciPy2016                              0.00   \n",
       "Materials for my scikit-learn tutorial                          0.00   \n",
       "scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ                                       0.00   \n",
       "Source code for the \"Learning scikit-learn: Mac...              0.23   \n",
       "Scikit-Learn tutorial material for Scipy 2015                   0.00   \n",
       "Simplified interface for TensorFlow (mimicking ...              0.00   \n",
       "Tutorial on scikit-learn and IPython for parall...              0.17   \n",
       "Scikit-learn integration package for Apache Spark               0.00   \n",
       "Machine Learning with Text in scikit-learn                      0.17   \n",
       "Hidden Markov Models in Python, with scikit-lea...              0.00   \n",
       "Materials for my Pycon 2015 scikit-learn tutorial.              0.00   \n",
       "Some sample IPython notebooks for scikit-learn                  0.00   \n",
       "Dive into Machine Learning with Python Jupyter ...              0.16   \n",
       "Scikit-Learn, NLTK, Spacy, Gensim, Textblob and...              0.00   \n",
       "Julia implementation of the scikit-learn API                    0.00   \n",
       "A scikit-learn compatible neural network librar...              0.00   \n",
       "Scikit-learn compatible tools using theano                      0.00   \n",
       "Scikit-learn tutorials for the Scipy 2013 confe...              0.00   \n",
       "scikit-learn compatible projects                                0.00   \n",
       "Scikit-Learn tutorials                                          0.00   \n",
       "scikit-learn inspired API for CRFsuite                          0.00   \n",
       "Repository containing files for my PyCon 2014 s...              0.00   \n",
       "Applied Machine Learning in Python with scikit-...              0.17   \n",
       "Scikit-Learn Tutorial for PyData Seattle 2015                   0.00   \n",
       "Scikit-learn style model finetuning for NLP                     0.00   \n",
       "...                                                              ...   \n",
       "Curated list of Linguistic Resources for doing ...              0.00   \n",
       "                                                                0.00   \n",
       "List of projects related to Natural Language Pr...              0.00   \n",
       "Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ                                                          0.00   \n",
       "NLP course at Chulalongkorn University                          0.00   \n",
       "Some frequently used NLP blocks I implemented                   0.00   \n",
       "NLP Sandbox                                                     0.00   \n",
       "Vietnamese NLP Toolkit for Node                                 0.00   \n",
       "Toy Python implementation of http://www-nlp.sta...              0.00   \n",
       "tensorflowÂÆûÊàòÁªÉ‰π†ÔºåÂåÖÊã¨Âº∫ÂåñÂ≠¶‰π†„ÄÅÊé®ËçêÁ≥ªÁªü„ÄÅnlpÁ≠â                                 0.00   \n",
       "Deep Learning Chinese Word Segment                              0.00   \n",
       "NLPCC 2016 ÂæÆÂçöÂàÜËØçËØÑÊµãÈ°πÁõÆ                                             0.00   \n",
       "Âêå‰πâËØçË°®ÔºåÂèç‰πâËØçË°®ÔºåÂê¶ÂÆöËØçË°®                                                  0.00   \n",
       "Áà¨Ëô´‰∏éÊú∫Âô®Â≠¶‰π†                                                         0.00   \n",
       "NLP Education Tools by YuZhen(www.yuzhenkeji.com)               0.00   \n",
       "NLP reading group at the University of Arizona                  0.00   \n",
       "in progress                                                     0.00   \n",
       "Lectures for Udemy - INLP                                       0.00   \n",
       "A NLP library for Russian language                              0.00   \n",
       "Study E-Book(ComputerVision DeepLearning Machin...              0.00   \n",
       "Python implementation of TextRank for text docu...              0.00   \n",
       "üí´  Models for the spaCy Natural Language Proces...              0.00   \n",
       "\"End-To-End Memory Networks\" in Tensorflow                      0.00   \n",
       "Deprecated in favor of https://github.com/faceb...              0.00   \n",
       "A very brief introduction to Natural Language P...              0.00   \n",
       "Time-NLPÁöÑpython3ÁâàÊú¨ ‰∏≠ÊñáÊó∂Èó¥Ë°®ËææËØçËΩ¨Êç¢                                    0.00   \n",
       "A companion repository for the \"Writing code fo...              0.01   \n",
       "Bi-directional Attention Flow (BiDAF) network i...              0.00   \n",
       "                                                                0.00   \n",
       "Tensorflow Tutorial files and Implementations o...              0.00   \n",
       "\n",
       "                                                    scikit_learn  \\\n",
       "scikit-learn: machine learning in Python                    0.18   \n",
       "Jupyter notebooks from the scikit-learn video s...          0.18   \n",
       "PySpark + Scikit-learn = Sparkit-learn                      0.27   \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                       0.18   \n",
       "Automated Machine Learning with scikit-learn                0.18   \n",
       "Scikit-learn tutorial at SciPy2016                          0.19   \n",
       "Materials for my scikit-learn tutorial                      0.19   \n",
       "scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ                                   0.09   \n",
       "Source code for the \"Learning scikit-learn: Mac...          0.18   \n",
       "Scikit-Learn tutorial material for Scipy 2015               0.19   \n",
       "Simplified interface for TensorFlow (mimicking ...          0.18   \n",
       "Tutorial on scikit-learn and IPython for parall...          0.19   \n",
       "Scikit-learn integration package for Apache Spark           0.18   \n",
       "Machine Learning with Text in scikit-learn                  0.18   \n",
       "Hidden Markov Models in Python, with scikit-lea...          0.18   \n",
       "Materials for my Pycon 2015 scikit-learn tutorial.          0.19   \n",
       "Some sample IPython notebooks for scikit-learn              0.18   \n",
       "Dive into Machine Learning with Python Jupyter ...          0.18   \n",
       "Scikit-Learn, NLTK, Spacy, Gensim, Textblob and...          0.18   \n",
       "Julia implementation of the scikit-learn API                0.18   \n",
       "A scikit-learn compatible neural network librar...          0.19   \n",
       "Scikit-learn compatible tools using theano                  0.18   \n",
       "Scikit-learn tutorials for the Scipy 2013 confe...          0.18   \n",
       "scikit-learn compatible projects                            0.18   \n",
       "Scikit-Learn tutorials                                      0.18   \n",
       "scikit-learn inspired API for CRFsuite                      0.18   \n",
       "Repository containing files for my PyCon 2014 s...          0.19   \n",
       "Applied Machine Learning in Python with scikit-...          0.18   \n",
       "Scikit-Learn Tutorial for PyData Seattle 2015               0.19   \n",
       "Scikit-learn style model finetuning for NLP                 0.18   \n",
       "...                                                          ...   \n",
       "Curated list of Linguistic Resources for doing ...          0.00   \n",
       "                                                            0.00   \n",
       "List of projects related to Natural Language Pr...          0.00   \n",
       "Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ                                                      0.00   \n",
       "NLP course at Chulalongkorn University                      0.00   \n",
       "Some frequently used NLP blocks I implemented               0.00   \n",
       "NLP Sandbox                                                 0.00   \n",
       "Vietnamese NLP Toolkit for Node                             0.00   \n",
       "Toy Python implementation of http://www-nlp.sta...          0.00   \n",
       "tensorflowÂÆûÊàòÁªÉ‰π†ÔºåÂåÖÊã¨Âº∫ÂåñÂ≠¶‰π†„ÄÅÊé®ËçêÁ≥ªÁªü„ÄÅnlpÁ≠â                             0.00   \n",
       "Deep Learning Chinese Word Segment                          0.00   \n",
       "NLPCC 2016 ÂæÆÂçöÂàÜËØçËØÑÊµãÈ°πÁõÆ                                         0.00   \n",
       "Âêå‰πâËØçË°®ÔºåÂèç‰πâËØçË°®ÔºåÂê¶ÂÆöËØçË°®                                              0.00   \n",
       "Áà¨Ëô´‰∏éÊú∫Âô®Â≠¶‰π†                                                     0.00   \n",
       "NLP Education Tools by YuZhen(www.yuzhenkeji.com)           0.00   \n",
       "NLP reading group at the University of Arizona              0.00   \n",
       "in progress                                                 0.00   \n",
       "Lectures for Udemy - INLP                                   0.00   \n",
       "A NLP library for Russian language                          0.00   \n",
       "Study E-Book(ComputerVision DeepLearning Machin...          0.00   \n",
       "Python implementation of TextRank for text docu...          0.00   \n",
       "üí´  Models for the spaCy Natural Language Proces...          0.01   \n",
       "\"End-To-End Memory Networks\" in Tensorflow                  0.01   \n",
       "Deprecated in favor of https://github.com/faceb...          0.00   \n",
       "A very brief introduction to Natural Language P...          0.00   \n",
       "Time-NLPÁöÑpython3ÁâàÊú¨ ‰∏≠ÊñáÊó∂Èó¥Ë°®ËææËØçËΩ¨Êç¢                                0.00   \n",
       "A companion repository for the \"Writing code fo...          0.01   \n",
       "Bi-directional Attention Flow (BiDAF) network i...          0.00   \n",
       "                                                            0.00   \n",
       "Tensorflow Tutorial files and Implementations o...          0.02   \n",
       "\n",
       "                                                    jupyter_notebook  \\\n",
       "scikit-learn: machine learning in Python                        0.00   \n",
       "Jupyter notebooks from the scikit-learn video s...              0.24   \n",
       "PySpark + Scikit-learn = Sparkit-learn                          0.00   \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                           0.00   \n",
       "Automated Machine Learning with scikit-learn                    0.00   \n",
       "Scikit-learn tutorial at SciPy2016                              0.00   \n",
       "Materials for my scikit-learn tutorial                          0.00   \n",
       "scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ                                       0.00   \n",
       "Source code for the \"Learning scikit-learn: Mac...              0.00   \n",
       "Scikit-Learn tutorial material for Scipy 2015                   0.00   \n",
       "Simplified interface for TensorFlow (mimicking ...              0.00   \n",
       "Tutorial on scikit-learn and IPython for parall...              0.01   \n",
       "Scikit-learn integration package for Apache Spark               0.00   \n",
       "Machine Learning with Text in scikit-learn                      0.00   \n",
       "Hidden Markov Models in Python, with scikit-lea...              0.00   \n",
       "Materials for my Pycon 2015 scikit-learn tutorial.              0.00   \n",
       "Some sample IPython notebooks for scikit-learn                  0.10   \n",
       "Dive into Machine Learning with Python Jupyter ...              0.20   \n",
       "Scikit-Learn, NLTK, Spacy, Gensim, Textblob and...              0.00   \n",
       "Julia implementation of the scikit-learn API                    0.00   \n",
       "A scikit-learn compatible neural network librar...              0.00   \n",
       "Scikit-learn compatible tools using theano                      0.00   \n",
       "Scikit-learn tutorials for the Scipy 2013 confe...              0.00   \n",
       "scikit-learn compatible projects                                0.00   \n",
       "Scikit-Learn tutorials                                          0.00   \n",
       "scikit-learn inspired API for CRFsuite                          0.00   \n",
       "Repository containing files for my PyCon 2014 s...              0.01   \n",
       "Applied Machine Learning in Python with scikit-...              0.00   \n",
       "Scikit-Learn Tutorial for PyData Seattle 2015                   0.00   \n",
       "Scikit-learn style model finetuning for NLP                     0.00   \n",
       "...                                                              ...   \n",
       "Curated list of Linguistic Resources for doing ...              0.00   \n",
       "                                                                0.00   \n",
       "List of projects related to Natural Language Pr...              0.00   \n",
       "Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ                                                          0.00   \n",
       "NLP course at Chulalongkorn University                          0.01   \n",
       "Some frequently used NLP blocks I implemented                   0.00   \n",
       "NLP Sandbox                                                     0.00   \n",
       "Vietnamese NLP Toolkit for Node                                 0.00   \n",
       "Toy Python implementation of http://www-nlp.sta...              0.00   \n",
       "tensorflowÂÆûÊàòÁªÉ‰π†ÔºåÂåÖÊã¨Âº∫ÂåñÂ≠¶‰π†„ÄÅÊé®ËçêÁ≥ªÁªü„ÄÅnlpÁ≠â                                 0.00   \n",
       "Deep Learning Chinese Word Segment                              0.00   \n",
       "NLPCC 2016 ÂæÆÂçöÂàÜËØçËØÑÊµãÈ°πÁõÆ                                             0.00   \n",
       "Âêå‰πâËØçË°®ÔºåÂèç‰πâËØçË°®ÔºåÂê¶ÂÆöËØçË°®                                                  0.00   \n",
       "Áà¨Ëô´‰∏éÊú∫Âô®Â≠¶‰π†                                                         0.00   \n",
       "NLP Education Tools by YuZhen(www.yuzhenkeji.com)               0.00   \n",
       "NLP reading group at the University of Arizona                  0.00   \n",
       "in progress                                                     0.00   \n",
       "Lectures for Udemy - INLP                                       0.00   \n",
       "A NLP library for Russian language                              0.00   \n",
       "Study E-Book(ComputerVision DeepLearning Machin...              0.00   \n",
       "Python implementation of TextRank for text docu...              0.00   \n",
       "üí´  Models for the spaCy Natural Language Proces...              0.00   \n",
       "\"End-To-End Memory Networks\" in Tensorflow                      0.00   \n",
       "Deprecated in favor of https://github.com/faceb...              0.00   \n",
       "A very brief introduction to Natural Language P...              0.00   \n",
       "Time-NLPÁöÑpython3ÁâàÊú¨ ‰∏≠ÊñáÊó∂Èó¥Ë°®ËææËØçËΩ¨Êç¢                                    0.00   \n",
       "A companion repository for the \"Writing code fo...              0.02   \n",
       "Bi-directional Attention Flow (BiDAF) network i...              0.00   \n",
       "                                                                0.00   \n",
       "Tensorflow Tutorial files and Implementations o...              0.00   \n",
       "\n",
       "                                                    python_library   nlp  \\\n",
       "scikit-learn: machine learning in Python                      0.18  0.00   \n",
       "Jupyter notebooks from the scikit-learn video s...            0.00  0.00   \n",
       "PySpark + Scikit-learn = Sparkit-learn                        0.00  0.00   \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                         0.00  0.00   \n",
       "Automated Machine Learning with scikit-learn                  0.00  0.00   \n",
       "Scikit-learn tutorial at SciPy2016                            0.00  0.00   \n",
       "Materials for my scikit-learn tutorial                        0.00  0.00   \n",
       "scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ                                     0.00  0.00   \n",
       "Source code for the \"Learning scikit-learn: Mac...            0.20  0.06   \n",
       "Scikit-Learn tutorial material for Scipy 2015                 0.00  0.00   \n",
       "Simplified interface for TensorFlow (mimicking ...            0.00  0.20   \n",
       "Tutorial on scikit-learn and IPython for parall...            0.00  0.00   \n",
       "Scikit-learn integration package for Apache Spark             0.00  0.00   \n",
       "Machine Learning with Text in scikit-learn                    0.00  0.00   \n",
       "Hidden Markov Models in Python, with scikit-lea...            0.19  0.00   \n",
       "Materials for my Pycon 2015 scikit-learn tutorial.            0.00  0.00   \n",
       "Some sample IPython notebooks for scikit-learn                0.00  0.00   \n",
       "Dive into Machine Learning with Python Jupyter ...            0.18  0.00   \n",
       "Scikit-Learn, NLTK, Spacy, Gensim, Textblob and...            0.00  0.00   \n",
       "Julia implementation of the scikit-learn API                  0.01  0.00   \n",
       "A scikit-learn compatible neural network librar...            0.01  0.01   \n",
       "Scikit-learn compatible tools using theano                    0.00  0.00   \n",
       "Scikit-learn tutorials for the Scipy 2013 confe...            0.00  0.00   \n",
       "scikit-learn compatible projects                              0.00  0.00   \n",
       "Scikit-Learn tutorials                                        0.00  0.00   \n",
       "scikit-learn inspired API for CRFsuite                        0.01  0.00   \n",
       "Repository containing files for my PyCon 2014 s...            0.00  0.00   \n",
       "Applied Machine Learning in Python with scikit-...            0.18  0.00   \n",
       "Scikit-Learn Tutorial for PyData Seattle 2015                 0.00  0.00   \n",
       "Scikit-learn style model finetuning for NLP                   0.00  0.00   \n",
       "...                                                            ...   ...   \n",
       "Curated list of Linguistic Resources for doing ...            0.00  0.01   \n",
       "                                                              0.00  0.00   \n",
       "List of projects related to Natural Language Pr...            0.01  0.02   \n",
       "Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ                                                        0.00  0.00   \n",
       "NLP course at Chulalongkorn University                        0.00  0.01   \n",
       "Some frequently used NLP blocks I implemented                 0.00  0.01   \n",
       "NLP Sandbox                                                   0.00  0.00   \n",
       "Vietnamese NLP Toolkit for Node                               0.00  0.00   \n",
       "Toy Python implementation of http://www-nlp.sta...            0.20  0.01   \n",
       "tensorflowÂÆûÊàòÁªÉ‰π†ÔºåÂåÖÊã¨Âº∫ÂåñÂ≠¶‰π†„ÄÅÊé®ËçêÁ≥ªÁªü„ÄÅnlpÁ≠â                               0.00  0.00   \n",
       "Deep Learning Chinese Word Segment                            0.00  0.19   \n",
       "NLPCC 2016 ÂæÆÂçöÂàÜËØçËØÑÊµãÈ°πÁõÆ                                           0.00  0.00   \n",
       "Âêå‰πâËØçË°®ÔºåÂèç‰πâËØçË°®ÔºåÂê¶ÂÆöËØçË°®                                                0.00  0.00   \n",
       "Áà¨Ëô´‰∏éÊú∫Âô®Â≠¶‰π†                                                       0.00  0.00   \n",
       "NLP Education Tools by YuZhen(www.yuzhenkeji.com)             0.01  0.01   \n",
       "NLP reading group at the University of Arizona                0.00  0.01   \n",
       "in progress                                                   0.00  0.00   \n",
       "Lectures for Udemy - INLP                                     0.00  0.00   \n",
       "A NLP library for Russian language                            0.02  0.01   \n",
       "Study E-Book(ComputerVision DeepLearning Machin...            0.20  0.01   \n",
       "Python implementation of TextRank for text docu...            0.20  0.01   \n",
       "üí´  Models for the spaCy Natural Language Proces...            0.03  0.02   \n",
       "\"End-To-End Memory Networks\" in Tensorflow                    0.00  0.01   \n",
       "Deprecated in favor of https://github.com/faceb...            0.01  0.00   \n",
       "A very brief introduction to Natural Language P...            0.20  0.01   \n",
       "Time-NLPÁöÑpython3ÁâàÊú¨ ‰∏≠ÊñáÊó∂Èó¥Ë°®ËææËØçËΩ¨Êç¢                                  0.00  0.00   \n",
       "A companion repository for the \"Writing code fo...            0.03  0.01   \n",
       "Bi-directional Attention Flow (BiDAF) network i...            0.00  0.00   \n",
       "                                                              0.00  0.00   \n",
       "Tensorflow Tutorial files and Implementations o...            0.00  0.12   \n",
       "\n",
       "                                                    julia_package  kubernetes  \\\n",
       "scikit-learn: machine learning in Python                     0.00        0.00   \n",
       "Jupyter notebooks from the scikit-learn video s...           0.00        0.00   \n",
       "PySpark + Scikit-learn = Sparkit-learn                       0.00        0.00   \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                        0.00        0.00   \n",
       "Automated Machine Learning with scikit-learn                 0.00        0.00   \n",
       "Scikit-learn tutorial at SciPy2016                           0.00        0.00   \n",
       "Materials for my scikit-learn tutorial                       0.00        0.00   \n",
       "scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ                                    0.00        0.00   \n",
       "Source code for the \"Learning scikit-learn: Mac...           0.00        0.00   \n",
       "Scikit-Learn tutorial material for Scipy 2015                0.00        0.00   \n",
       "Simplified interface for TensorFlow (mimicking ...           0.01        0.00   \n",
       "Tutorial on scikit-learn and IPython for parall...           0.00        0.00   \n",
       "Scikit-learn integration package for Apache Spark            0.02        0.01   \n",
       "Machine Learning with Text in scikit-learn                   0.00        0.00   \n",
       "Hidden Markov Models in Python, with scikit-lea...           0.00        0.00   \n",
       "Materials for my Pycon 2015 scikit-learn tutorial.           0.00        0.00   \n",
       "Some sample IPython notebooks for scikit-learn               0.00        0.00   \n",
       "Dive into Machine Learning with Python Jupyter ...           0.00        0.00   \n",
       "Scikit-Learn, NLTK, Spacy, Gensim, Textblob and...           0.00        0.00   \n",
       "Julia implementation of the scikit-learn API                 0.18        0.00   \n",
       "A scikit-learn compatible neural network librar...           0.01        0.00   \n",
       "Scikit-learn compatible tools using theano                   0.00        0.00   \n",
       "Scikit-learn tutorials for the Scipy 2013 confe...           0.00        0.00   \n",
       "scikit-learn compatible projects                             0.00        0.00   \n",
       "Scikit-Learn tutorials                                       0.00        0.00   \n",
       "scikit-learn inspired API for CRFsuite                       0.00        0.00   \n",
       "Repository containing files for my PyCon 2014 s...           0.00        0.01   \n",
       "Applied Machine Learning in Python with scikit-...           0.00        0.00   \n",
       "Scikit-Learn Tutorial for PyData Seattle 2015                0.00        0.00   \n",
       "Scikit-learn style model finetuning for NLP                  0.00        0.00   \n",
       "...                                                           ...         ...   \n",
       "Curated list of Linguistic Resources for doing ...           0.00        0.00   \n",
       "                                                             0.00        0.00   \n",
       "List of projects related to Natural Language Pr...           0.02        0.00   \n",
       "Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ                                                       0.00        0.00   \n",
       "NLP course at Chulalongkorn University                       0.00        0.00   \n",
       "Some frequently used NLP blocks I implemented                0.00        0.00   \n",
       "NLP Sandbox                                                  0.00        0.00   \n",
       "Vietnamese NLP Toolkit for Node                              0.00        0.00   \n",
       "Toy Python implementation of http://www-nlp.sta...           0.00        0.00   \n",
       "tensorflowÂÆûÊàòÁªÉ‰π†ÔºåÂåÖÊã¨Âº∫ÂåñÂ≠¶‰π†„ÄÅÊé®ËçêÁ≥ªÁªü„ÄÅnlpÁ≠â                              0.00        0.00   \n",
       "Deep Learning Chinese Word Segment                           0.00        0.00   \n",
       "NLPCC 2016 ÂæÆÂçöÂàÜËØçËØÑÊµãÈ°πÁõÆ                                          0.00        0.00   \n",
       "Âêå‰πâËØçË°®ÔºåÂèç‰πâËØçË°®ÔºåÂê¶ÂÆöËØçË°®                                               0.00        0.00   \n",
       "Áà¨Ëô´‰∏éÊú∫Âô®Â≠¶‰π†                                                      0.00        0.00   \n",
       "NLP Education Tools by YuZhen(www.yuzhenkeji.com)            0.00        0.00   \n",
       "NLP reading group at the University of Arizona               0.00        0.00   \n",
       "in progress                                                  0.00        0.00   \n",
       "Lectures for Udemy - INLP                                    0.00        0.00   \n",
       "A NLP library for Russian language                           0.03        0.00   \n",
       "Study E-Book(ComputerVision DeepLearning Machin...           0.00        0.00   \n",
       "Python implementation of TextRank for text docu...           0.00        0.00   \n",
       "üí´  Models for the spaCy Natural Language Proces...           0.03        0.00   \n",
       "\"End-To-End Memory Networks\" in Tensorflow                   0.00        0.00   \n",
       "Deprecated in favor of https://github.com/faceb...           0.00        0.01   \n",
       "A very brief introduction to Natural Language P...           0.02        0.00   \n",
       "Time-NLPÁöÑpython3ÁâàÊú¨ ‰∏≠ÊñáÊó∂Èó¥Ë°®ËææËØçËΩ¨Êç¢                                 0.00        0.00   \n",
       "A companion repository for the \"Writing code fo...           0.01        0.01   \n",
       "Bi-directional Attention Flow (BiDAF) network i...           0.00        0.01   \n",
       "                                                             0.00        0.00   \n",
       "Tensorflow Tutorial files and Implementations o...           0.01        0.01   \n",
       "\n",
       "                                                    deep_learning  \n",
       "scikit-learn: machine learning in Python                     0.00  \n",
       "Jupyter notebooks from the scikit-learn video s...           0.00  \n",
       "PySpark + Scikit-learn = Sparkit-learn                       0.00  \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                        0.00  \n",
       "Automated Machine Learning with scikit-learn                 0.00  \n",
       "Scikit-learn tutorial at SciPy2016                           0.00  \n",
       "Materials for my scikit-learn tutorial                       0.00  \n",
       "scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ                                    0.00  \n",
       "Source code for the \"Learning scikit-learn: Mac...           0.00  \n",
       "Scikit-Learn tutorial material for Scipy 2015                0.00  \n",
       "Simplified interface for TensorFlow (mimicking ...           0.02  \n",
       "Tutorial on scikit-learn and IPython for parall...           0.00  \n",
       "Scikit-learn integration package for Apache Spark            0.00  \n",
       "Machine Learning with Text in scikit-learn                   0.00  \n",
       "Hidden Markov Models in Python, with scikit-lea...           0.00  \n",
       "Materials for my Pycon 2015 scikit-learn tutorial.           0.00  \n",
       "Some sample IPython notebooks for scikit-learn               0.00  \n",
       "Dive into Machine Learning with Python Jupyter ...           0.00  \n",
       "Scikit-Learn, NLTK, Spacy, Gensim, Textblob and...           0.00  \n",
       "Julia implementation of the scikit-learn API                 0.00  \n",
       "A scikit-learn compatible neural network librar...           0.02  \n",
       "Scikit-learn compatible tools using theano                   0.18  \n",
       "Scikit-learn tutorials for the Scipy 2013 confe...           0.00  \n",
       "scikit-learn compatible projects                             0.00  \n",
       "Scikit-Learn tutorials                                       0.00  \n",
       "scikit-learn inspired API for CRFsuite                       0.00  \n",
       "Repository containing files for my PyCon 2014 s...           0.00  \n",
       "Applied Machine Learning in Python with scikit-...           0.00  \n",
       "Scikit-Learn Tutorial for PyData Seattle 2015                0.00  \n",
       "Scikit-learn style model finetuning for NLP                  0.02  \n",
       "...                                                           ...  \n",
       "Curated list of Linguistic Resources for doing ...           0.00  \n",
       "                                                             0.00  \n",
       "List of projects related to Natural Language Pr...           0.01  \n",
       "Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ                                                       0.00  \n",
       "NLP course at Chulalongkorn University                       0.00  \n",
       "Some frequently used NLP blocks I implemented                0.00  \n",
       "NLP Sandbox                                                  0.00  \n",
       "Vietnamese NLP Toolkit for Node                              0.00  \n",
       "Toy Python implementation of http://www-nlp.sta...           0.00  \n",
       "tensorflowÂÆûÊàòÁªÉ‰π†ÔºåÂåÖÊã¨Âº∫ÂåñÂ≠¶‰π†„ÄÅÊé®ËçêÁ≥ªÁªü„ÄÅnlpÁ≠â                              0.00  \n",
       "Deep Learning Chinese Word Segment                           0.00  \n",
       "NLPCC 2016 ÂæÆÂçöÂàÜËØçËØÑÊµãÈ°πÁõÆ                                          0.00  \n",
       "Âêå‰πâËØçË°®ÔºåÂèç‰πâËØçË°®ÔºåÂê¶ÂÆöËØçË°®                                               0.00  \n",
       "Áà¨Ëô´‰∏éÊú∫Âô®Â≠¶‰π†                                                      0.00  \n",
       "NLP Education Tools by YuZhen(www.yuzhenkeji.com)            0.00  \n",
       "NLP reading group at the University of Arizona               0.00  \n",
       "in progress                                                  0.00  \n",
       "Lectures for Udemy - INLP                                    0.00  \n",
       "A NLP library for Russian language                           0.00  \n",
       "Study E-Book(ComputerVision DeepLearning Machin...           0.00  \n",
       "Python implementation of TextRank for text docu...           0.01  \n",
       "üí´  Models for the spaCy Natural Language Proces...           0.01  \n",
       "\"End-To-End Memory Networks\" in Tensorflow                   0.03  \n",
       "Deprecated in favor of https://github.com/faceb...           0.00  \n",
       "A very brief introduction to Natural Language P...           0.00  \n",
       "Time-NLPÁöÑpython3ÁâàÊú¨ ‰∏≠ÊñáÊó∂Èó¥Ë°®ËææËØçËΩ¨Êç¢                                 0.00  \n",
       "A companion repository for the \"Writing code fo...           0.00  \n",
       "Bi-directional Attention Flow (BiDAF) network i...           0.02  \n",
       "                                                             0.00  \n",
       "Tensorflow Tutorial files and Implementations o...           0.03  \n",
       "\n",
       "[7014 rows x 8 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = pd.DataFrame(doc_topic.round(2),\n",
    "             index = ex_label,\n",
    "             columns = [\"machine_learning\",\"scikit_learn\",\"jupyter_notebook\",\"python_library\",\"nlp\",\"julia_package\", \"kubernetes\", \"deep_learning\"])\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:09:09.188489Z",
     "start_time": "2019-03-27T02:09:09.091660Z"
    }
   },
   "outputs": [],
   "source": [
    "h_cv = CountVectorizer(stop_words='english')\n",
    "h_cv_1 = h_cv.fit(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_cv_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:09:14.273748Z",
     "start_time": "2019-03-27T02:09:14.246256Z"
    }
   },
   "outputs": [],
   "source": [
    "# nmf_h=nmf_model.transform(h_cv_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:49:00.934953Z",
     "start_time": "2019-03-27T01:49:00.914129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scikit-learn: machine learning in Python',\n",
       " 'Jupyter notebooks from the scikit-learn video series',\n",
       " 'PySpark + Scikit-learn = Sparkit-learn',\n",
       " ':book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£',\n",
       " 'Automated Machine Learning with scikit-learn',\n",
       " 'Scikit-learn tutorial at SciPy2016',\n",
       " 'Materials for my scikit-learn tutorial',\n",
       " 'scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ',\n",
       " 'Source code for the \"Learning scikit-learn: Machine Learning in Python\"',\n",
       " 'Scikit-Learn tutorial material for Scipy 2015',\n",
       " 'Simplified interface for TensorFlow (mimicking Scikit Learn) for Deep Learning',\n",
       " 'Tutorial on scikit-learn and IPython for parallel machine learning',\n",
       " 'Scikit-learn integration package for Apache Spark',\n",
       " 'Machine Learning with Text in scikit-learn',\n",
       " 'Hidden Markov Models in Python, with scikit-learn like API',\n",
       " 'Materials for my Pycon 2015 scikit-learn tutorial.',\n",
       " 'Some sample IPython notebooks for scikit-learn',\n",
       " 'Dive into Machine Learning with Python Jupyter notebook and scikit-learn!',\n",
       " 'Scikit-Learn, NLTK, Spacy, Gensim, Textblob and more',\n",
       " 'Julia implementation of the scikit-learn API',\n",
       " 'A scikit-learn compatible neural network library that wraps pytorch',\n",
       " 'Scikit-learn compatible tools using theano',\n",
       " 'Scikit-learn tutorials for the Scipy 2013 conference',\n",
       " 'scikit-learn compatible projects',\n",
       " 'Scikit-Learn tutorials',\n",
       " 'scikit-learn inspired API for CRFsuite',\n",
       " 'Repository containing files for my PyCon 2014 scikit-learn tutorial.',\n",
       " 'Applied Machine Learning in Python with scikit-learn',\n",
       " 'Scikit-Learn Tutorial for PyData Seattle 2015',\n",
       " 'Scikit-learn style model finetuning for NLP',\n",
       " 'Using python and scikit-learn to make stock predictions',\n",
       " 'Lab for Linear and Logistic Regression, SciKit Learn',\n",
       " 'Genetic Programming in Python, with a scikit-learn inspired API',\n",
       " 'A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in python using Scikit-Learn and TensorFlow.',\n",
       " 'pandas, scikit-learn, xgboost and seaborn integration ',\n",
       " 'Python package for Bayesian Machine Learning with scikit-learn API',\n",
       " 'An introduction to implementing a number of scikit-learn classifiers, along with some data exploration',\n",
       " 'Use evolutionary algorithms instead of gridsearch in scikit-learn',\n",
       " 'Advanced Scikit-learn training session',\n",
       " 'Tutorials on Machine Learning with Scikit-Learn',\n",
       " 'Files for my scikit-learn tutorial at PyCon 2013',\n",
       " 'Flask API for training and predicting using scikit learn models',\n",
       " 'Scikit-learn website hosted by github',\n",
       " 'Machine learning with scikit-learn tutorial at PyData Chicago 2016',\n",
       " 'Stanford Machine Learning course exercises implemented with scikit-learn',\n",
       " 'Combines the ease of use of scikit-learn with the power of Theano/Lasagne',\n",
       " 'IPython notebooks and data an interactive scikit-learn tutorial.',\n",
       " 'Materials for class on machine learning/deep learning using scikit-learn, tensorflow and keras',\n",
       " 'A template for scikit-learn extensions',\n",
       " 'Deep neural networks without the learning cliff! Classifiers and regressors compatible with scikit-learn.',\n",
       " 'A garden for scikit-learn compatible trees',\n",
       " 'Materials for the \"Advanced Scikit-learn\" class in the afternoon',\n",
       " 'Python library for converting Scikit-Learn pipelines to PMML',\n",
       " 'An intuitive library to add plotting functionality to scikit-learn objects.',\n",
       " 'Code & Data for Introduction to Machine Learning with Scikit-Learn',\n",
       " 'Compiled Decision Trees for scikit-learn',\n",
       " 'Survival analysis built on top of scikit-learn',\n",
       " 'Pydata NYC 2014 Scikit Learn Tutorial',\n",
       " 'Confidence intervals for scikit-learn forest algorithms',\n",
       " 'A complete ML study path, focused on TensorFlow and Scikit-Learn',\n",
       " 'Abridged implementation of the official scikit-learn beginner tutorials',\n",
       " 'Porn images detector with python, tensorflow, scikit-learn and opencv.',\n",
       " 'Youtube tutorial associated content',\n",
       " 'Pydata Dallas 2015 Scikit-Learn Tutorial',\n",
       " 'Scipy 2017 scikit-learn tutorial by Alex Gramfort and Andreas Mueller',\n",
       " 'Implementation of research papers on Deep Learning+ NLP+ CV in Python using Keras, Tensorflow and Scikit Learn.',\n",
       " 'Positive and unlabeled learning wrappers for scikit-learn',\n",
       " 'Tutorial: Machine Learning with Text in scikit-learn',\n",
       " 'based on \"Hands-On Machine Learning with Scikit-Learn & TensorFlow\" (O\\'Reilly, Aurelien Geron)',\n",
       " 'Tutorial for astronomy data processing with scikit-learn',\n",
       " 'Relevance Vector Machine implementation using the scikit-learn API.',\n",
       " 'Mastering Machine Learning with scikit learn Second Edition, published by Packt',\n",
       " 'practical introduction to pandas and scikit-learn via Kaggle problems - Sept 2014',\n",
       " 'Semi-supervised learning frameworks for python, which allow fitting scikit-learn classifiers to partially labeled data',\n",
       " 'Transpile trained scikit-learn estimators to C, Java, JavaScript and others.',\n",
       " \"Hands-On Machine Learning with Scikit-Learn & TensorFlow (O'Reilly)\",\n",
       " 'Geo-Located Data: Extracting Patterns from Mobile Data using Scikit-Learn and Cassandra',\n",
       " 'scikit-learn wrappers for Python fastText.',\n",
       " 'Tutorial sobre scikit-learn completo',\n",
       " 'Âà©Áî®Scikit LearnÂØπÁßíÁ∫ßËÇ°Á•®Êï∞ÊçÆËøõË°åÂª∫Ê®°È¢ÑÊµã',\n",
       " 'A wine recommender system tutorial using Python technologies such as Django, Pandas, or Scikit-learn, and others such as Bootstrap.',\n",
       " 'Demonstrate how to approach a machine learning problem with the tools of scikit-learn.',\n",
       " 'Machine Learning and NLP: Text Classification using python, scikit-learn and NLTK',\n",
       " 'Scikit-learn Tutorial at EuroPython 2014',\n",
       " 'Advanced Machine Learning with Scikit-learn part I',\n",
       " 'Genetic feature selection module for scikit-learn',\n",
       " 'A scikit-learn based module for multi-label et. al. classification',\n",
       " 'testing scikit-learn Isolation Forest',\n",
       " 'Highly interpretable classifiers for scikit learn, producing easily understood decision rules instead of black box models',\n",
       " 'A Python implementation of Deep Belief Networks built upon NumPy and TensorFlow with scikit-learn compatibility',\n",
       " 'SciKit-Learn Laboratory (SKLL) makes it easy to run machine learning experiments.',\n",
       " 'Scikit-learn compatible estimation of general graphical models',\n",
       " 'Java library and command-line application for converting Scikit-Learn pipelines to PMML',\n",
       " 'Data science Python notebooks: Deep learning (TensorFlow, Theano, Caffe, Keras), scikit-learn, Kaggle, big data (Spark, Hadoop MapReduce, HDFS), matplotlib, pandas, NumPy, SciPy, Python essentials, AWS, and various command lines.',\n",
       " 'Tutorial on topic models in Python with scikit-learn',\n",
       " 'scikit-learn Cookbook Second Edition, published by Packt',\n",
       " 'Advanced Machine Learning with Scikit-learn part II',\n",
       " ' Scipy 2018 scikit-learn tutorial by Guillaume Lemaitre and Andreas Mueller ',\n",
       " 'handwritten number recognizer by scikit-learn',\n",
       " 'This repo contains simple machine learning examples using scikit-learn and Python.',\n",
       " 'REST web service for the true real-time scoring (<1 ms) of R, Scikit-Learn and Apache Spark models',\n",
       " 'topics Models extension for Mallet & scikit-learn',\n",
       " 'SigOpt wrappers for scikit-learn methods',\n",
       " 'Continuous benchmark suite for the scikit-learn project.',\n",
       " 'Scikit-learn like Labeled-LDA',\n",
       " ':nut_and_bolt: Materials for talk on scikit-learn',\n",
       " 'Intermediate Machine Learning with Scikit-learn, 4h interactive workshop',\n",
       " 'ONNXMLTools enables conversion of models to ONNX. Currently supports Keras, CoreML, LightGBM and Scikit-Learn',\n",
       " 'Python Data Science Handbook: full text in Jupyter Notebooks',\n",
       " 'MNIST digit classification with scikit-learn and Support Vector Machine (SVM) algorithm.',\n",
       " 'Machine Learning using Scikit-Learn',\n",
       " 'Spatial classification and regression using Scikit-learn and Rasterio ',\n",
       " 'scikit-learn-compatible estimators from Civis Analytics',\n",
       " 'Pandas Adapters For Scikit-Learn',\n",
       " 'A conda-smithy repository for scikit-learn.',\n",
       " '',\n",
       " \"An implementation of Caruana et al's Ensemble Selection algorithm in Python, based on scikit-learn\",\n",
       " 'One hour interactive training for ML with scikit-learn',\n",
       " 'Introduction to Scikit-Learn and Pandas',\n",
       " 'EuroScipy 2014 tutorial: Introduction to predictive analytics with pandas and scikit-learn',\n",
       " 'scikit-learn compatible implementation of stability selection.',\n",
       " 'Machine Learning using scikit-learn',\n",
       " 'A set of tools for creating and testing machine learning features, with a scikit-learn compatible API',\n",
       " 'Code to compute permutation and drop-column importances in Python scikit-learn random forests',\n",
       " 'A fast python scikit-learn text sentiment API server.',\n",
       " 'Machine Learning with Scikit-Learn (material for pydata Amsterdam 2016)',\n",
       " 'Fundamentals of Machine Learning with Scikit-Learn',\n",
       " \"npm wrapper for python's scikit-learn machine learning library.\",\n",
       " \"sentdex's scikit machine learning tutorial for investing\",\n",
       " 'MICE Imputation implementation using scikit learn.',\n",
       " 'Interactive SVM Explorer, using Dash and scikit-learn ',\n",
       " 'A scikit-learn compatible library for graph kernels',\n",
       " 'Jupyter notebooks for interactive scikit-learn workshop',\n",
       " 'Jupyter Notebook exercises for k-means clustering with Python 3 and scikit-learn',\n",
       " 'An implementation of some of the tools used by the winner of the box plots competition using scikit-learn.',\n",
       " 'PyParis tutorial on machine learning using scikit-learn',\n",
       " \"A Beginner's Guide to Machine Learning with Scikit-Learn\",\n",
       " 'scikit-learn model evaluation made easy: plots, tables and markdown reports.',\n",
       " 'Patsy Adaptors for Scikit-learn',\n",
       " 'gdbt implement by scikit-learn',\n",
       " 'Predicting Amsterdam house / real estate prices using Ordinary Least Squares-, XGBoost-, KNN-, Lasso-, Ridge-, Polynomial-, Random Forest-, and Neural Network MLP Regression (via scikit-learn)',\n",
       " ':book: [ËØë] Scikit-learn ÁßòÁ±ç',\n",
       " 'Scikit-learn compatible Locality Preserving Projections in Python',\n",
       " 'A series of Jupyter notebooks with Chinese comment that walk you through the fundamentals of Machine Learning and Deep Learning in python using Scikit-Learn and TensorFlow.',\n",
       " 'Implementations of some Deep Learning models using tensorflow with scikit-learn like APIs',\n",
       " 'Intro To Scikit Learn',\n",
       " 'Scikit learn inspired library for gpu-accelerated machine learning',\n",
       " 'IPython notebook for PyData SF 2014 tutorial: \"Gradient Boosted Regression Trees in scikit-learn\"',\n",
       " 'Performs nested cross-validation for scikit-learn classes using MPI for parallel computing.',\n",
       " 'Bro Analysis Tools (BAT):  Processing and analysis of Bro network data with Pandas, scikit-learn, and Spark',\n",
       " 'NYC scikit-learn sprint (Sep 2018)',\n",
       " \"Hierarchical classification module based on scikit-learn's interfaces\",\n",
       " \"Repository for my 'K-Means Clustering with Scikit-Learn' talk materials.\",\n",
       " 'scikit-learn cross validators for iterative stratification of multilabel data',\n",
       " 'Python machine learning package providing simple interoperability between ML.NET and scikit-learn components.',\n",
       " 'The \"Python Machine Learning (2nd edition)\" book code repository and info resource',\n",
       " 'A centralized repository to report scikit-learn model performance across a variety of parameter settings and data sets.',\n",
       " 'Following along with  Sentdex‚Äôs tutorial',\n",
       " 'Detailed notes and code to learn the basics of machine learning with scikit-learn.',\n",
       " 'scikit-learn course for 2017 NGCM Summer Academy',\n",
       " 'Teaching materials for pandas and scikit-learn ',\n",
       " 'Detecting Fake News with Scikit-Learn ( Machine Learning ) ',\n",
       " 'Metric learning algorithms in Python',\n",
       " 'Materials fort Strata NYC 2016 scikit-learn tutorial',\n",
       " 'Data Wrangling, EDA, Feature Engineering, Model Selection, Regression, Binary and Multi-class Classification (Python, scikit-learn) ',\n",
       " 'Machine Learning with scikit-learn for Safari Books Online, intermediate',\n",
       " 'Materials for a course on scikit-learn at ENSAE',\n",
       " 'Scikit-learn API toy wrapper for Regularized Greedy Forests',\n",
       " 'Sentiment Analysis of IMDB Movie Reviews using word2vec and scikit-learn',\n",
       " '',\n",
       " 'Breve tutorial sobre scikit-learn',\n",
       " 'Project management related documents for scikit-learn',\n",
       " 'Convert scikit-learn models and pipelines to ONNX',\n",
       " '‚ÄúHands-On Machine Learning with Scikit-Learn and TensorFlow‚Äù  Excerpt From: Aur√©lien G√©ron. ‚ÄúHands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems.‚Äù iBooks. ',\n",
       " 'My code from the Scikit-Learn Cookbook',\n",
       " 'A library that allows serialization of SciKit-Learn estimators into PMML',\n",
       " 'A scikit-learn-compatible Python implementation of ReBATE, a suite of Relief-based feature selection algorithms for Machine Learning.',\n",
       " 'Common library for serving TensorFlow, XGBoost and scikit-learn models in production.',\n",
       " 'Abstract interface of ScikitLearn.jl',\n",
       " 'Fuzzy machine learning algorithms implementing the scikit-learn interface.',\n",
       " 'Notebooks (and slides) for my PyData NYC 2014 tutorial on the more advanced features of scikit-learn.',\n",
       " 'Cookiecutter template for testing Python scikit-learn classifiers.',\n",
       " 'A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in Python using Scikit-Learn, Keras and TensorFlow 2.',\n",
       " 'A dataset and notebook for demonstrating the power and simplicity of using scikit-learn for machine learning.',\n",
       " 'Toolkit for building predictive workflows on the top of pandas and scikit-learn.',\n",
       " \"A multi-output/multi-label and stream data framework. Inspired by MOA and MEKA, following scikit-learn's philosophy.\",\n",
       " 'I used Machine Learning to make a Logistic Regression model using scikit-learn, pandas, numpy, seaborn and matplotlib to predict the results of FIFA 2018 World Cup.',\n",
       " '',\n",
       " 'Ê©üÂô®Â≠∏Áøí: Python',\n",
       " 'The \"Python Machine Learning (1st edition)\"  book code repository and info resource',\n",
       " 'Scikit-learn style cross-validation classes for time series data',\n",
       " '',\n",
       " 'Python implementations of the k-modes and k-prototypes clustering algorithms, for clustering categorical data',\n",
       " 'Introduction to scikit-learn and TPOT',\n",
       " 'Classification of spam messages with SVM-linear, SVM-rbf and Naive Bayes by scikit-learn',\n",
       " 'creating machine learning web services using scikit_learn',\n",
       " '',\n",
       " 'Material for Machine Learning Meetup \"Machine Learning with Scikit-learn\"',\n",
       " 'japanese scikit-learn tutorial',\n",
       " '',\n",
       " 'Multilayer Feed-Forward Neural Network predictive model implementations with TensorFlow and scikit-learn',\n",
       " 'Tools that make working with scikit-learn and pandas easier.',\n",
       " 'Published by Packt',\n",
       " \"Empirical dynamic modeling in scikit-learn's style\",\n",
       " \"Novice's attempt for Stock Prices Prediction & Portfolio Optimization using Machine Learning with Python & Scikit Learn\",\n",
       " \"ogrisel's utility extensions for scikit-learn\",\n",
       " 'A scikit-learn compatible library for anomaly detection',\n",
       " 'MILBoost and other boosting algorithms, compatible with scikit-learn',\n",
       " 'Solutions to kdd99 dataset with Decision tree and Neural network by scikit-learn',\n",
       " 'Common post-estimation tasks for scikit-learn',\n",
       " 'Estimating and plotting the decision boundary (decision surface) of machine learning classifiers in higher dimensions (scikit-learn compatible)',\n",
       " 'Deep reinforcement learning. In scikit-learn. In less than 50 effective lines.',\n",
       " 'A place for dash docsets. Includes scipy, numpy, pandas, scikit-learn, scikit-image,...',\n",
       " 'A simple example of python api for real time machine learning, using scikit-learn, Flask and Docker',\n",
       " \"Convergent Cross Mapping in Scikit Learn's style\",\n",
       " 'A scikit-learn compatible implementation of MCA',\n",
       " 'Framework for setting up predictive analytics services',\n",
       " 'Illustrating Pandas and Scikit learn with different examples',\n",
       " 'Active Learning for text classification using scikit-learn',\n",
       " 'Dask powered gridsearch and pipeline a la scikit-learn',\n",
       " 'scikit-learn addon to operate on set/\"group\"-based features',\n",
       " 'A general image classifier using Visual Bag of Words and SIFT, with OpenCV and scikit-learn',\n",
       " 'a django app to persist and retrieve scikit learn machine learning models',\n",
       " 'Code, Notebooks and Examples from Practical Business Python',\n",
       " '',\n",
       " 'Prototype Selection and Generation Toolbox based on scikit-learn',\n",
       " 'Ruby Scikit Learn',\n",
       " 'A clustering tutorial with scikit-learn for beginners.',\n",
       " 'Scikit-learn style estimator for Minimum Spanning Tree Clustering in Python',\n",
       " 'Code example to predict prices of Airbnb vacation rentals, using scikit-learn on Spark with spark-sklearn, on MapR.',\n",
       " 'Work in progress for eventual contribution to scikit-learn',\n",
       " 'An unsupervised image clustering algorithm that uses VGGNet for image transformation. Python, scikit-learn and tensorflow.',\n",
       " 'A conda-smithy repository for scikit-learn.',\n",
       " 'Python Cheat Sheet NumPy, Matplotlib',\n",
       " 'A django app as an interface to scikit-learn',\n",
       " 'Code for building a sentiment classifier using classic Scikit-learn and a modern TensorFlow classifier.',\n",
       " 'demo of scikit-learn pipelines',\n",
       " '‰ΩøÁî®PythonËøõË°åÊï∞ÊçÆÂàÜÊûêÂÆûÈ™åÂ∑•ÂÖ∑NumPy„ÄÅPandas„ÄÅMatplotlib„ÄÅScikit-learnÁöÑÂÖ•Èó®‰ªãÁªçÔºå‰ΩøÁî®IPython NotebookÊ†ºÂºè',\n",
       " 'Web page for NISL: NeuroImaging with scikit-learn',\n",
       " 'MLeap: Deploy Spark Pipelines to Production',\n",
       " 'Use Pandas DataFrame with scikit-learn Pipelines and Feature Unions',\n",
       " '',\n",
       " 'Python scripts using scikit-image and scikit-learn to cluster images.',\n",
       " 'A scikit learn based interface to facebook fasttext.',\n",
       " 'A couple projects using scikit-learn illustrating project decision making.',\n",
       " 'Support code for building and running Amazon SageMaker compatible Docker containers based on the open source framework Scikit-learn (http://scikit-learn.org/stable/)',\n",
       " 'ML Scikit-learn',\n",
       " 'PythonÊú∫Âô®Â≠¶‰π†ÔºåÊú∫Âô®Â≠¶‰π†ÂÖ•Èó®È¶ñÈÄâ„ÄÇ',\n",
       " 'DBN for Regression Problem using Theano, NumPy, and Scikit-learn',\n",
       " 'Training time estimation for scikit-learn algorithms',\n",
       " 'Trolling Detection PoC with NLTK and scikit-learn',\n",
       " 'simple Echo State Networks integrated with scikit-learn',\n",
       " 'Enhancement proposals for scikit-learn: structured discussions and rational for large additions and modifications',\n",
       " 'POC IDS anomaly detection engine built with iPython notebook, matplotlib, pandas, numpy, scikit-learn, d3.js, hyperloglog implementation, PYCON 2013 Intro and Advanced Machine Learning Tutorial Notebooks',\n",
       " 'Start writing machine learning code in just 10 hours ',\n",
       " \"Additional kernels that can be used with scikit-learn's Gaussian Process module\",\n",
       " 'An implementation of the SuperLearner algorithm in Python based on scikit-learn.',\n",
       " '',\n",
       " 'Mastering Machine Learning with scikit-learn',\n",
       " 'Probabilistic classification in PyTorch/TensorFlow/scikit-learn with Fenchel-Young losses',\n",
       " 'Hands-on NLP with NLTK and scikit-learn[video], published by Packt',\n",
       " 'A Machine Learning pipeline that performs hand localization and static-gesture recognition built using the scikit learn and scikit image libraries http://www.ssreehari.com/Sign-language-and-static-gesture-recgnition/',\n",
       " 'Machine Learning with Scikit-Learn and TensorFlow',\n",
       " 'Clustering analysis of one million tweets using scikit-learn, including basic benchmarking of various clustering algorithms',\n",
       " 'A web-based application for quick, scalable, and automated hyperparameter tuning and stacked ensembling in Python.',\n",
       " 'Talk on \"Tree models with Scikit-Learn: Great learners with little assumptions\" presented at PyPata Paris 2015',\n",
       " 'Machine Learning Tutorials in Python',\n",
       " 'Classifier for predicting user interests based on Twitter profile and using Python library scikit-learn.',\n",
       " \"A scikit-learn wrapper for the gensim package for easy usage through scikit-learn's Pipeline and GridSearchCV classes.\",\n",
       " 'An open source python framework for automated feature engineering',\n",
       " 'Material for the MASH course on introduction to scikit-learn',\n",
       " 'xarray-aware scikit-learn',\n",
       " 'Notebook demonstrating bag-of-words sentiment analysis of tweets in scikit-learn',\n",
       " 'Transform ML models into a native code (Java, C, Python, etc.) with zero dependencies',\n",
       " 'Slides and presentation material for my talk about scikit-learn at PyCon Argentina 2013',\n",
       " 'Helpers for constructing scikit-learn grid search',\n",
       " '',\n",
       " 'Materials for the workshop Advanced Text Analysis with SpaCy and Scikit-Learn, given at NYU during NYCDH Week 2017, and at PyData NYC in Nov. 2017.',\n",
       " 'Introduction to applying machine learning with the scikit-learn Python library',\n",
       " 'Scikit-learn compatible implementations of the Random Rotation Ensemble idea of (Blaser & Fryzlewicz, 2016)',\n",
       " 'Apple CoreML example with scikit-learn',\n",
       " 'Cookiecutter template for testing Python scikit-learn regression learners.',\n",
       " '',\n",
       " 'PythonÔºÜÊ©üÊ¢∞Â≠¶Áøí„É©„Ç§„Éñ„É©„É™ scikit-learn „ÅÆ‰Ωø„ÅÑÊñπ„ÅÆÁ∑¥Áøí„Ç≥„Éº„ÉâÈõÜ„ÄÇÊ©üÊ¢∞Â≠¶Áøí„ÅÆÁêÜË´ñËß£Ë™¨‰ªò„Åç',\n",
       " '',\n",
       " 'A introductory tutorial on scikit-learn with the focus on NLP.',\n",
       " 'Visual analysis and diagnostic tools to facilitate machine learning model selection.',\n",
       " 'Home of the PipeGraph extension to Scikit-Learn',\n",
       " 'Advanced Machine Learning Video Course by Andres Muller ',\n",
       " 'Brand disambiguator for tweets to differentiate e.g. Orange vs orange (brand vs foodstuff), using NLTK and scikit-learn',\n",
       " 'Breast Cancer Classification with Scikit Learn',\n",
       " 'Scikit-Learn GUI',\n",
       " 'Algorithmically counting cell colonies in pictures of agar plates using OpenCV and scikit-learn',\n",
       " 'A k-means variation that produces clusters of the same size utilizing the scikit-learn API and related utilities',\n",
       " 'Introduction to Pandas, Scikit-Learn and Keras',\n",
       " 'Email clustering with machine learning',\n",
       " 'A web.py service for interacting with scikit-learn',\n",
       " 'Parallel implementation of Stochastic Gradient Descent using SciKit-Learn library in Python.',\n",
       " 'Hands-On Machine Learning with Python and Scikit-Learn, published by Packt',\n",
       " '',\n",
       " 'Materials for Strata Singapore \"Machine learning In Python with scikit-learn\" tutorial.',\n",
       " 'Develop and apply Machine Learning techniques using two of the most popular frameworks',\n",
       " 'Context-based similar documents with gensim and scikit-learn',\n",
       " 'A collection of Machine Learning algorithms written from sctrach.',\n",
       " 'Build an accurate sentiment model using Python with scikit-learn',\n",
       " 'Some scikit-learn-esque wrappers for statsmodels GLM',\n",
       " 'Scikit-learn-compatible datasets',\n",
       " 'Initially for DSL meetup',\n",
       " 'notebooks with example for machine learning examples',\n",
       " 'PyData Boston 2013 talks: \"Intro to scikit-learn\" & \"Realtime Predictive Analytics: Using scikit-learn and RabbitMQ\"',\n",
       " '',\n",
       " 'Denoising Autoencoder wrapper (from Theano) to sklearn (scikit learn)',\n",
       " 'Fast and memory-efficient clustering ',\n",
       " 'Detecting Road Features: identifying lane and vehicles boundaries in a video.',\n",
       " '',\n",
       " 'Pancake is a Python package which provides a simple API to stack scikit-learn models.',\n",
       " 'A minimal benchmark for scalability, speed and accuracy of commonly used open source implementations (R packages, Python scikit-learn, H2O, xgboost, Spark MLlib etc.) of the top machine learning algorithms for binary classification (random forests, gradient boosted trees, deep neural networks etc.).',\n",
       " 'A library for debugging/inspecting machine learning classifiers and explaining their predictions',\n",
       " 'A pattern focusing on how to use scikit learn and python in Watson Studio to predict opioid prescribers based off of a 2014 kaggle dataset.',\n",
       " 'ipython flask scikit-learn',\n",
       " 'Experimenting with RBMs using scikit-learn on MNIST and simulating a DBN using Keras.',\n",
       " 'Machine learning in Matlab using scikit-learn syntax',\n",
       " 'Notebook comparing scikit-learn and Spark ML for building Machine Learning Pipelines',\n",
       " 'Real-World Machine Learning Projects with Scikit-Learn [Video], Published by Packt',\n",
       " 'A collection of tools that extend the scikit-learn functionality.',\n",
       " ' Soccer Matches Predictor using Machine Learning',\n",
       " 'Predicting Forex Future Price with Machine Learning',\n",
       " 'A collection of supervised learning models based on shallow neural network approaches (e.g., word2vec and fastText) with some additional exclusive features. Written in Python and fully compatible with Scikit-learn.',\n",
       " 'Emotion Detection & Classification of Tweets Using Streaming APIs. [NLTK] [Scikit Learn] [Twitter Streaming API] [Bing API]',\n",
       " 'Cheat sheets for Numpy, Pandas, SQL, Scikit Learn',\n",
       " \"Book Hands on Machine Learning with Scikit-Learn and Tensorflow from O'reilly - Geron\",\n",
       " 'Notebooks to learn data science - Videos https://www.edyoda.com/resources/videolisting/1416/',\n",
       " 'An implementation of the Co-Training semi-supervised learning technique from (Blue, Mitchell 1998) that is meant to work well with scikit-learn classifiers.',\n",
       " 'practical machine learning with Scikit-learn',\n",
       " 'Titanic assignment on Kaggle competition',\n",
       " 'How to deploy serverless Machine Learning Microservice with AWS Lambda,  API Gateway and\\xa0scikit-learn :moneybag: :globe_with_meridians: :zap:',\n",
       " 'A Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming.',\n",
       " 'Arquivos das aulas de Machine Leaning em Portugu√™s (python + scikit-learn - https://www.youtube.com/playlist?list=PL4OAe-tL47sb3xdFBVXs2w1BA2LRN5JU2_)',\n",
       " 'pymc-learn: Practical probabilistic machine learning in Python ',\n",
       " 'REST API (and possible UI) for Machine Learning workflows',\n",
       " 'There are plenty of courses and tutorials that can help you learn Scikit-Learn from scratch, you can use this workflow to solve other real problems and use it as a template to deal with machine learning problems.',\n",
       " 'Advanced MachineLearning with scikit-learn',\n",
       " 'Plotting tools for scikit learn',\n",
       " 'Using Scikit-learn, machine learning library for the Python programming language.',\n",
       " 'Introduction to python, numpy, scikit-learn',\n",
       " 'Open Neural Network Exchange',\n",
       " 'Machine learning with scikit-learn and tensorflow for node-red.',\n",
       " 'The \"citizen journalists\" in the social media produce the content. This library uses Scikit-Learn and Spark MLlib to analyze the emotional sentiment of the text data. ',\n",
       " 'Introduction to Statistical Learning with RÏùÑ PythonÏúºÎ°ú ',\n",
       " \"Automated animation for scikit-learn's t-sne algorithm\",\n",
       " 'Predicting stock prices from Yahoo stock screener using scikit-learn and sending the predicitons via smtplib to a phone number. ',\n",
       " 'Collection of scripts for visualizing high dimensional data with scikit-learn and bh_tsne',\n",
       " 'scikit-learn Â≠¶‰π†Á¨îËÆ∞',\n",
       " 'Pretrained VGG-16 network as feature extractor for Object Recognition (Python, Keras, Scikit-Learn)',\n",
       " 'Create ensembles of machine learning models from scikit-learn, caret, and julia',\n",
       " \"Explore machine learning models. Leveraging scikit-learn's models and exposing their behaviour through API\",\n",
       " 'Slides and materials for workshop on \"Two views on regression with PyMC3 and scikit-learn\"',\n",
       " '',\n",
       " 'Benchmark suite for scikit-learn performances',\n",
       " 'A repository to try out Supervised Learning algorithms in Machine Learning',\n",
       " 'A quick and dirty Kaggle competition submission showcasing some of what Scikit-learn can do',\n",
       " 'A command-line tool to develop advanced text classifiers using SciKit-Learn.',\n",
       " \"'Deploying machine learning models with a Flask API' tutorial, written for HyperionDev\",\n",
       " 'Cookiecutter Starter App for Building API with Scikit-learn models and Tornado Web Framework',\n",
       " 'A consolidated package of small extensions to scikit-learn',\n",
       " 'PyMTL (Python library for Multi-task learning) is a Python module implementing a Multi-task learning framework built on top of scikit-learn, SciPy and NumPy.',\n",
       " 'Cookiecutter template for testing Python scikit-learn clustering learners.',\n",
       " 'AiLearning: Êú∫Âô®Â≠¶‰π† - MachineLearning - ML„ÄÅÊ∑±Â∫¶Â≠¶‰π† - DeepLearning - DL„ÄÅËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ NLP',\n",
       " 'Quite Practical and Far from any Theoretical Concepts- Learn python, Numpy, Pandas, Matplotlib, Seaborn, Scikit-learn ',\n",
       " 'Machine learning algorithm code samples',\n",
       " 'Introducci√≥n a scikit-learn',\n",
       " 'Some DataScience Test with docker + python + SciKit-learn',\n",
       " 'A stacked generalization framework. Built on top of scikit learn',\n",
       " ':mortar_board: Jupyter notebooks from UFC data science course',\n",
       " '',\n",
       " 'Small scale machine learning projects to understand the core concepts',\n",
       " 'PyData 2014 Know Thy Neighbor: Scikit-Learn and kNN Algorithm Tutorial and PyCon 2014 Talk',\n",
       " 'https://www.kaggle.com/c/data-science-london-scikit-learn',\n",
       " 'Exercises for hierarchical clustering with Python 3 and scipy as Jupyter Notebooks',\n",
       " 'scikit-learn like interface to chainer',\n",
       " 'scikit-learn inspired API for CRFsuite',\n",
       " 'The project aims at building a machine learning model that will be able to classify the various hand gestures used for fingerspelling in sign language. In this user independent model, classification machine learning algorithms are trained using a set of image data and testing is done. Various machine learning algorithms are applied on the datasets, including Convolutional Neural Network (CNN).',\n",
       " 'Portfolio of data science projects completed by me for academic, self learning, and hobby purposes.',\n",
       " 'Predicting Google‚Äôs stock price using regression',\n",
       " 'A feature extractor based on Python 3, Tensorflow and Scikit-learn created in order to improve the accuracy of SVM to classify MNIST dataset fast and with more accuracy.',\n",
       " 'Machine Learning plugin for Rhino\\\\grasshopper based on Python\\\\scikit-learn module.',\n",
       " 'Introductory presentation on using scikit learn in Jupyter',\n",
       " 'Landing page for scikit learn and nilearn tutorials, originally curated for MAIN 2018 conference',\n",
       " 'Simplified tree-based classifier and regressor for interpretable machine learning (scikit-learn compatible)',\n",
       " 'Datasets and solutions for the Programming Assignments for the Microsoft DAT210X course, EdX, July-August 2016.',\n",
       " 'Active semi-supervised clustering algorithms for scikit-learn',\n",
       " 'Understanding emotions with Neural Networks (Python, Scikit-Learn, Keras) and the Ravdess dataset: 95% accuracy on the training set and 92% on the test set.',\n",
       " 'Plant phenology models in python with a scikit-learn inspired API',\n",
       " 'Conjunto de scripts para treinar um Sistema de Recomenda√ß√£o H√≠brido baseado nos algoritmos do scikit-learn',\n",
       " 'an improved scikit-learn interface for xgboost',\n",
       " 'A modular active learning framework for Python3',\n",
       " 'Machine Learning tutorial with scikit-learn',\n",
       " 'All my submissions for Kaggle contests that I have been, and going to be participating.',\n",
       " 'Simple Churn Prediction examples using different Python frameworks including Tensorflow, Skflow, Scikit-learn and PySpark',\n",
       " 'Python/Pandas/Scikit-learn utilities and wrappers for analyzing Fitbit files',\n",
       " 'A simple example of how to solve Kaggle\\'s \"Titanic: Machine Learning from Disaster\" challenge using Python and scikit-learn',\n",
       " 'PyConUK 2016 talk - Using Machine Learning to solve a classification problem with scikit-learn - a practical walkthrough',\n",
       " 'iPython + scikit-learn for machine learning.',\n",
       " 'Open Machine Learning Course',\n",
       " '',\n",
       " 'We hope more Chinese could know about this machine learning package scikit-learn',\n",
       " 'Credit Risk analysis by using Python and ML',\n",
       " 'Experimental work for using IPython.parallel with scikit-learn',\n",
       " '',\n",
       " 'Helpful tools for building feature extraction pipelines with scikit-learn',\n",
       " 'An ipython notebook to demonstrate scikit learn & keras; for Machine Learning Fall 2017',\n",
       " 'Extreme learning machine implemented by python3 with scikit-learn interface',\n",
       " 'Python implementation of miSVM, built on top of Scikit-Learn.',\n",
       " 'A machine learning project in Python using scikit-learn.',\n",
       " 'A basic introduction to machine learning (one day training).',\n",
       " 'Notes from scikit-learn - a Python-based machine learning library.',\n",
       " 'Tutorial \"An introduction to Machine Learning with Scikit-Learn\", presented at CERN',\n",
       " 'Scikit-learn compatible sequence classifier',\n",
       " 'Code for training and test machine learning classifiers on MIT-BIH Arrhyhtmia database',\n",
       " 'Python for chemoinformatics',\n",
       " 'Machine Learning in .NET Core.',\n",
       " 'I gave a talk introducing scikit-learn at PyData1 (https://www.facebook.com/events/994351117258134/) in Singapore on 15th January 2015. This repository contains my presentation slides and the iPython notebooks I used to give some examples.',\n",
       " 'sklearn presentation for THW',\n",
       " 'This is a sandbox repo to test out various scikit-learn features that will be used in the development of the iterative Random Forests (iRF) implementation. It will eventually be deprecated once the scikit-learn iRF implementation is complete.',\n",
       " 'Simple implementation of sar target recognition using machine learning methods',\n",
       " \"Scikit-Learn's linear regression extended with p-values.\",\n",
       " 'Stock Price Movement Prediction using Mahout and Pydoop+Scikit-learn',\n",
       " 'Core ML verson of Scikit Learn Linear Regression Examples',\n",
       " 'Learn how to process, classify, cluster, summarize, understand syntax, semantics and sentiment of text data with the power of Python! This repository contains code and datasets used in my book, \"Text Analytics with Python\" published by Apress/Springer. ',\n",
       " 'Implementation of a BnsTransformer and BnsVectorizer for use with Scikit-Learn and classification of text documents.',\n",
       " 'Malicious URL detector using keras recurrent networks and scikit-learn classifiers',\n",
       " 'Describe your scikit-learn estimators for posterity!',\n",
       " 'Hands-on Introduction to Machine Learning with Python, Pandas, Matplotlib and Scikit-Learn',\n",
       " 'A simple implementation to regression problems using Python 2.7, scikit-learn and XGBoost',\n",
       " 'This repositories contain various Machine Learning examples done with Python.',\n",
       " 'Stuff for my Pycon talk \"Realtime predictive analytics using scikit-learn & RabbitMQ\" https://us.pycon.org/2014/schedule/presentation/224/',\n",
       " 'This repository contains ClassificaIO, a Python package that provides a graphical user interface (GUI) for machine learning algorithms from scikit-learn.',\n",
       " 'Shows how to write a simple data contest entry for Kaggle, using scikit-learn for machine learning algorithms',\n",
       " \"Digit Recognition with scikit-learn's Bernoulli RBM and Logistic Classifier\",\n",
       " '',\n",
       " 'Proteomic Data Analysis with Python (pandas, scikit-learn, numpy, scipy)',\n",
       " 'Collection of classification examples with scikit-learn',\n",
       " 'Fraud Detection model build with Python (numpy, scipy, pandas, scikit-learn), based on anonymized credit card transactions. The dataset is publicly available here: https://clouda-datasets.s3.amazonaws.com/creditcard.csv.zip',\n",
       " 'My dataquest project solutions',\n",
       " 'A scikit-learn style implementation of NBSVM',\n",
       " 'A library for machine learning research on motion capture data ',\n",
       " 'This package aims to compute conditional quantiles using random regression forests from the scikit-learn library.',\n",
       " 'scikit-learn friendly Implementation of Neural Nets. Will also try to reproduce results in this area',\n",
       " 'Python3 scikit-learn with Jupyter docker image based on alpine ',\n",
       " 'Node.js wrapper of scikit-learn',\n",
       " 'a face recognition system based on convolutional neural network.',\n",
       " '',\n",
       " 'Joint Automated Repository for Various Integrated Simulations (JARVIS) is an integrated framework for computational science using density functional theory, classical force-field/molecular dynamics and machine-learning.  ',\n",
       " '‰ΩøÁî®scikit-learnËøõË°åÊñáÊú¨ÂàÜÁ±ª',\n",
       " 'Lecture notes and excercises for data analysis in python. Includes introduction to Python, Numpy, Scipy, Scikit-Learn, SimpleCV. Topics Supervised/Unsupervised Learning, Signal Analysis, Image Analysis, Text and Web-Media Analysis',\n",
       " 'Graph-Based Semi-Supervised Learning, with scikit-learn',\n",
       " \"Using indico's imagefeatures API and scikit-learn to produce a solve an image classification task\",\n",
       " '',\n",
       " 'Unofficial implementation of  Reframe Visualization in Keras / Scikit-learn',\n",
       " 'An Introduction to Natural Language Processing in Python with NLTK and Scikit-learn',\n",
       " 'Recipes for scikits.learn',\n",
       " 'Materials for the course of machine learning at Imperial College organized by Yandex SDA',\n",
       " 'Dockerfile utilizing flask to host a scikit-learn image recognition model',\n",
       " '',\n",
       " 'This repository subpart contains codes for various machine learning models. Mostly using Python, Scikit learn',\n",
       " 'Text classification using Doc2Vec',\n",
       " 'Sample Flask App using Scikit-Learn Model',\n",
       " 'UBC Scientific Software Seminar: Hands-On Machine Learning with Scikit-Learn & Tensorflow',\n",
       " '‰ΩøÁî®MnistÊï∞ÊçÆÈõÜÊµãËØïscikit-learnÁöÑÊú∫Âô®Â≠¶‰π†Á±ªÂ∫ì',\n",
       " 'A version of scikit-learn that includes implementations of Wager & Athey and Scott Powers causal forests.  ',\n",
       " 'DeltaTfidfVectorizer for scikit-learn',\n",
       " 'Curso de introducci√≥n al an√°lisis y modelado de datos con Python (pandas y scikit-learn) - https://cacheme.org/curso-introduccion-datos-python/',\n",
       " 'SciKit-Learn documentation',\n",
       " \"A module for allowing the use of multiple metric functions in scikit's cross_val_score\",\n",
       " 'Classify capitals to which continent they belong',\n",
       " \"General Assembly's 2015 Data Science course in Washington, DC\",\n",
       " 'A comprehensive list of Deep Learning / Artificial Intelligence and Machine Learning tutorials - rapidly expanding into areas of AI/Deep Learning / Machine Vision / NLP and industry specific areas such as Automotives, Retail, Pharma, Medicine, Healthcare by Tarry Singh until at-least 2020 until he finishes his Ph.D. (which might end up being inter-stellar cosmic networks! Who knows! üòÄ)',\n",
       " 'An anytime implementation of scikit-learn GridSearchCV',\n",
       " 'A wrapper class for the scikit-learn BaseEstimator class that implements both the astroML and Bovy et al. (2011) XDGMM methods.',\n",
       " 'Published by Packt',\n",
       " 'Published by Packt',\n",
       " 'Scipy 2017 scikit-learn tutorial by Alex Gramfort and Andreas Mueller',\n",
       " 'Machine Learning for High Energy Physics.',\n",
       " 'scikit-learn wrapper for Ruby',\n",
       " '50% faster, 50% less RAM Machine Learning. Numba rewritten Sklearn. SVD, NNMF, PCA, LinearReg, RidgeReg, Randomized, Truncated SVD/PCA, CSR Matrices all 50+% faster',\n",
       " 'Implementation of https://arxiv.org/pdf/1702.08835.pdf in scikit-learn',\n",
       " 'Clustering routines for the unit sphere',\n",
       " 'Collection of scripts and tools related to machine learning',\n",
       " 'Samples and Tools for Windows ML.',\n",
       " 'Face/Beauty Rating with both the traditional ML approaches and Convolutional Neural Network Approach',\n",
       " 'RSMTool is a python package for facilitating research on building and evaluating automated scoring models.',\n",
       " 'Machine Learning Serving cluster',\n",
       " 'Aprendizado de m√°quina com Python e scikit-learn',\n",
       " 'Classifier for the iris dataset using scikit-learn',\n",
       " 'An√°lise de posicionamento pol√≠tico utilizando a API de Dados Abertos da C√¢mara dos Deputados',\n",
       " 'Tutorial on Pipelines and Gridsearch in scikit-learn',\n",
       " 'Master the essential skills needed to recognize and solve complex real-world problems with Machine Learning and Deep Learning by leveraging the highly popular Python Machine Learning Eco-system.',\n",
       " 'Machine Learning and Reinforcement Learning in Finance New York University Tandon School of Engineering',\n",
       " 'A Natural Language Intent classifier in Python using NLTK and Scikit-Learn',\n",
       " 'Introduction to Machine Learning',\n",
       " 'Examples of ML using the  Scikit-Learn Library using Python in Jupyter Notebooks',\n",
       " 'Visualizer for deep learning and machine learning models',\n",
       " 'Working through the scikit-learn tutorials',\n",
       " 'NOTE: skutil is now deprecated. See its sister project: https://github.com/tgsmith61591/skoot. Original description: A set of scikit-learn and h2o extension classes (as well as caret classes for python). See more here: https://tgsmith61591.github.io/skutil',\n",
       " 'Find the best model, using random hyperparameter optimization, using scikit-learn',\n",
       " 'this is post-prune tree code for scikit-learn 0.18.0',\n",
       " 'Stacking methods in scikit-learn',\n",
       " 'Emotions recognition from audio signal using OpenSmile, PCA and set of classifiers from Scikit-learn library',\n",
       " 'Python and Lua tutorials',\n",
       " 'A guide to scikit-learn compatible nearest neighbors classification using the recently introduced word mover‚Äôs distance (WMD)',\n",
       " 'A guide to scikit-learn compatible nearest neighbors classification using the recently introduced word mover‚Äôs distance (WMD)',\n",
       " 'MRMR implemented in Cython for scikit-learn',\n",
       " 'Jet clustering with scikit-learn',\n",
       " '',\n",
       " 'Build your first ML app with Scikit Learn',\n",
       " 'Machine Learning with Scikit-learn',\n",
       " 'A Priori and Recommender Systems with scikit-learn',\n",
       " 'Regression and Classification model comparison wrapper around scikit-learn',\n",
       " 'Samples of serving various ML models in Google Cloud Machine Learning Engine using Tensorflow, Keras and Scikit-Learn, tutorials on how to use the estimator APIs to perform various ML tasks[WIP]',\n",
       " '',\n",
       " 'Training SVM classifier to recognize people expressions (emotions) on Fer2013 dataset',\n",
       " 'A simple machine learning powered captcha breaker',\n",
       " 'Destructive deep learning estimators and functions that are compatible with scikit-learn.',\n",
       " 'Classify newspaper articles using scikit-learn and scraping test articles from several online newspapers like BBC, The Guardian, Telegraph and Reuters.',\n",
       " 'Hyperparameter optimization for machine learning pipelines',\n",
       " 'Computer vision sabbatical study materials',\n",
       " ' RapidML is a smart Python framework for rapidly prototyping Machine Learning APIs for the Web!',\n",
       " 'Tutorial del Scikit-learn para el Aula de Software Libre',\n",
       " 'Machine Learning examples adapted from Hastie, Tibshirani, and Friedman book',\n",
       " 'Practice and tutorial-style notebooks  covering wide variety of machine learning techniques',\n",
       " '',\n",
       " 'Samples for NimbusML, a Python machine learning package providing simple interoperability between ML.NET and scikit-learn components.',\n",
       " \"This is the source code for the 'Natural Language Processing for Text Classification with NLTK & Scikit-learn' video \",\n",
       " 'Questions, Help, and Issues for Comet ML',\n",
       " \"Code for determining optimal number of clusters for K-means algorithm using the 'elbow criterion'\",\n",
       " 'Getting meaning out of scientific articles using nltk/gensim and scikit-learn',\n",
       " 'Tutorial on deploying machine learning models to production',\n",
       " 'Scikit-learn compatible wrapper of the Random Bits Forest program written by (Wang et al., 2016)',\n",
       " 'Credit Card Fraud Detection using ML: IEEE style paper + Jupyter Notebook',\n",
       " 'Projects using Scikit-Learn for Supervised and Unsupervised Machine Learning.',\n",
       " 'AutoML library for Accurat, based on AutoKeras and Scikit-Learn.',\n",
       " 'ü§ìüîÆüî¨ Emoji prediction from a text using machine learning',\n",
       " ':book: [ËØë] SciPyCon 2018 Sklearn ÊïôÁ®ã',\n",
       " \"Bug Triager using scikit learn cuz I'm laaaaaaazy.\",\n",
       " 'Scikit-learn compatible Kernel Entropy Component Analysis in Python ',\n",
       " 'My code and solutions related to the book Hands-on Machine Learning with Scikit-Learn and TensorFlow.',\n",
       " 'Exercise files for Python SciKit Learn Machine Learning Training',\n",
       " 'brief introduction to Python for machine learning',\n",
       " 'Feature engineering toolkit, designed to work with scikit-learn.',\n",
       " 'Using Google BigQuery to analyze and extend scikit learn',\n",
       " 'Automated machine learning for analytics & production',\n",
       " 'Interactive Linear Regression Explorer, using Dash + scikit-learn',\n",
       " 'scikit-learn„ÅÆ„ÉÅ„Éº„Éà„Ç∑„Éº„Éà„Çí‰ΩúÊàê„Åó„Åæ„Åó„Çá„ÅÜ',\n",
       " 'Assignments of Coursera Machine Learning Specialization using Scikit-Learn, Pandas, Numpy and Scipy',\n",
       " 'Analysis and preprocessing of the kdd cup 99 dataset using python and scikit-learn',\n",
       " 'Various scikit-learn extensions',\n",
       " 'Online version of the merged Scikit statistical learning tutorial',\n",
       " 'Êú∫Âô®Â≠¶‰π†Á¨îËÆ∞ÔºåÊù•Ê∫ê‰∫éÔºöÊùéËà™ÁöÑ„ÄäÁªüËÆ°Â≠¶‰π†ÊñπÊ≥ï„Äã Âë®ÂøóÂçéÁöÑ„ÄäÊú∫Âô®Â≠¶‰π†„Äã Peter Harrington ÁöÑ„ÄäÊú∫Âô®Â≠¶‰π†ÂÆûÊàò„Äã ‰ª•ÂèäPythonÁöÑ  Scikit-Learn ÂºÄÊ∫êÂ∫ì„ÄÇ',\n",
       " 'Scikit-learn style implementation of TrAdaBoost algorithm',\n",
       " 'Scikit learn model persistence using MsgPack',\n",
       " 'Sklearn (Scikit-learn) like interface for Chainer',\n",
       " 'A simple logistic regression implementation using pandas and scikit learn',\n",
       " 'scikit-learn gradient-boosting-model interactions',\n",
       " 'Custom scikit-learn estimators and transfomers',\n",
       " 'Introduction to clustering with Scikit-learn ',\n",
       " 'sklearn talk for dataphilly/phillypug based on github.com/jakevdp/sklearn_pycon2013 and http://scikit-learn.github.io/scikit-learn-tutorial/general_concepts.html',\n",
       " 'Introducci√≥n a Pandas y Scikit-Learn',\n",
       " 'Ejemplo clasificaci√≥n de textos con scikit-learn',\n",
       " 'Assisting library for the ML4CV tutorial based on scikit-learn.',\n",
       " 'Face tracking and categorization based on MDP, scikit-learn, and cv2.  Currently implements age, gender, smile, and glasses.',\n",
       " 'Face tracking and categorization based on MDP, scikit-learn, and cv2.  Currently implements age, gender, smile, and glasses.',\n",
       " 'A merger of tutorials, talks, and training material on Dask (mostly) and Scikit-Learn (a little bit)',\n",
       " 'MHacks 9 Project. Uses NLTK and Scikit Learn to determine whether or not a news article is fake news.',\n",
       " 'Automated machine learning- just give it a data file! Check out the production-ready version of this project at ClimbsRocks/auto_ml',\n",
       " 'A basic scikit-learn compatible neural network library for Python 3',\n",
       " 'scikit-learnÈ†òÂüüÊé¢Á¥¢ & KaggleÂØ¶Êà∞',\n",
       " 'Machine Learning by Examples using Google Colab and Scikit-Learn, Keras, Tensorflow.',\n",
       " 'Project work from the Udacity machine learning nanodegree encompassing general techniques for supervised,unsupervised and reinforcement learning',\n",
       " 'ADAM - A Question Answering System. Inspired from IBM Watson',\n",
       " 'Connecting scikit-learn and xarray',\n",
       " 'Classifying the physical activities performed by a user based on accelerometer and gyroscope sensor data collected by a smartphone in the user‚Äôs pocket. The activities to be classified are: Standing, Sitting, Stairsup, StairsDown, Walking and Cycling.',\n",
       " 'IPython widgets, interactive plots, interactive machine learning',\n",
       " \"Heard of Machine Learning? What's it all about? ü§∑üèæ\\u200d‚ôÄÔ∏è   This repo will contain tutorials on different models required to give you an intro into the world of Machine Learning\",\n",
       " 'Creating Predictions for Numerai with Keras and scikit-learn',\n",
       " 'Example PyMC3 project for performing Bayesian data analysis using a probabilistic programming approach to machine learning.',\n",
       " 'Combination of Keras CNN with Scikit-learn classifiers.',\n",
       " \"Article recommendation system for pelican based on post similarity calculated using NLTK and scikit-learn's TFIDF vectorizer.\",\n",
       " 'MATLAB Wrapper for scikit-learn',\n",
       " 'Python library for computer vision based on scikit-image and scikit-learn',\n",
       " 'Using scikit-learn for classification',\n",
       " 'Code and notes from using scikit-learn on the MNIST digits dataset. For more of a narrative on this project, see the article:',\n",
       " 'scikit-learn compatibel multi-label classification',\n",
       " 'NYC scikit-learn sprint (March 2017)',\n",
       " 'Python implementation of GMMs and HMMs.  DEPRECATED: This package has been incorporated into scikits-learn.  Check there for updates.',\n",
       " 'Feature Rich Encoding for Python Scikit Learn',\n",
       " 'Solution of the Titanic Kaggle competition ',\n",
       " ':crown: Python factor analysis library (PCA, CA, MCA, MFA, FAMD)',\n",
       " 'Recognizing human activity using multiple wearable accelerometer sensors placed at different body positions.',\n",
       " ' Euclidean Distance Computation in Python for 4x-100x+ speedups over SciPy and scikit-learn. Also leverages GPU for better performance on specific datasets.',\n",
       " 'This repository contains all the code and dataset used in my blog series: Minimal Data Science',\n",
       " 'An integration of pandas dataframes with scikit learn.',\n",
       " 'A repository to share Scikit Learn Machine Learning algorithms and small snippets with the world',\n",
       " 'The HMM-code from scikit-learn will live here for now as it will be removed from the scikit-learn project in version 0.17',\n",
       " 'scikit-learn study by the book which is \"introduction to Machine learning with python\"',\n",
       " 'Scikit-Learn k√ºt√ºphanesi ile basit bir duygu analizi √∂rneƒüi',\n",
       " 'Clasificador de flores mediante aprendizaje supervisado',\n",
       " 'My notes (and code) on Machine Learning using Python, Scikit-Learn, TensorFlow, Keras.',\n",
       " 'Code for my Scikit-learn, and Microservices Talks',\n",
       " 'Use pertained Caffe models with a Scikit-learn-like API',\n",
       " 'A Tableau Web Data Connector using the scikit-learn machine learning library',\n",
       " 'Extension to scikit-learn dealing with graph data',\n",
       " 'Learn to learn with scikit-learn. ',\n",
       " 'Âü∫‰∫éÊÉÖÊÑüÂ≠óÂÖ∏ÂíåÊú∫Âô®Â≠¶‰π†ÁöÑËÇ°Â∏ÇËàÜÊÉÖÊÉÖÊÑüÂàÜÁ±ªÂèØËßÜÂåñWeb',\n",
       " 'Machine Learning Model for Sport Predictions (Football, Basketball, Baseball, Hockey, Soccer & Tennis) ',\n",
       " 'Small Docker image with Python Machine Learning tools (~180MB) https://hub.docker.com/r/frolvlad/alpine-python-machinelearning/',\n",
       " \"Build machine learning models in R like using python's scikit-learn library\",\n",
       " 'A package for data science practitioners. This library implements a number of helpful, common data transformations with a scikit-learn friendly interface in an effort to expedite the modeling process.',\n",
       " 'Scikit-learn-compatible visualizations',\n",
       " 'Classify each document inside the corpus using Python machine learning module: scikit-learn',\n",
       " '',\n",
       " 'Helm charts for creating reproducible and maintainable deployments of Polyaxon with Kubernetes.',\n",
       " 'Utilities for scikit-learn.',\n",
       " 'R scikit-learn port',\n",
       " 'Using RDKIT and SciKit-Learn to analyse Herg data from Chembl',\n",
       " 'Shiu Lab code base for Machine Learning implemented in SciKit-Learn',\n",
       " 'scikit-learn like interface and stacked autoencoder for chainer',\n",
       " 'a thin scikit-learn style wrapper for tensorflow framework',\n",
       " 'ICDSS Machine Learning Workshop Series: Linear Models',\n",
       " 'Machine learning examples written in python (scikit-learn, tensorflow)',\n",
       " 'Testing out various Scikit Learn algorithms to detect spam',\n",
       " 'Data Science Retreat Course on scikit-learn pipelines',\n",
       " 'Predicting housing prices using Decision Tree Regression (scikit-learn)',\n",
       " 'A nearest neighbor density ratio estimator with model selection, written in Python 2. It uses numpy and scikit-learn.',\n",
       " \"This is the notebook that goes along with the 'Building a k-NN model with Scikit-learn' tutorial on Medium.\",\n",
       " 'Notebooks demonstrating various ML software (Scikit-Learn, Tensorflow, etc.)',\n",
       " 'Categorical variables for pandas DataFrames and scikit-learn',\n",
       " 'This repo contains simple machine learning examples using scikit-learn.',\n",
       " 'Project webpage',\n",
       " 'LogitBoost classification algorithm built on top of scikit-learn',\n",
       " 'Predicting NHL games using Scikit-Learn and Random Forest Classifier',\n",
       " 'Short tutorial about scikit-learn pipelines',\n",
       " 'Base image for the machine learning algorithms using scikit-learn',\n",
       " 'Introductory Machine Learning in Python with Scikit-learn',\n",
       " 'Common Machine Learning Library for Python',\n",
       " 'A scikit-learn compatible implementation of hyperband',\n",
       " 'A scikit-learn compatible comprehensive set of fairness metrics for datasets and machine learning models, explanations for these metrics, and algorithms to mitigate bias in datasets and models.',\n",
       " 'Scikit-learn docset for Zeal/Dash',\n",
       " 'Experimental scikit-learn extensions - experts only',\n",
       " 'Convenient plot templates for scikit learn',\n",
       " 'Machine Learning using python (scikit-learn)',\n",
       " 'Disease Prediction based on Symptoms.',\n",
       " 'A plugin for the GATE language technology framework for training and using machine learning models.  Currently supports Mallet (MaxEnt, NaiveBayes, CRF and others), LibSVM, Scikit-Learn, Weka, and DNNs through Pytorch and Keras.',\n",
       " 'voice-to-text for songbirds',\n",
       " 'NLP in python Vector Space Modelling and document classification NLP',\n",
       " 'Demo app of digits classification by scikit-learn and Core ML in Swift',\n",
       " 'Models built using sckit-learn',\n",
       " '',\n",
       " 'The material for the Talk \"Agile Machine learning with Scalding and scikit-learn\", QCON-SF 2014 (http://qconsf.com/tutorial/agile-machine-learning-scalding-and-scikit-learn)',\n",
       " \"Repository for the ICON 2017 hackathon 'multivoxel pattern analysis (MVPA) of fMRI data in Python'\",\n",
       " 'Natural language processing (NLP) & text mining functions / preprocessors / transformers, compatible with pandas and scikit-learn Pipelines. ',\n",
       " 'Natural language processing (NLP) & text mining functions / preprocessors / transformers, compatible with pandas and scikit-learn Pipelines. ',\n",
       " 'Repository of Team DataScience',\n",
       " 'Some code snippets / explanations showing things i learned in machine learning (scikit-learn/python)',\n",
       " 'Automatic paper clustering and search tool by fastext from Facebook Research',\n",
       " 'A web app that classifies text, powered by Python, Django and Scikit-Learn.',\n",
       " 'simple machine learning programs using libraries such as scikit-learn & Tensorflow',\n",
       " 'Easy to follow introduction to Machine Learning using Scikit-Learn, Pandas and Python',\n",
       " 'Cookiecutter Starter App for Building Flask App with Scikit-learn models',\n",
       " 'The fraud identification models were build using Python Scikit-learn machine-learning module.',\n",
       " 'Scikit-learn-compatible Keras models',\n",
       " 'VGG16-Python-scikit-learn-SVM',\n",
       " 'Scikit-Learn wrapper for Tensorflow',\n",
       " \"scikit-learn wrapper for gensim's doc2vec implementation\",\n",
       " 'Automated Machine Learning [AutoML] for Python',\n",
       " 'access sklearn (scikit-learn) machine learning library via command line',\n",
       " 'Cheatsheets,Scikit-learn,pandas,matplotlib,scipy,numpy,pysparck',\n",
       " 'A scikit-learn implementation of hopfield network for MNIST',\n",
       " 'A library to parse PMML models into Scikit-learn estimators. (WIP)',\n",
       " 'Demo of an In-database processing tool for scikit-learn',\n",
       " 'Serve scikit-learn models over HTTP using flask',\n",
       " 'Machine Learning plugin for Rhino\\\\Grasshopper based on Python\\\\scikit-learn module. [Gh_CPython generated version]',\n",
       " 'Python Machine Learning Algorithms ',\n",
       " 'A tutorial on basic ML concepts using Python',\n",
       " '',\n",
       " 'Dynamically get the suggested clusters in the data for unsupervised learning.',\n",
       " 'Machine Learning Experiments with scikit-learn, Deep learning with Keras, TensorFlow and Pytorch. Data Science examples for various datasets and competitions from Kaggle and Analytics Vidhya.',\n",
       " 'Python-based Feedzai OpenML Providers',\n",
       " 'A study on machine learning Hyperparameter Tuning on KNN SVN and custom NN using scikit learn and Google cloud platform',\n",
       " 'pima-indians-diabetes.csv #sciket version data analysis',\n",
       " 'Predicting Future Influenza Virus Sequences with Machine Learning ',\n",
       " 'Study E-Book(ComputerVision DeepLearning MachineLearning Math NLP Python ReinforcementLearning)',\n",
       " 'ÈòøÈáåÂ§©Ê±†ÔºåÂπø‰∏úÂÖ¨ÂÖ±‰∫§ÈÄöÂ§ßÊï∞ÊçÆÁ´ûËµõÔºåÁÆÄÂçïÂÆûË∑µÔºå‰∏ªË¶ÅÊ∂âÂèäÁâπÂæÅÊèêÂèñÔºåÁâπÂæÅÈÄâÊã©Ôºåscikit-learn‰ΩøÁî®',\n",
       " 'Dockerfile for scikit-learn, based on davidshen84/jupyter',\n",
       " 'Maximum entropy and minimum divergence models in Python',\n",
       " 'machine learning practice',\n",
       " 'Dockerfile for machine learning environment(scikit-learn, chainer, gensim, tensorflow, jupyter)',\n",
       " 'Intro to Machine Learning - Jeremy Howard',\n",
       " '',\n",
       " '',\n",
       " 'Python library for machine learning',\n",
       " 'Where we put unmerged scikit-learn contributions yet that are useful code',\n",
       " 'Machine learning workshop using Python, pandas, and scikit-learn.  The first half of the day covered supervised classification using Logistic Regression and how to use cross validation to evaluate your models .  The second half of the day covered unsupervised clustering with Kmeans as well as an overview of the data science process.',\n",
       " 'Introduction to scikit-learn: classification of facial expressions using AMFED dataset by (Daniel McDuff et al.,  2013). ',\n",
       " 'Regression analysis on Boston house prices with Scikit-Learn',\n",
       " 'a Python machine learning library for neurophysiology data',\n",
       " 'Docker image for python datascience container with NumPy, SciPy, Scikit-learn, Matplotlib, nltk, pandas packages installed.',\n",
       " 'A collection of notebooks of my Machine Learning class written in python 3',\n",
       " 'Scikit-Learn Easy Runner - To automate and simplify running scikit-learn for simple cases through configuration',\n",
       " 'pyExtremeLM is a python module, which implements the extreme learning machine, in the style of scikit-learn.',\n",
       " '',\n",
       " 'A collection of awesome scripts from developers around the globe.',\n",
       " '',\n",
       " 'Guarding OpenStreetMap from harmful edits using machine learning',\n",
       " 'Python Data Mining Cookbook by Packt',\n",
       " 'Data Science analysis and visualization using Python.',\n",
       " 'Training and running a Machine Learning Regression Model on AWS Lambda with Scikit Learn',\n",
       " 'Quora Kaggle Competition : Natural Language Processing using word2vec embeddings, scikit-learn and xgboost for training',\n",
       " 'A project illustrating the capabilities of ML in making a game player',\n",
       " 'Small workshop on solving dota2 competition',\n",
       " 'Mentorship Repository for Machine Learning Type = Level 1',\n",
       " 'Machine learning project for predicting the number of deaths on Titanic dataset using linear regression,scikit learn. ',\n",
       " 'demos about numpy, scipy, scikit-learn, matplotlib',\n",
       " 'scikit-learn TransformerMixins for various matrix factorizations',\n",
       " 'Sets out a very simple example of using Scikit-learn to run supervised classification over your own corpus of text data',\n",
       " 'Tutorial covering a new workflow available going from pandas to scikit-learn',\n",
       " 'scikit-learn implementation of locality preserving projections (LPP)',\n",
       " 'LFW face recognition with svm and some ensemble methods,including Adaboost, Random Forest, Boosting, Voting and so on. PCA is used to extract features. Implemented with scikit-learn',\n",
       " 'Job management for scikit learn classifiers',\n",
       " 'Pure Python extensions for Scikit-Learn.',\n",
       " 'Common models are implemented using scikit-learn',\n",
       " 'Machine Learning using open source python libraries. (TensorFlow & Scikit Learn) ',\n",
       " 'A simple face recognition system using scikit-learn and OpenCV',\n",
       " 'Predicting customer churn using scikit-learn',\n",
       " 'Machine learning using python package scikit-learn',\n",
       " 'Machine Learning Implementation with Scikit-learn',\n",
       " 'Print table with results from Scikit-learn',\n",
       " 'Mentorship Repository for Machine Learning Type = Level 1',\n",
       " 'Python package equipped with a procedures to process data streams using estimators with API compatible with scikit-learn.',\n",
       " 'Spark acceleration for Scikit-Learn cross validation techniques',\n",
       " 'A big data web application to predict USA airline traffic delay with Python, Flask, Apache Spark, Kafka, MongoDB, ElasticSearch, d3.js, scikit-learn, MLlib and Apache Airflow.',\n",
       " 'Artist Prediction with Scikit Learn :art:',\n",
       " '„ÄäÊú∫Âô®Â≠¶‰π†ÂÆûÁî®ÊåáÂçóÂü∫‰∫éscikit-learn & tensorflow„Äã‰ª£Á†ÅËØ¶Â∞ΩÊ≥®Èáähands on machine learning with scikit-learn & tensorflow',\n",
       " 'XGP Python package with a scikit-learn interface',\n",
       " 'Interface around scikit-learn models and selectors',\n",
       " 'Basic linear regressions with scikit-learn.',\n",
       " 'Simple Machine learning project with scikit learn',\n",
       " 'Learning to use scikit-learn, scipy, pandas, numpy, lda, etc',\n",
       " 'Flask app to train predict using scikit-learn',\n",
       " 'Lightweight python image with Keras, Tensorflow and Scikit-learn',\n",
       " 'Short scikit-learn tutorial for the Austin Python Meetup.',\n",
       " 'Crop Yield Prediction  Laravel Web App',\n",
       " 'Input Output Hidden Markov Model (IOHMM) in Python',\n",
       " \"A research project that aims to detect Parkinson's disease in patients using Gait Analysis data. Subsequently, the project may make use of Gait Data Analysis to make powerful inferences which would help in genralizing the most common groups affected by this disease.\",\n",
       " 'Predict if you would have survived if you were on the Titanic Ship',\n",
       " 'A Python based code to construct a Sorted Coulomb matrix from Smile strings (CSV input) of molecules . An optional scikit-learn is invoked at the end of the script to classify molecules using SVM.',\n",
       " 'A machine learning library to predict stuff!',\n",
       " '',\n",
       " 'Learn scikit-learn',\n",
       " 'Machine learning workshop using Python, pandas, and scikit-learn.  The first half of the day covered supervised classification using Logistic Regression and how to use cross validation to evaluate your models .  The second half of the day covered unsupervised clustering with Kmeans as well as an overview of the data science process.',\n",
       " '',\n",
       " 'a practice to learn the ML toolkit called scikit-learn',\n",
       " 'Basic scikit-Learn tutorial',\n",
       " 'Âü∫‰∫éscikit-learnÁöÑBBSÂûÉÂúæÊñáÊú¨ÂàÜÁ±ªÂô®',\n",
       " 'Notebooks and resources from Building a Sentiment Analysis Pipeline in scikit-learn series',\n",
       " \"Machine Learning in Python - Recognizing handwritten digits using Scikit Learn's KNN algrithm \",\n",
       " 'learn scikit-learn',\n",
       " 'A multi-feature fusion and any blending(stacking) learning framework based on scikit-learn.',\n",
       " 'Extension of scikit-learn TfidfVectorizer and CountVectorizer that allows for online learning / partial fit.',\n",
       " 'This is  the idea from scikit-learn to implement the task of multi-label for Chinese text.  ',\n",
       " 'An unsupervised analysis combining topic modeling and clustering to preserve an individuals work history and credentials while tailoring their resume towards a new career field',\n",
       " 'Data Analysis and Machine Learning with Python: EDA with ECDF and Correlation analysis, Preprocessing and Feature engineering, L1 (Lasso) Regression and Random Forest Regressor with scikit-learn backed up by cross-validation, grid search and plots of feature importance.',\n",
       " 'A library for creating and curating reproducible pipelines for scientific and industrial machine learning',\n",
       " 'BBC News classification algorithm comparison',\n",
       " '',\n",
       " 'Text processing library for sentiment analysis and related tasks ',\n",
       " 'Scikit-learn',\n",
       " 'üìùNatural language processing (NLP) utils: word embeddings (Word2Vec, GloVe, FastText, ...) and preprocessing transformers, compatible with scikit-learn Pipelines. üõ†',\n",
       " 'A fast, robust Python library to check for offensive language in strings.',\n",
       " 'scikit-learn',\n",
       " 'Machine learning projects and examples taken from the Aurelien Geron book',\n",
       " 'BBC News classification algorithm comparison',\n",
       " 'Scikit learn',\n",
       " 'scikit-learn !!!',\n",
       " 'scikit learn',\n",
       " 'scikit-learn',\n",
       " 'scikit-learn',\n",
       " 'Scikit Learn',\n",
       " 'Scikit-learn',\n",
       " 'scikit-learn',\n",
       " 'A library for creating and curating reproducible pipelines for scientific and industrial machine learning',\n",
       " 'scikit-learn',\n",
       " 'scikit-learn',\n",
       " '',\n",
       " 'Visualizations of machine learning algorithms',\n",
       " 'scikit-learn',\n",
       " 'scikit-learn ',\n",
       " 'scikit.learn',\n",
       " 'Scikit-learn',\n",
       " 'Scikit-learn',\n",
       " 'SciKit - learn',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " \"This was my Master's project where i was involved using a dataset from Wireless Sensor Data Mining Lab (WISDM) to build a machine learning model to predict basic human activities using a smartphone accelerometer, Using Tensorflow framework, recurrent neural nets and multiple stacks of Long-short-term memory units(LSTM)  for building a deep network.  After the model was trained,  it was saved and exported to an android application and the predictions were made using the model and the interface to speak out the results using text-to-speech API.\",\n",
       " 'Recognize stuck out tongue',\n",
       " 'machine learning',\n",
       " 'A practice repository using scikit python library',\n",
       " 'Scikit Learn examples',\n",
       " 'Scikits learn tutorial',\n",
       " 'Just type some code and try scikit learn',\n",
       " '',\n",
       " '',\n",
       " 'Scikit - Learn Examples',\n",
       " '',\n",
       " 'Just type some code and try scikit learn',\n",
       " '',\n",
       " '',\n",
       " 'Use Python and scikit-learn to get up and running with the hottest developments in machine learning',\n",
       " \"This was my Master's project where i was involved using a dataset from Wireless Sensor Data Mining Lab (WISDM) to build a machine learning model to predict basic human activities using a smartphone accelerometer, Using Tensorflow framework, recurrent neural nets and multiple stacks of Long-short-term memory units(LSTM)  for building a deep network.  After the model was trained,  it was saved and exported to an android application and the predictions were made using the model and the interface to speak out the results using text-to-speech API.\",\n",
       " 'üìö Various cheatsheets in PDF',\n",
       " 'Data science Python notebooks: Deep learning (TensorFlow, Theano, Caffe, Keras), scikit-learn, Kaggle, big data (Spark, Hadoop MapReduce, HDFS), matplotlib, pandas, NumPy, SciPy, Python essentials, AWS, and various command lines.',\n",
       " 'scikit-learnÊú∫Âô®Â≠¶‰π† Â∏∏Áî®ÁÆóÊ≥ïÂéüÁêÜÂèäÁºñÁ®ãÂÆûÊàò ÈªÑÊ∞∏ÊòåÁºñËëó',\n",
       " \"A web app that uses logarithmic regression to predict the outcome of tennis matches. Built with Python's Scikit-learn package and Flask\",\n",
       " 'UBC Scientific Software Seminar: Machine Learning in Python with scikit-learn',\n",
       " 'Easy utilities for fitting various regressors, extracting stats, and making relevant plots with scikit-learn models',\n",
       " 'Community Scientific Python notebooks',\n",
       " 'Scikit-learn compatible Topic Modelling with Hierarchical Statistical Block Models (Gerlach, Peixoto and Altmann, 2018)',\n",
       " 'Learn from the scikit-learn',\n",
       " 'A ClowdFlows 2.0 package, which provides data mining widgets based on scikit-learn.',\n",
       " 'Predict the category of crimes that occurred in San Francisco with scikit-learn.',\n",
       " 'Implemented different regression models without using scikit learn functionalities during model building process',\n",
       " 'scikit-learn BDT pickles used by the hh channel multivariate analysis in hhana.',\n",
       " 'Dealing with real-world data examples using numpy, pandas, and scikit-learn',\n",
       " 'Different Machine learning algorithms in python trying \\nto follow the interfaces of scikit-learn',\n",
       " 'Learn someuseful scikit-learn examples.',\n",
       " 'SPC08 Talk 1: \"First Step for Machine Learning with scikit-learn\"',\n",
       " 'Automatic License Plate Reader (ALPR) Designed Around OpenCV and SciKit Learn ',\n",
       " 'Object detector from HOG + Linear SVM framework',\n",
       " 'Using machine learning libraries to analyze NBA data',\n",
       " '',\n",
       " '',\n",
       " 'A very basic decision tree using Scikit-Learn',\n",
       " '',\n",
       " 'Machine Learnign using scikit learn http://scikit-learn.org/',\n",
       " 'The scikit-learn package Examples',\n",
       " '',\n",
       " 'Machine Learning  -ScikitLearn-Train',\n",
       " 'Experimental Learning space for using scikit-learn',\n",
       " 'ML-ScikitLearn-PCA',\n",
       " 'scikit-learn: machine learning in Python http://scikit-learn.org',\n",
       " '',\n",
       " '',\n",
       " 'Pandas and Scikit-Learn demo',\n",
       " '',\n",
       " '',\n",
       " 'Application of neural nets',\n",
       " 'Some examples of testing out very simple machine learning code with scikitlearn',\n",
       " 'Practice exercises from the \"Hands-On Machine Learning with Scikit-Learn & TensorFlow\" book',\n",
       " 'https://github.com/scikit-learn/scikit-learn.git',\n",
       " '',\n",
       " 'tools for working with scikit learn',\n",
       " 'Materiales del curso de Udemy de de iniciacion en scikit learn y pypsark',\n",
       " '',\n",
       " 'Demo of ScikitLearn',\n",
       " '',\n",
       " '',\n",
       " 'Hands-On Machine Learning with Scikit-Learn & Tensorflow',\n",
       " 'scikit learn prictise',\n",
       " '',\n",
       " 'Examples using scikit learn library in Python',\n",
       " '',\n",
       " '',\n",
       " 'scikit-learn test project',\n",
       " '',\n",
       " '',\n",
       " 'Julia package mirror.',\n",
       " '',\n",
       " 'a few examples using scikitlearn',\n",
       " \"It's a very stable library with a of small dummy datasets to go in and try-out and do machine learning. Although Tensorflow is much popular, with more feature to do machine learning, a lot of essential libraries are not there specially on the data preprocessing. So, it's key to learn scikit-learn if one wants to do machine-learning.\",\n",
       " 'ScikitLearn_Lab1',\n",
       " 'SVM with Scikit Learn and jupyter',\n",
       " 'Julia package mirror.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Some sample code using scikit learning, following the best machine learning best practices',\n",
       " '',\n",
       " '',\n",
       " 'Scikit-learn learning in experiment',\n",
       " '',\n",
       " 'My code from Pluralsight course Building Machine Learning Models in Python with scikit-learn(https://app.pluralsight.com/library/courses/python-scikit-learn-building-machine-learning-models)',\n",
       " 'Me playing around with scikitLearn and machine learning in python. ',\n",
       " 'üí°Scikit Learn examples - Python',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " \"Scikit learn is a library through which we can implement various machine learning algorithms. scikit learn is undeniably the best package in the market. Machine Learning implementation doesn't require very strong math background but just an understanding about small tweaks in the working of an algorithm. Start your machine learning pursuit here with this tutorial.\",\n",
       " 'Machine Learning  Scikit-Learn -KNeighbor (K-Nearest Neighbors)',\n",
       " '',\n",
       " '',\n",
       " 'A Collection of Scikit-Learn Examples',\n",
       " 'ScikitlLearn open source explanation and theory',\n",
       " 'Linear regression different data set using Scikitlearn  ',\n",
       " '',\n",
       " 'Data Science tools',\n",
       " 'Algorithmic trading using machine learning.',\n",
       " 'Practicing SciKitLearn library with Iris Dataset',\n",
       " 'Golem is a modular machine learning library for Python. It is no longer maintained, please use scikit-learn instead: http://scikit-learn.org',\n",
       " 'C√≥digos de prueba de Machine Learning con Python y Scikit-Learn',\n",
       " 'demo code for statistics / math / Natural language / image processing / machine learning/ deep learning and  pyplot',\n",
       " \"Presentation at the NYC Data Science Study Group on how to streamline your cross-validation and classification workflow using scikit-learn's Pipelines and FeatureUnions modules.\",\n",
       " 'Autism Detection APIThis project has 3 goals: To find out the best machine learning pipeline for predicting ASD cases using genetic algorithms, via the TPOT library. (Classification Problem) Compare the accuracy of the accuracy of the determined pipeline, with a standard Naive-Bayes classifier. Saving the classifier as an external file, and use this file in a Flask API to make predictions in the cloud.',\n",
       " 'Lecture materials, Python Workshop: An Introduction to Scientific Tools',\n",
       " 'Python package providing mesoscale connectivity models for mouse.',\n",
       " 'python library implementing ensemble methods for regression, classification and visualisation tools including Voronoi tesselations.',\n",
       " 'S3 provider, scikit learn',\n",
       " 'Scikit-learn additional analytics',\n",
       " 'scikit-learn data classifiers',\n",
       " 'Chapter 5 Scikit Learn',\n",
       " 'Personal scikit-learn tutorial',\n",
       " 'Easy hyperparameter optimization and automatic result saving across machine learning algorithms and libraries',\n",
       " 'The Software will enable the user to detect the programming language without the help of file extension.',\n",
       " 'TPs for the Data-Mining course at University Paris 7',\n",
       " 'Vagrantfile for scikit-learn',\n",
       " 'scikit-learn with python ',\n",
       " 'ScikitÔºçLearn Test',\n",
       " 'Scikit-learn practice session',\n",
       " 'scikit learn tutorial 2015',\n",
       " 'scikit_learn_iris',\n",
       " 'Python + Scikit_learn',\n",
       " 'Scikit-learn-compatible metrics',\n",
       " 'Scikit-Learn Demo',\n",
       " 'scikit-learn exploration',\n",
       " 'Website with scikit-learn',\n",
       " 'Scikit-Learn and Tensorflow',\n",
       " 'Scikit-Learn and TensorFlow ',\n",
       " 'scikit-learn + ontobio',\n",
       " 'scikit-learn documents',\n",
       " 'scikit_learn_tutorial',\n",
       " 'scikit-learn sample project',\n",
       " 'study scikit-learn',\n",
       " 'knn with scikit-learn',\n",
       " 'Simple Scikit-Learn Classifier',\n",
       " 'beginner_scikit_learn',\n",
       " 'Illustration of scikit-learn',\n",
       " 'Learning Scikit Learn',\n",
       " 'scikit_learn_study',\n",
       " 'codes to learn scikit',\n",
       " '—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ scikit-learn',\n",
       " 'Scikit Learn , Tensorflow',\n",
       " 'Hacking scikit-learn',\n",
       " 'tools for scikit-learn',\n",
       " 'Implemented using SciKit Learn',\n",
       " 'Classifiers with SciKit Learn',\n",
       " 'scikit_learn_topic_modeling',\n",
       " 'PyTorch, Scikit-Learn',\n",
       " 'Scikit-learn and TensorFlow',\n",
       " 'book about scikit-learn',\n",
       " 'python / pandas / scikit-learn',\n",
       " 'visulize scikit-learn pipeline',\n",
       " 'Projects using scikit-learn',\n",
       " 'my_scikit_learn',\n",
       " 'official scikit-learn tutorials ',\n",
       " 'Exploring Python scikit-learn',\n",
       " 'From SciKit-Learn',\n",
       " 'scikit-learn code',\n",
       " 'scikit-learn-chinese-edition',\n",
       " 'face-recognition scikit-learn',\n",
       " '(SVM) Scikit Learn Tutorial',\n",
       " 'exercises of scikit-learn',\n",
       " 'scikit-learn website testing',\n",
       " 'SciKit Learn exercises record',\n",
       " 'What is scikit-learn?',\n",
       " 'Scikit-learn examples',\n",
       " 'Practice of scikit-learn',\n",
       " 'Prediction with Scikit-Learn',\n",
       " 'Python, scikit-learn',\n",
       " 'Testing out scikit-learn',\n",
       " 'Scikit-learn examples',\n",
       " 'scikit-learn examples',\n",
       " 'Â≠¶‰π†scikit-learn',\n",
       " 'TensorFlow/pytorch/scikit-learn',\n",
       " 'scikit-learn experiments',\n",
       " 'SciKit Learn Workshop',\n",
       " 'Yet another scikit-learn',\n",
       " 'Scikit-Learn GUI',\n",
       " 'Scikit-Learn workspace',\n",
       " 'scikit-learn ML practice',\n",
       " 'Scikit-learn-scripts',\n",
       " 'scikit-learn-review',\n",
       " 'Keras, Scikit-learn, TensorFlow',\n",
       " 'Learning scikit-learn',\n",
       " 'NIDS with scikit-learn',\n",
       " 'scikit-learn scoring demo',\n",
       " 'introduction scikit-learn',\n",
       " 'BYOD-Scikit-Learn',\n",
       " 'scikit_learn_basic_study',\n",
       " 'scikit_learn_example',\n",
       " 'Scikit Learn Examples',\n",
       " 'JavaFX + Scikit Learn',\n",
       " ...]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:49:02.253990Z",
     "start_time": "2019-03-27T01:49:02.219985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00440</th>\n",
       "      <th>01783v1</th>\n",
       "      <th>02456</th>\n",
       "      <th>02755</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>0636920034391</th>\n",
       "      <th>08835</th>\n",
       "      <th>...</th>\n",
       "      <th>ÏûêÎ£å</th>\n",
       "      <th>ÏûêÎ£åÎì§ÏùÑ</th>\n",
       "      <th>ÏûêÎ£åÎ™®Ïùå</th>\n",
       "      <th>ÏûêÏó∞Ïñ¥Ï≤òÎ¶¨</th>\n",
       "      <th>ÌÖêÏÑúÌîåÎ°úÎ°ú</th>\n",
       "      <th>ÌååÏù¥Ïç¨python</th>\n",
       "      <th>ÌååÏù¥Ïç¨ÏùÑ</th>\n",
       "      <th>Ìå®Ïä§Ìä∏Ï∫†ÌçºÏä§</th>\n",
       "      <th>ÌïúÎààÏóê</th>\n",
       "      <th>ùì∑ùì≠ùìªùìÆùîÄ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>component_1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_5</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_6</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_7</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component_8</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows √ó 7385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             00440  01783v1  02456  02755   03     04     05   06  \\\n",
       "component_1  0.000    0.000  0.000    0.0  0.0  0.000  0.000  0.0   \n",
       "component_2  0.000    0.000  0.000    0.0  0.0  0.000  0.000  0.0   \n",
       "component_3  0.000    0.000  0.000    0.0  0.0  0.000  0.003  0.0   \n",
       "component_4  0.000    0.000  0.000    0.0  0.0  0.000  0.002  0.0   \n",
       "component_5  0.004    0.000  0.008    0.0  0.0  0.005  0.000  0.0   \n",
       "component_6  0.000    0.000  0.000    0.0  0.0  0.000  0.000  0.0   \n",
       "component_7  0.000    0.000  0.000    0.0  0.0  0.000  0.000  0.0   \n",
       "component_8  0.000    0.017  0.005    0.0  0.0  0.000  0.008  0.0   \n",
       "\n",
       "             0636920034391  08835  ...     ÏûêÎ£å  ÏûêÎ£åÎì§ÏùÑ  ÏûêÎ£åÎ™®Ïùå  ÏûêÏó∞Ïñ¥Ï≤òÎ¶¨  ÌÖêÏÑúÌîåÎ°úÎ°ú  \\\n",
       "component_1          0.000  0.000  ...    0.0   0.0   0.0    0.0    0.0   \n",
       "component_2          0.000  0.007  ...    0.0   0.0   0.0    0.0    0.0   \n",
       "component_3          0.000  0.000  ...    0.0   0.0   0.0    0.0    0.0   \n",
       "component_4          0.004  0.000  ...    0.0   0.0   0.0    0.0    0.0   \n",
       "component_5          0.000  0.000  ...    0.0   0.0   0.0    0.0    0.0   \n",
       "component_6          0.000  0.000  ...    0.0   0.0   0.0    0.0    0.0   \n",
       "component_7          0.000  0.000  ...    0.0   0.0   0.0    0.0    0.0   \n",
       "component_8          0.000  0.000  ...    0.0   0.0   0.0    0.0    0.0   \n",
       "\n",
       "             ÌååÏù¥Ïç¨python  ÌååÏù¥Ïç¨ÏùÑ  Ìå®Ïä§Ìä∏Ï∫†ÌçºÏä§  ÌïúÎààÏóê  ùì∑ùì≠ùìªùìÆùîÄ  \n",
       "component_1        0.0   0.0     0.0  0.0  0.004  \n",
       "component_2        0.0   0.0     0.0  0.0  0.000  \n",
       "component_3        0.0   0.0     0.0  0.0  0.000  \n",
       "component_4        0.0   0.0     0.0  0.0  0.000  \n",
       "component_5        0.0   0.0     0.0  0.0  0.000  \n",
       "component_6        0.0   0.0     0.0  0.0  0.000  \n",
       "component_7        0.0   0.0     0.0  0.0  0.000  \n",
       "component_8        0.0   0.0     0.0  0.0  0.000  \n",
       "\n",
       "[8 rows x 7385 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = pd.DataFrame(nmf_model.components_.round(3),\n",
    "             index = [\"component_1\",\"component_2\",\"component_3\",\"component_4\",\"component_5\",\"component_6\", \"component_7\", \"component_8\"],\n",
    "             columns = vectorizer.get_feature_names())\n",
    "topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:49:02.947445Z",
     "start_time": "2019-03-27T01:49:02.780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "learning, machine, algorithms, code, course, repository, library, models\n",
      "\n",
      "Topic  1\n",
      "learn, scikit, tutorial, tensorflow, pandas, compatible, implementation, models\n",
      "\n",
      "Topic  2\n",
      "jupyter, notebooks, notebook, data, ipython, collection, code, course\n",
      "\n",
      "Topic  3\n",
      "python, library, code, api, data, client, repository, book\n",
      "\n",
      "Topic  4\n",
      "learning, deep, tensorflow, reinforcement, nlp, models, keras, course\n",
      "\n",
      "Topic  5\n",
      "julia, package, library, language, interface, programming, wrapper, implementation\n",
      "\n",
      "Topic  6\n",
      "kubernetes, cluster, docker, clusters, deploy, service, running, based\n",
      "\n",
      "Topic  7\n",
      "using, data, tensorflow, model, analysis, neural, project, network\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf_model, vectorizer.get_feature_names(), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:16:44.259357Z",
     "start_time": "2019-03-27T02:16:44.245725Z"
    }
   },
   "outputs": [],
   "source": [
    "H['topic'] = H.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:16:51.211565Z",
     "start_time": "2019-03-27T02:16:51.194694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machine_learning</th>\n",
       "      <th>scikit_learn</th>\n",
       "      <th>jupyter_notebook</th>\n",
       "      <th>python_library</th>\n",
       "      <th>nlp</th>\n",
       "      <th>julia_package</th>\n",
       "      <th>kubernetes</th>\n",
       "      <th>deep_learning</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scikit-learn: machine learning in Python</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jupyter notebooks from the scikit-learn video series</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>jupyter_notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PySpark + Scikit-learn = Sparkit-learn</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Automated Machine Learning with scikit-learn</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    machine_learning  \\\n",
       "scikit-learn: machine learning in Python                        0.17   \n",
       "Jupyter notebooks from the scikit-learn video s...              0.00   \n",
       "PySpark + Scikit-learn = Sparkit-learn                          0.00   \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                           0.00   \n",
       "Automated Machine Learning with scikit-learn                    0.17   \n",
       "\n",
       "                                                    scikit_learn  \\\n",
       "scikit-learn: machine learning in Python                    0.18   \n",
       "Jupyter notebooks from the scikit-learn video s...          0.18   \n",
       "PySpark + Scikit-learn = Sparkit-learn                      0.27   \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                       0.18   \n",
       "Automated Machine Learning with scikit-learn                0.18   \n",
       "\n",
       "                                                    jupyter_notebook  \\\n",
       "scikit-learn: machine learning in Python                        0.00   \n",
       "Jupyter notebooks from the scikit-learn video s...              0.24   \n",
       "PySpark + Scikit-learn = Sparkit-learn                          0.00   \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                           0.00   \n",
       "Automated Machine Learning with scikit-learn                    0.00   \n",
       "\n",
       "                                                    python_library  nlp  \\\n",
       "scikit-learn: machine learning in Python                      0.18  0.0   \n",
       "Jupyter notebooks from the scikit-learn video s...            0.00  0.0   \n",
       "PySpark + Scikit-learn = Sparkit-learn                        0.00  0.0   \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                         0.00  0.0   \n",
       "Automated Machine Learning with scikit-learn                  0.00  0.0   \n",
       "\n",
       "                                                    julia_package  kubernetes  \\\n",
       "scikit-learn: machine learning in Python                      0.0         0.0   \n",
       "Jupyter notebooks from the scikit-learn video s...            0.0         0.0   \n",
       "PySpark + Scikit-learn = Sparkit-learn                        0.0         0.0   \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                         0.0         0.0   \n",
       "Automated Machine Learning with scikit-learn                  0.0         0.0   \n",
       "\n",
       "                                                    deep_learning  \\\n",
       "scikit-learn: machine learning in Python                      0.0   \n",
       "Jupyter notebooks from the scikit-learn video s...            0.0   \n",
       "PySpark + Scikit-learn = Sparkit-learn                        0.0   \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                         0.0   \n",
       "Automated Machine Learning with scikit-learn                  0.0   \n",
       "\n",
       "                                                               topic  \n",
       "scikit-learn: machine learning in Python                scikit_learn  \n",
       "Jupyter notebooks from the scikit-learn video s...  jupyter_notebook  \n",
       "PySpark + Scikit-learn = Sparkit-learn                  scikit_learn  \n",
       ":book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£                   scikit_learn  \n",
       "Automated Machine Learning with scikit-learn            scikit_learn  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:16:56.496222Z",
     "start_time": "2019-03-27T02:16:56.492677Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:17:22.096885Z",
     "start_time": "2019-03-27T02:17:22.067317Z"
    }
   },
   "outputs": [],
   "source": [
    "result = pairwise_distances(doc_word.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:17:23.022806Z",
     "start_time": "2019-03-27T02:17:22.637Z"
    }
   },
   "outputs": [],
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:17:40.560593Z",
     "start_time": "2019-03-27T02:17:40.547315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.0),\n",
       " (1094, 0.0),\n",
       " (2052, 0.0),\n",
       " (27, 1.0),\n",
       " (515, 1.0),\n",
       " (642, 1.0),\n",
       " (649, 1.0),\n",
       " (2959, 1.0),\n",
       " (4, 1.4142135623730951),\n",
       " (13, 1.4142135623730951),\n",
       " (39, 1.4142135623730951),\n",
       " (84, 1.4142135623730951),\n",
       " (110, 1.4142135623730951),\n",
       " (121, 1.4142135623730951),\n",
       " (126, 1.4142135623730951),\n",
       " (258, 1.4142135623730951),\n",
       " (262, 1.4142135623730951),\n",
       " (333, 1.4142135623730951),\n",
       " (396, 1.4142135623730951),\n",
       " (402, 1.4142135623730951),\n",
       " (413, 1.4142135623730951),\n",
       " (733, 1.4142135623730951),\n",
       " (734, 1.4142135623730951),\n",
       " (908, 1.4142135623730951),\n",
       " (924, 1.4142135623730951),\n",
       " (945, 1.4142135623730951),\n",
       " (976, 1.4142135623730951),\n",
       " (991, 1.4142135623730951),\n",
       " (2154, 1.4142135623730951),\n",
       " (2282, 1.4142135623730951),\n",
       " (2720, 1.4142135623730951),\n",
       " (8, 1.7320508075688772),\n",
       " (17, 1.7320508075688772),\n",
       " (35, 1.7320508075688772),\n",
       " (67, 1.7320508075688772),\n",
       " (96, 1.7320508075688772),\n",
       " (127, 1.7320508075688772),\n",
       " (136, 1.7320508075688772),\n",
       " (266, 1.7320508075688772),\n",
       " (278, 1.7320508075688772),\n",
       " (298, 1.7320508075688772),\n",
       " (415, 1.7320508075688772),\n",
       " (546, 1.7320508075688772),\n",
       " (603, 1.7320508075688772),\n",
       " (628, 1.7320508075688772),\n",
       " (681, 1.7320508075688772),\n",
       " (699, 1.7320508075688772),\n",
       " (745, 1.7320508075688772),\n",
       " (775, 1.7320508075688772),\n",
       " (778, 1.7320508075688772),\n",
       " (781, 1.7320508075688772),\n",
       " (782, 1.7320508075688772),\n",
       " (783, 1.7320508075688772),\n",
       " (784, 1.7320508075688772),\n",
       " (785, 1.7320508075688772),\n",
       " (786, 1.7320508075688772),\n",
       " (787, 1.7320508075688772),\n",
       " (788, 1.7320508075688772),\n",
       " (790, 1.7320508075688772),\n",
       " (791, 1.7320508075688772),\n",
       " (794, 1.7320508075688772),\n",
       " (795, 1.7320508075688772),\n",
       " (796, 1.7320508075688772),\n",
       " (797, 1.7320508075688772),\n",
       " (798, 1.7320508075688772),\n",
       " (799, 1.7320508075688772),\n",
       " (805, 1.7320508075688772),\n",
       " (866, 1.7320508075688772),\n",
       " (888, 1.7320508075688772),\n",
       " (892, 1.7320508075688772),\n",
       " (958, 1.7320508075688772),\n",
       " (963, 1.7320508075688772),\n",
       " (964, 1.7320508075688772),\n",
       " (972, 1.7320508075688772),\n",
       " (984, 1.7320508075688772),\n",
       " (1006, 1.7320508075688772),\n",
       " (1009, 1.7320508075688772),\n",
       " (1488, 1.7320508075688772),\n",
       " (2048, 1.7320508075688772),\n",
       " (2072, 1.7320508075688772),\n",
       " (2073, 1.7320508075688772),\n",
       " (2138, 1.7320508075688772),\n",
       " (2201, 1.7320508075688772),\n",
       " (2269, 1.7320508075688772),\n",
       " (2311, 1.7320508075688772),\n",
       " (2316, 1.7320508075688772),\n",
       " (2363, 1.7320508075688772),\n",
       " (2494, 1.7320508075688772),\n",
       " (2498, 1.7320508075688772),\n",
       " (2500, 1.7320508075688772),\n",
       " (2507, 1.7320508075688772),\n",
       " (2520, 1.7320508075688772),\n",
       " (2551, 1.7320508075688772),\n",
       " (2610, 1.7320508075688772),\n",
       " (2660, 1.7320508075688772),\n",
       " (2716, 1.7320508075688772),\n",
       " (2808, 1.7320508075688772),\n",
       " (2916, 1.7320508075688772),\n",
       " (3020, 1.7320508075688772),\n",
       " (3033, 1.7320508075688772),\n",
       " (4037, 1.7320508075688772),\n",
       " (4099, 1.7320508075688772),\n",
       " (11, 2.0),\n",
       " (24, 2.0),\n",
       " (54, 2.0),\n",
       " (75, 2.0),\n",
       " (77, 2.0),\n",
       " (135, 2.0),\n",
       " (145, 2.0),\n",
       " (161, 2.0),\n",
       " (226, 2.0),\n",
       " (246, 2.0),\n",
       " (291, 2.0),\n",
       " (300, 2.0),\n",
       " (321, 2.0),\n",
       " (338, 2.0),\n",
       " (343, 2.0),\n",
       " (344, 2.0),\n",
       " (346, 2.0),\n",
       " (352, 2.0),\n",
       " (370, 2.0),\n",
       " (432, 2.0),\n",
       " (470, 2.0),\n",
       " (472, 2.0),\n",
       " (499, 2.0),\n",
       " (547, 2.0),\n",
       " (621, 2.0),\n",
       " (622, 2.0),\n",
       " (643, 2.0),\n",
       " (670, 2.0),\n",
       " (673, 2.0),\n",
       " (694, 2.0),\n",
       " (728, 2.0),\n",
       " (757, 2.0),\n",
       " (765, 2.0),\n",
       " (807, 2.0),\n",
       " (812, 2.0),\n",
       " (817, 2.0),\n",
       " (823, 2.0),\n",
       " (827, 2.0),\n",
       " (835, 2.0),\n",
       " (849, 2.0),\n",
       " (867, 2.0),\n",
       " (891, 2.0),\n",
       " (897, 2.0),\n",
       " (918, 2.0),\n",
       " (923, 2.0),\n",
       " (925, 2.0),\n",
       " (931, 2.0),\n",
       " (932, 2.0),\n",
       " (933, 2.0),\n",
       " (934, 2.0),\n",
       " (935, 2.0),\n",
       " (936, 2.0),\n",
       " (937, 2.0),\n",
       " (940, 2.0),\n",
       " (941, 2.0),\n",
       " (944, 2.0),\n",
       " (947, 2.0),\n",
       " (948, 2.0),\n",
       " (949, 2.0),\n",
       " (950, 2.0),\n",
       " (951, 2.0),\n",
       " (953, 2.0),\n",
       " (955, 2.0),\n",
       " (956, 2.0),\n",
       " (957, 2.0),\n",
       " (965, 2.0),\n",
       " (969, 2.0),\n",
       " (973, 2.0),\n",
       " (974, 2.0),\n",
       " (975, 2.0),\n",
       " (977, 2.0),\n",
       " (978, 2.0),\n",
       " (979, 2.0),\n",
       " (982, 2.0),\n",
       " (983, 2.0),\n",
       " (985, 2.0),\n",
       " (986, 2.0),\n",
       " (988, 2.0),\n",
       " (989, 2.0),\n",
       " (992, 2.0),\n",
       " (994, 2.0),\n",
       " (995, 2.0),\n",
       " (998, 2.0),\n",
       " (999, 2.0),\n",
       " (1001, 2.0),\n",
       " (1004, 2.0),\n",
       " (1007, 2.0),\n",
       " (1008, 2.0),\n",
       " (1011, 2.0),\n",
       " (1012, 2.0),\n",
       " (1013, 2.0),\n",
       " (1015, 2.0),\n",
       " (1016, 2.0),\n",
       " (1018, 2.0),\n",
       " (1079, 2.0),\n",
       " (1189, 2.0),\n",
       " (1318, 2.0),\n",
       " (1381, 2.0),\n",
       " (1765, 2.0),\n",
       " (1777, 2.0),\n",
       " (1779, 2.0),\n",
       " (2046, 2.0),\n",
       " (2092, 2.0),\n",
       " (2137, 2.0),\n",
       " (2145, 2.0),\n",
       " (2161, 2.0),\n",
       " (2177, 2.0),\n",
       " (2180, 2.0),\n",
       " (2184, 2.0),\n",
       " (2210, 2.0),\n",
       " (2215, 2.0),\n",
       " (2219, 2.0),\n",
       " (2236, 2.0),\n",
       " (2239, 2.0),\n",
       " (2246, 2.0),\n",
       " (2285, 2.0),\n",
       " (2300, 2.0),\n",
       " (2331, 2.0),\n",
       " (2344, 2.0),\n",
       " (2353, 2.0),\n",
       " (2360, 2.0),\n",
       " (2364, 2.0),\n",
       " (2380, 2.0),\n",
       " (2433, 2.0),\n",
       " (2459, 2.0),\n",
       " (2460, 2.0),\n",
       " (2465, 2.0),\n",
       " (2471, 2.0),\n",
       " (2479, 2.0),\n",
       " (2487, 2.0),\n",
       " (2513, 2.0),\n",
       " (2523, 2.0),\n",
       " (2530, 2.0),\n",
       " (2569, 2.0),\n",
       " (2599, 2.0),\n",
       " (2608, 2.0),\n",
       " (2623, 2.0),\n",
       " (2657, 2.0),\n",
       " (2659, 2.0),\n",
       " (2670, 2.0),\n",
       " (2672, 2.0),\n",
       " (2680, 2.0),\n",
       " (2740, 2.0),\n",
       " (2753, 2.0),\n",
       " (2762, 2.0),\n",
       " (2763, 2.0),\n",
       " (2796, 2.0),\n",
       " (2802, 2.0),\n",
       " (2807, 2.0),\n",
       " (2822, 2.0),\n",
       " (2834, 2.0),\n",
       " (2895, 2.0),\n",
       " (2913, 2.0),\n",
       " (2929, 2.0),\n",
       " (2977, 2.0),\n",
       " (2980, 2.0),\n",
       " (2989, 2.0),\n",
       " (2994, 2.0),\n",
       " (3050, 2.0),\n",
       " (3148, 2.0),\n",
       " (4974, 2.0),\n",
       " (5550, 2.0),\n",
       " (5969, 2.0),\n",
       " (5, 2.23606797749979),\n",
       " (6, 2.23606797749979),\n",
       " (7, 2.23606797749979),\n",
       " (23, 2.23606797749979),\n",
       " (43, 2.23606797749979),\n",
       " (44, 2.23606797749979),\n",
       " (48, 2.23606797749979),\n",
       " (66, 2.23606797749979),\n",
       " (81, 2.23606797749979),\n",
       " (82, 2.23606797749979),\n",
       " (94, 2.23606797749979),\n",
       " (99, 2.23606797749979),\n",
       " (106, 2.23606797749979),\n",
       " (113, 2.23606797749979),\n",
       " (115, 2.23606797749979),\n",
       " (118, 2.23606797749979),\n",
       " (125, 2.23606797749979),\n",
       " (128, 2.23606797749979),\n",
       " (138, 2.23606797749979),\n",
       " (139, 2.23606797749979),\n",
       " (141, 2.23606797749979),\n",
       " (146, 2.23606797749979),\n",
       " (162, 2.23606797749979),\n",
       " (165, 2.23606797749979),\n",
       " (169, 2.23606797749979),\n",
       " (174, 2.23606797749979),\n",
       " (179, 2.23606797749979),\n",
       " (187, 2.23606797749979),\n",
       " (188, 2.23606797749979),\n",
       " (191, 2.23606797749979),\n",
       " (193, 2.23606797749979),\n",
       " (196, 2.23606797749979),\n",
       " (197, 2.23606797749979),\n",
       " (198, 2.23606797749979),\n",
       " (199, 2.23606797749979),\n",
       " (224, 2.23606797749979),\n",
       " (236, 2.23606797749979),\n",
       " (241, 2.23606797749979),\n",
       " (257, 2.23606797749979),\n",
       " (271, 2.23606797749979),\n",
       " (276, 2.23606797749979),\n",
       " (282, 2.23606797749979),\n",
       " (283, 2.23606797749979),\n",
       " (284, 2.23606797749979),\n",
       " (295, 2.23606797749979),\n",
       " (299, 2.23606797749979),\n",
       " (306, 2.23606797749979),\n",
       " (310, 2.23606797749979),\n",
       " (314, 2.23606797749979),\n",
       " (319, 2.23606797749979),\n",
       " (341, 2.23606797749979),\n",
       " (342, 2.23606797749979),\n",
       " (357, 2.23606797749979),\n",
       " (371, 2.23606797749979),\n",
       " (374, 2.23606797749979),\n",
       " (385, 2.23606797749979),\n",
       " (403, 2.23606797749979),\n",
       " (404, 2.23606797749979),\n",
       " (405, 2.23606797749979),\n",
       " (408, 2.23606797749979),\n",
       " (411, 2.23606797749979),\n",
       " (412, 2.23606797749979),\n",
       " (416, 2.23606797749979),\n",
       " (419, 2.23606797749979),\n",
       " (420, 2.23606797749979),\n",
       " (431, 2.23606797749979),\n",
       " (439, 2.23606797749979),\n",
       " (451, 2.23606797749979),\n",
       " (457, 2.23606797749979),\n",
       " (463, 2.23606797749979),\n",
       " (483, 2.23606797749979),\n",
       " (491, 2.23606797749979),\n",
       " (492, 2.23606797749979),\n",
       " (502, 2.23606797749979),\n",
       " (506, 2.23606797749979),\n",
       " (512, 2.23606797749979),\n",
       " (513, 2.23606797749979),\n",
       " (519, 2.23606797749979),\n",
       " (530, 2.23606797749979),\n",
       " (539, 2.23606797749979),\n",
       " (552, 2.23606797749979),\n",
       " (555, 2.23606797749979),\n",
       " (564, 2.23606797749979),\n",
       " (566, 2.23606797749979),\n",
       " (579, 2.23606797749979),\n",
       " (587, 2.23606797749979),\n",
       " (589, 2.23606797749979),\n",
       " (594, 2.23606797749979),\n",
       " (606, 2.23606797749979),\n",
       " (615, 2.23606797749979),\n",
       " (617, 2.23606797749979),\n",
       " (619, 2.23606797749979),\n",
       " (641, 2.23606797749979),\n",
       " (656, 2.23606797749979),\n",
       " (666, 2.23606797749979),\n",
       " (671, 2.23606797749979),\n",
       " (683, 2.23606797749979),\n",
       " (697, 2.23606797749979),\n",
       " (698, 2.23606797749979),\n",
       " (704, 2.23606797749979),\n",
       " (708, 2.23606797749979),\n",
       " (709, 2.23606797749979),\n",
       " (711, 2.23606797749979),\n",
       " (730, 2.23606797749979),\n",
       " (742, 2.23606797749979),\n",
       " (756, 2.23606797749979),\n",
       " (759, 2.23606797749979),\n",
       " (761, 2.23606797749979),\n",
       " (773, 2.23606797749979),\n",
       " (792, 2.23606797749979),\n",
       " (793, 2.23606797749979),\n",
       " (800, 2.23606797749979),\n",
       " (801, 2.23606797749979),\n",
       " (802, 2.23606797749979),\n",
       " (810, 2.23606797749979),\n",
       " (811, 2.23606797749979),\n",
       " (813, 2.23606797749979),\n",
       " (815, 2.23606797749979),\n",
       " (816, 2.23606797749979),\n",
       " (833, 2.23606797749979),\n",
       " (839, 2.23606797749979),\n",
       " (840, 2.23606797749979),\n",
       " (842, 2.23606797749979),\n",
       " (844, 2.23606797749979),\n",
       " (845, 2.23606797749979),\n",
       " (846, 2.23606797749979),\n",
       " (847, 2.23606797749979),\n",
       " (850, 2.23606797749979),\n",
       " (851, 2.23606797749979),\n",
       " (852, 2.23606797749979),\n",
       " (853, 2.23606797749979),\n",
       " (854, 2.23606797749979),\n",
       " (859, 2.23606797749979),\n",
       " (860, 2.23606797749979),\n",
       " (862, 2.23606797749979),\n",
       " (864, 2.23606797749979),\n",
       " (865, 2.23606797749979),\n",
       " (868, 2.23606797749979),\n",
       " (869, 2.23606797749979),\n",
       " (870, 2.23606797749979),\n",
       " (871, 2.23606797749979),\n",
       " (872, 2.23606797749979),\n",
       " (873, 2.23606797749979),\n",
       " (874, 2.23606797749979),\n",
       " (876, 2.23606797749979),\n",
       " (880, 2.23606797749979),\n",
       " (882, 2.23606797749979),\n",
       " (883, 2.23606797749979),\n",
       " (884, 2.23606797749979),\n",
       " (886, 2.23606797749979),\n",
       " (887, 2.23606797749979),\n",
       " (889, 2.23606797749979),\n",
       " (893, 2.23606797749979),\n",
       " (894, 2.23606797749979),\n",
       " (895, 2.23606797749979),\n",
       " (898, 2.23606797749979),\n",
       " (899, 2.23606797749979),\n",
       " (900, 2.23606797749979),\n",
       " (903, 2.23606797749979),\n",
       " (915, 2.23606797749979),\n",
       " (916, 2.23606797749979),\n",
       " (917, 2.23606797749979),\n",
       " (919, 2.23606797749979),\n",
       " (926, 2.23606797749979),\n",
       " (927, 2.23606797749979),\n",
       " (929, 2.23606797749979),\n",
       " (930, 2.23606797749979),\n",
       " (939, 2.23606797749979),\n",
       " (942, 2.23606797749979),\n",
       " (952, 2.23606797749979),\n",
       " (959, 2.23606797749979),\n",
       " (960, 2.23606797749979),\n",
       " (962, 2.23606797749979),\n",
       " (966, 2.23606797749979),\n",
       " (967, 2.23606797749979),\n",
       " (968, 2.23606797749979),\n",
       " (970, 2.23606797749979),\n",
       " (971, 2.23606797749979),\n",
       " (980, 2.23606797749979),\n",
       " (981, 2.23606797749979),\n",
       " (987, 2.23606797749979),\n",
       " (990, 2.23606797749979),\n",
       " (993, 2.23606797749979),\n",
       " (1000, 2.23606797749979),\n",
       " (1002, 2.23606797749979),\n",
       " (1003, 2.23606797749979),\n",
       " (1005, 2.23606797749979),\n",
       " (1010, 2.23606797749979),\n",
       " (1014, 2.23606797749979),\n",
       " (1017, 2.23606797749979),\n",
       " (1019, 2.23606797749979),\n",
       " (1021, 2.23606797749979),\n",
       " (1032, 2.23606797749979),\n",
       " (1074, 2.23606797749979),\n",
       " (1104, 2.23606797749979),\n",
       " (1106, 2.23606797749979),\n",
       " (1122, 2.23606797749979),\n",
       " (1126, 2.23606797749979),\n",
       " (1140, 2.23606797749979),\n",
       " (1144, 2.23606797749979),\n",
       " (1174, 2.23606797749979),\n",
       " (1236, 2.23606797749979),\n",
       " (1245, 2.23606797749979),\n",
       " (1254, 2.23606797749979),\n",
       " (1265, 2.23606797749979),\n",
       " (1274, 2.23606797749979),\n",
       " (1278, 2.23606797749979),\n",
       " (1281, 2.23606797749979),\n",
       " (1296, 2.23606797749979),\n",
       " (1308, 2.23606797749979),\n",
       " (1309, 2.23606797749979),\n",
       " (1340, 2.23606797749979),\n",
       " (1345, 2.23606797749979),\n",
       " (1351, 2.23606797749979),\n",
       " (1366, 2.23606797749979),\n",
       " (1380, 2.23606797749979),\n",
       " (1441, 2.23606797749979),\n",
       " (1442, 2.23606797749979),\n",
       " (1457, 2.23606797749979),\n",
       " (1461, 2.23606797749979),\n",
       " (1462, 2.23606797749979),\n",
       " (1474, 2.23606797749979),\n",
       " (1485, 2.23606797749979),\n",
       " (1486, 2.23606797749979),\n",
       " (1498, 2.23606797749979),\n",
       " (1500, 2.23606797749979),\n",
       " (1512, 2.23606797749979),\n",
       " (1513, 2.23606797749979),\n",
       " (1540, 2.23606797749979),\n",
       " (1549, 2.23606797749979),\n",
       " (1554, 2.23606797749979),\n",
       " (1560, 2.23606797749979),\n",
       " (1567, 2.23606797749979),\n",
       " (1571, 2.23606797749979),\n",
       " (1597, 2.23606797749979),\n",
       " (1603, 2.23606797749979),\n",
       " (1609, 2.23606797749979),\n",
       " (1615, 2.23606797749979),\n",
       " (1616, 2.23606797749979),\n",
       " (1618, 2.23606797749979),\n",
       " (1620, 2.23606797749979),\n",
       " (1633, 2.23606797749979),\n",
       " (1636, 2.23606797749979),\n",
       " (1673, 2.23606797749979),\n",
       " (1698, 2.23606797749979),\n",
       " (1714, 2.23606797749979),\n",
       " (1734, 2.23606797749979),\n",
       " (1747, 2.23606797749979),\n",
       " (1755, 2.23606797749979),\n",
       " (1760, 2.23606797749979),\n",
       " (1781, 2.23606797749979),\n",
       " (1783, 2.23606797749979),\n",
       " (1792, 2.23606797749979),\n",
       " (1796, 2.23606797749979),\n",
       " (1815, 2.23606797749979),\n",
       " (1826, 2.23606797749979),\n",
       " (1856, 2.23606797749979),\n",
       " (1885, 2.23606797749979),\n",
       " (1900, 2.23606797749979),\n",
       " (1920, 2.23606797749979),\n",
       " (1924, 2.23606797749979),\n",
       " (1937, 2.23606797749979),\n",
       " (1966, 2.23606797749979),\n",
       " (1970, 2.23606797749979),\n",
       " (1971, 2.23606797749979),\n",
       " (1990, 2.23606797749979),\n",
       " (1993, 2.23606797749979),\n",
       " (2012, 2.23606797749979),\n",
       " (2015, 2.23606797749979),\n",
       " (2056, 2.23606797749979),\n",
       " (2058, 2.23606797749979),\n",
       " (2063, 2.23606797749979),\n",
       " (2084, 2.23606797749979),\n",
       " (2089, 2.23606797749979),\n",
       " (2090, 2.23606797749979),\n",
       " (2093, 2.23606797749979),\n",
       " (2101, 2.23606797749979),\n",
       " (2109, 2.23606797749979),\n",
       " (2126, 2.23606797749979),\n",
       " (2133, 2.23606797749979),\n",
       " (2144, 2.23606797749979),\n",
       " (2149, 2.23606797749979),\n",
       " (2153, 2.23606797749979),\n",
       " (2160, 2.23606797749979),\n",
       " (2170, 2.23606797749979),\n",
       " (2172, 2.23606797749979),\n",
       " (2174, 2.23606797749979),\n",
       " (2187, 2.23606797749979),\n",
       " (2188, 2.23606797749979),\n",
       " (2189, 2.23606797749979),\n",
       " (2204, 2.23606797749979),\n",
       " (2207, 2.23606797749979),\n",
       " (2213, 2.23606797749979),\n",
       " (2216, 2.23606797749979),\n",
       " (2220, 2.23606797749979),\n",
       " (2221, 2.23606797749979),\n",
       " (2226, 2.23606797749979),\n",
       " (2235, 2.23606797749979),\n",
       " (2244, 2.23606797749979),\n",
       " (2249, 2.23606797749979),\n",
       " (2252, 2.23606797749979),\n",
       " (2254, 2.23606797749979),\n",
       " (2260, 2.23606797749979),\n",
       " (2262, 2.23606797749979),\n",
       " (2263, 2.23606797749979),\n",
       " (2266, 2.23606797749979),\n",
       " (2280, 2.23606797749979),\n",
       " (2284, 2.23606797749979),\n",
       " (2288, 2.23606797749979),\n",
       " (2292, 2.23606797749979),\n",
       " (2293, 2.23606797749979),\n",
       " (2296, 2.23606797749979),\n",
       " (2308, 2.23606797749979),\n",
       " (2312, 2.23606797749979),\n",
       " (2317, 2.23606797749979),\n",
       " (2318, 2.23606797749979),\n",
       " (2321, 2.23606797749979),\n",
       " (2325, 2.23606797749979),\n",
       " (2328, 2.23606797749979),\n",
       " (2332, 2.23606797749979),\n",
       " (2333, 2.23606797749979),\n",
       " (2337, 2.23606797749979),\n",
       " (2342, 2.23606797749979),\n",
       " (2343, 2.23606797749979),\n",
       " (2348, 2.23606797749979),\n",
       " (2355, 2.23606797749979),\n",
       " (2368, 2.23606797749979),\n",
       " (2373, 2.23606797749979),\n",
       " (2377, 2.23606797749979),\n",
       " (2381, 2.23606797749979),\n",
       " (2385, 2.23606797749979),\n",
       " (2386, 2.23606797749979),\n",
       " (2393, 2.23606797749979),\n",
       " (2401, 2.23606797749979),\n",
       " (2408, 2.23606797749979),\n",
       " (2423, 2.23606797749979),\n",
       " (2425, 2.23606797749979),\n",
       " (2426, 2.23606797749979),\n",
       " (2428, 2.23606797749979),\n",
       " (2434, 2.23606797749979),\n",
       " (2439, 2.23606797749979),\n",
       " (2445, 2.23606797749979),\n",
       " (2452, 2.23606797749979),\n",
       " (2453, 2.23606797749979),\n",
       " (2454, 2.23606797749979),\n",
       " (2464, 2.23606797749979),\n",
       " (2470, 2.23606797749979),\n",
       " (2474, 2.23606797749979),\n",
       " (2476, 2.23606797749979),\n",
       " (2485, 2.23606797749979),\n",
       " (2486, 2.23606797749979),\n",
       " (2488, 2.23606797749979),\n",
       " (2490, 2.23606797749979),\n",
       " (2493, 2.23606797749979),\n",
       " (2496, 2.23606797749979),\n",
       " (2518, 2.23606797749979),\n",
       " (2525, 2.23606797749979),\n",
       " (2529, 2.23606797749979),\n",
       " (2548, 2.23606797749979),\n",
       " (2549, 2.23606797749979),\n",
       " (2553, 2.23606797749979),\n",
       " (2558, 2.23606797749979),\n",
       " (2566, 2.23606797749979),\n",
       " (2567, 2.23606797749979),\n",
       " (2570, 2.23606797749979),\n",
       " (2573, 2.23606797749979),\n",
       " (2578, 2.23606797749979),\n",
       " (2579, 2.23606797749979),\n",
       " (2582, 2.23606797749979),\n",
       " (2583, 2.23606797749979),\n",
       " (2591, 2.23606797749979),\n",
       " (2594, 2.23606797749979),\n",
       " (2604, 2.23606797749979),\n",
       " (2605, 2.23606797749979),\n",
       " (2611, 2.23606797749979),\n",
       " (2612, 2.23606797749979),\n",
       " (2613, 2.23606797749979),\n",
       " (2618, 2.23606797749979),\n",
       " (2626, 2.23606797749979),\n",
       " (2635, 2.23606797749979),\n",
       " (2638, 2.23606797749979),\n",
       " (2643, 2.23606797749979),\n",
       " (2663, 2.23606797749979),\n",
       " (2666, 2.23606797749979),\n",
       " (2678, 2.23606797749979),\n",
       " (2690, 2.23606797749979),\n",
       " (2696, 2.23606797749979),\n",
       " (2705, 2.23606797749979),\n",
       " (2709, 2.23606797749979),\n",
       " (2712, 2.23606797749979),\n",
       " (2718, 2.23606797749979),\n",
       " (2724, 2.23606797749979),\n",
       " (2725, 2.23606797749979),\n",
       " (2736, 2.23606797749979),\n",
       " (2738, 2.23606797749979),\n",
       " (2741, 2.23606797749979),\n",
       " (2744, 2.23606797749979),\n",
       " (2749, 2.23606797749979),\n",
       " (2750, 2.23606797749979),\n",
       " (2760, 2.23606797749979),\n",
       " (2773, 2.23606797749979),\n",
       " (2775, 2.23606797749979),\n",
       " (2776, 2.23606797749979),\n",
       " (2780, 2.23606797749979),\n",
       " (2786, 2.23606797749979),\n",
       " (2791, 2.23606797749979),\n",
       " (2792, 2.23606797749979),\n",
       " (2801, 2.23606797749979),\n",
       " (2812, 2.23606797749979),\n",
       " (2815, 2.23606797749979),\n",
       " (2831, 2.23606797749979),\n",
       " (2833, 2.23606797749979),\n",
       " (2837, 2.23606797749979),\n",
       " (2842, 2.23606797749979),\n",
       " (2845, 2.23606797749979),\n",
       " (2848, 2.23606797749979),\n",
       " (2850, 2.23606797749979),\n",
       " (2854, 2.23606797749979),\n",
       " (2857, 2.23606797749979),\n",
       " (2861, 2.23606797749979),\n",
       " (2871, 2.23606797749979),\n",
       " (2873, 2.23606797749979),\n",
       " (2900, 2.23606797749979),\n",
       " (2904, 2.23606797749979),\n",
       " (2907, 2.23606797749979),\n",
       " (2910, 2.23606797749979),\n",
       " (2917, 2.23606797749979),\n",
       " (2925, 2.23606797749979),\n",
       " (2933, 2.23606797749979),\n",
       " (2935, 2.23606797749979),\n",
       " (2945, 2.23606797749979),\n",
       " (2949, 2.23606797749979),\n",
       " (2951, 2.23606797749979),\n",
       " (2955, 2.23606797749979),\n",
       " (2961, 2.23606797749979),\n",
       " (2965, 2.23606797749979),\n",
       " (2966, 2.23606797749979),\n",
       " (2969, 2.23606797749979),\n",
       " (2970, 2.23606797749979),\n",
       " (2971, 2.23606797749979),\n",
       " (2978, 2.23606797749979),\n",
       " (2979, 2.23606797749979),\n",
       " (2982, 2.23606797749979),\n",
       " (2992, 2.23606797749979),\n",
       " (2995, 2.23606797749979),\n",
       " (2998, 2.23606797749979),\n",
       " (3005, 2.23606797749979),\n",
       " (3007, 2.23606797749979),\n",
       " (3008, 2.23606797749979),\n",
       " (3025, 2.23606797749979),\n",
       " (3030, 2.23606797749979),\n",
       " (3031, 2.23606797749979),\n",
       " (3034, 2.23606797749979),\n",
       " (3036, 2.23606797749979),\n",
       " (3040, 2.23606797749979),\n",
       " (3042, 2.23606797749979),\n",
       " (3052, 2.23606797749979),\n",
       " (3079, 2.23606797749979),\n",
       " (3111, 2.23606797749979),\n",
       " (3131, 2.23606797749979),\n",
       " (3180, 2.23606797749979),\n",
       " (3182, 2.23606797749979),\n",
       " (3218, 2.23606797749979),\n",
       " (3233, 2.23606797749979),\n",
       " (3250, 2.23606797749979),\n",
       " (3293, 2.23606797749979),\n",
       " (3318, 2.23606797749979),\n",
       " (3331, 2.23606797749979),\n",
       " (3332, 2.23606797749979),\n",
       " (3346, 2.23606797749979),\n",
       " (3378, 2.23606797749979),\n",
       " (3395, 2.23606797749979),\n",
       " (3419, 2.23606797749979),\n",
       " (3425, 2.23606797749979),\n",
       " (3436, 2.23606797749979),\n",
       " (3439, 2.23606797749979),\n",
       " (3452, 2.23606797749979),\n",
       " (3473, 2.23606797749979),\n",
       " (3482, 2.23606797749979),\n",
       " (3514, 2.23606797749979),\n",
       " (3533, 2.23606797749979),\n",
       " (3560, 2.23606797749979),\n",
       " (3572, 2.23606797749979),\n",
       " (3598, 2.23606797749979),\n",
       " (3627, 2.23606797749979),\n",
       " (3635, 2.23606797749979),\n",
       " (3639, 2.23606797749979),\n",
       " (3702, 2.23606797749979),\n",
       " (3735, 2.23606797749979),\n",
       " (3736, 2.23606797749979),\n",
       " (3756, 2.23606797749979),\n",
       " (3774, 2.23606797749979),\n",
       " (3802, 2.23606797749979),\n",
       " (3821, 2.23606797749979),\n",
       " (3850, 2.23606797749979),\n",
       " (3874, 2.23606797749979),\n",
       " (3890, 2.23606797749979),\n",
       " (3897, 2.23606797749979),\n",
       " (3906, 2.23606797749979),\n",
       " (3911, 2.23606797749979),\n",
       " (3924, 2.23606797749979),\n",
       " (3943, 2.23606797749979),\n",
       " (3949, 2.23606797749979),\n",
       " (3958, 2.23606797749979),\n",
       " (3979, 2.23606797749979),\n",
       " (4011, 2.23606797749979),\n",
       " (4036, 2.23606797749979),\n",
       " (4063, 2.23606797749979),\n",
       " (4069, 2.23606797749979),\n",
       " (4093, 2.23606797749979),\n",
       " (4101, 2.23606797749979),\n",
       " (4102, 2.23606797749979),\n",
       " (4109, 2.23606797749979),\n",
       " (4165, 2.23606797749979),\n",
       " (4198, 2.23606797749979),\n",
       " (4253, 2.23606797749979),\n",
       " (4258, 2.23606797749979),\n",
       " (4301, 2.23606797749979),\n",
       " (4368, 2.23606797749979),\n",
       " (4413, 2.23606797749979),\n",
       " (4520, 2.23606797749979),\n",
       " (4605, 2.23606797749979),\n",
       " (4644, 2.23606797749979),\n",
       " (4647, 2.23606797749979),\n",
       " (4649, 2.23606797749979),\n",
       " (4673, 2.23606797749979),\n",
       " (4677, 2.23606797749979),\n",
       " (4679, 2.23606797749979),\n",
       " (4715, 2.23606797749979),\n",
       " (4742, 2.23606797749979),\n",
       " (4759, 2.23606797749979),\n",
       " (4806, 2.23606797749979),\n",
       " (4815, 2.23606797749979),\n",
       " (4822, 2.23606797749979),\n",
       " (4844, 2.23606797749979),\n",
       " (4866, 2.23606797749979),\n",
       " (4872, 2.23606797749979),\n",
       " (4880, 2.23606797749979),\n",
       " (4881, 2.23606797749979),\n",
       " (4887, 2.23606797749979),\n",
       " (4893, 2.23606797749979),\n",
       " (4925, 2.23606797749979),\n",
       " (4926, 2.23606797749979),\n",
       " (4942, 2.23606797749979),\n",
       " (4981, 2.23606797749979),\n",
       " (4984, 2.23606797749979),\n",
       " (4989, 2.23606797749979),\n",
       " (4998, 2.23606797749979),\n",
       " (4999, 2.23606797749979),\n",
       " (5057, 2.23606797749979),\n",
       " (5064, 2.23606797749979),\n",
       " (5067, 2.23606797749979),\n",
       " (5074, 2.23606797749979),\n",
       " (5101, 2.23606797749979),\n",
       " (5147, 2.23606797749979),\n",
       " (5154, 2.23606797749979),\n",
       " (5163, 2.23606797749979),\n",
       " (5184, 2.23606797749979),\n",
       " (5204, 2.23606797749979),\n",
       " (5252, 2.23606797749979),\n",
       " (5255, 2.23606797749979),\n",
       " (5274, 2.23606797749979),\n",
       " (5299, 2.23606797749979),\n",
       " (5328, 2.23606797749979),\n",
       " (5352, 2.23606797749979),\n",
       " (5360, 2.23606797749979),\n",
       " (5388, 2.23606797749979),\n",
       " (5395, 2.23606797749979),\n",
       " (5405, 2.23606797749979),\n",
       " (5466, 2.23606797749979),\n",
       " (5549, 2.23606797749979),\n",
       " (5559, 2.23606797749979),\n",
       " (5638, 2.23606797749979),\n",
       " (5705, 2.23606797749979),\n",
       " (5749, 2.23606797749979),\n",
       " (5895, 2.23606797749979),\n",
       " (5920, 2.23606797749979),\n",
       " (5930, 2.23606797749979),\n",
       " (5937, 2.23606797749979),\n",
       " (5967, 2.23606797749979),\n",
       " (5977, 2.23606797749979),\n",
       " (6105, 2.23606797749979),\n",
       " (6110, 2.23606797749979),\n",
       " (6132, 2.23606797749979),\n",
       " (6187, 2.23606797749979),\n",
       " (6191, 2.23606797749979),\n",
       " (6356, 2.23606797749979),\n",
       " (6415, 2.23606797749979),\n",
       " (6471, 2.23606797749979),\n",
       " (6675, 2.23606797749979),\n",
       " (6688, 2.23606797749979),\n",
       " (6691, 2.23606797749979),\n",
       " (6692, 2.23606797749979),\n",
       " (6701, 2.23606797749979),\n",
       " (6721, 2.23606797749979),\n",
       " (6725, 2.23606797749979),\n",
       " (6766, 2.23606797749979),\n",
       " (6773, 2.23606797749979),\n",
       " (6790, 2.23606797749979),\n",
       " (6846, 2.23606797749979),\n",
       " (6857, 2.23606797749979),\n",
       " (6878, 2.23606797749979),\n",
       " (6879, 2.23606797749979),\n",
       " (6885, 2.23606797749979),\n",
       " (6905, 2.23606797749979),\n",
       " (6924, 2.23606797749979),\n",
       " (6985, 2.23606797749979),\n",
       " (7012, 2.23606797749979),\n",
       " (2, 2.449489742783178),\n",
       " (3, 2.449489742783178),\n",
       " (16, 2.449489742783178),\n",
       " (19, 2.449489742783178),\n",
       " (25, 2.449489742783178),\n",
       " (30, 2.449489742783178),\n",
       " (32, 2.449489742783178),\n",
       " (38, 2.449489742783178),\n",
       " (42, 2.449489742783178),\n",
       " (50, 2.449489742783178),\n",
       " (52, 2.449489742783178),\n",
       " (55, 2.449489742783178),\n",
       " (56, 2.449489742783178),\n",
       " (71, 2.449489742783178),\n",
       " (78, 2.449489742783178),\n",
       " (83, 2.449489742783178),\n",
       " (87, 2.449489742783178),\n",
       " (98, 2.449489742783178),\n",
       " (102, 2.449489742783178),\n",
       " (104, 2.449489742783178),\n",
       " (105, 2.449489742783178),\n",
       " (114, 2.449489742783178),\n",
       " (142, 2.449489742783178),\n",
       " (158, 2.449489742783178),\n",
       " (160, 2.449489742783178),\n",
       " (166, 2.449489742783178),\n",
       " (170, 2.449489742783178),\n",
       " (181, 2.449489742783178),\n",
       " (205, 2.449489742783178),\n",
       " (215, 2.449489742783178),\n",
       " (218, 2.449489742783178),\n",
       " (222, 2.449489742783178),\n",
       " (227, 2.449489742783178),\n",
       " (232, 2.449489742783178),\n",
       " (234, 2.449489742783178),\n",
       " (256, 2.449489742783178),\n",
       " (280, 2.449489742783178),\n",
       " (287, 2.449489742783178),\n",
       " (290, 2.449489742783178),\n",
       " (294, 2.449489742783178),\n",
       " (308, 2.449489742783178),\n",
       " (330, 2.449489742783178),\n",
       " (354, 2.449489742783178),\n",
       " (358, 2.449489742783178),\n",
       " (369, 2.449489742783178),\n",
       " (379, 2.449489742783178),\n",
       " (380, 2.449489742783178),\n",
       " (394, 2.449489742783178),\n",
       " (417, 2.449489742783178),\n",
       " (434, 2.449489742783178),\n",
       " (441, 2.449489742783178),\n",
       " (444, 2.449489742783178),\n",
       " (449, 2.449489742783178),\n",
       " (455, 2.449489742783178),\n",
       " (460, 2.449489742783178),\n",
       " (477, 2.449489742783178),\n",
       " (482, 2.449489742783178),\n",
       " (495, 2.449489742783178),\n",
       " (508, 2.449489742783178),\n",
       " (511, 2.449489742783178),\n",
       " (514, 2.449489742783178),\n",
       " (516, 2.449489742783178),\n",
       " (524, 2.449489742783178),\n",
       " (550, 2.449489742783178),\n",
       " (563, 2.449489742783178),\n",
       " (567, 2.449489742783178),\n",
       " (575, 2.449489742783178),\n",
       " (600, 2.449489742783178),\n",
       " (607, 2.449489742783178),\n",
       " (612, 2.449489742783178),\n",
       " (618, 2.449489742783178),\n",
       " (624, 2.449489742783178),\n",
       " (636, 2.449489742783178),\n",
       " (640, 2.449489742783178),\n",
       " (644, 2.449489742783178),\n",
       " (646, 2.449489742783178),\n",
       " (647, 2.449489742783178),\n",
       " (648, 2.449489742783178),\n",
       " (662, 2.449489742783178),\n",
       " (665, 2.449489742783178),\n",
       " (668, 2.449489742783178),\n",
       " (669, 2.449489742783178),\n",
       " (674, 2.449489742783178),\n",
       " (696, 2.449489742783178),\n",
       " (706, 2.449489742783178),\n",
       " (727, 2.449489742783178),\n",
       " (735, 2.449489742783178),\n",
       " (740, 2.449489742783178),\n",
       " (743, 2.449489742783178),\n",
       " (744, 2.449489742783178),\n",
       " (748, 2.449489742783178),\n",
       " (749, 2.449489742783178),\n",
       " (755, 2.449489742783178),\n",
       " (764, 2.449489742783178),\n",
       " (808, 2.449489742783178),\n",
       " (834, 2.449489742783178),\n",
       " (857, 2.449489742783178),\n",
       " (879, 2.449489742783178),\n",
       " (905, 2.449489742783178),\n",
       " (928, 2.449489742783178),\n",
       " (938, 2.449489742783178),\n",
       " (943, 2.449489742783178),\n",
       " (946, 2.449489742783178),\n",
       " (954, 2.449489742783178),\n",
       " (961, 2.449489742783178),\n",
       " (996, 2.449489742783178),\n",
       " (997, 2.449489742783178),\n",
       " (1020, 2.449489742783178),\n",
       " (1022, 2.449489742783178),\n",
       " (1024, 2.449489742783178),\n",
       " (1030, 2.449489742783178),\n",
       " (1031, 2.449489742783178),\n",
       " (1034, 2.449489742783178),\n",
       " (1040, 2.449489742783178),\n",
       " (1043, 2.449489742783178),\n",
       " (1048, 2.449489742783178),\n",
       " (1054, 2.449489742783178),\n",
       " (1055, 2.449489742783178),\n",
       " (1057, 2.449489742783178),\n",
       " (1059, 2.449489742783178),\n",
       " (1063, 2.449489742783178),\n",
       " (1064, 2.449489742783178),\n",
       " (1069, 2.449489742783178),\n",
       " (1087, 2.449489742783178),\n",
       " (1088, 2.449489742783178),\n",
       " (1099, 2.449489742783178),\n",
       " (1105, 2.449489742783178),\n",
       " ...]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the sorted list of cosine similarities to the first document\n",
    "sims = sorted(enumerate(result[0]), key=lambda item: item[1])\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:17:43.030980Z",
     "start_time": "2019-03-27T02:17:43.018115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1094, 2052, 27, 515, 642, 649, 2959, 4, 13, 39, 84, 110, 121, 126, 258, 262, 333, 396, 402, 413, 733, 734, 908, 924, 945, 976, 991, 2154, 2282, 2720, 8, 17, 35, 67, 96, 127, 136, 266, 278, 298, 415, 546, 603, 628, 681, 699, 745, 775, 778, 781, 782, 783, 784, 785, 786, 787, 788, 790, 791, 794, 795, 796, 797, 798, 799, 805, 866, 888, 892, 958, 963, 964, 972, 984, 1006, 1009, 1488, 2048, 2072, 2073, 2138, 2201, 2269, 2311, 2316, 2363, 2494, 2498, 2500, 2507, 2520, 2551, 2610, 2660, 2716, 2808, 2916, 3020, 3033, 4037, 4099, 11, 24, 54, 75, 77, 135, 145, 161, 226, 246, 291, 300, 321, 338, 343, 344, 346, 352, 370, 432, 470, 472, 499, 547, 621, 622, 643, 670, 673, 694, 728, 757, 765, 807, 812, 817, 823, 827, 835, 849, 867, 891, 897, 918, 923, 925, 931, 932, 933, 934, 935, 936, 937, 940, 941, 944, 947, 948, 949, 950, 951, 953, 955, 956, 957, 965, 969, 973, 974, 975, 977, 978, 979, 982, 983, 985, 986, 988, 989, 992, 994, 995, 998, 999, 1001, 1004, 1007, 1008, 1011, 1012, 1013, 1015, 1016, 1018, 1079, 1189, 1318, 1381, 1765, 1777, 1779, 2046, 2092, 2137, 2145, 2161, 2177, 2180, 2184, 2210, 2215, 2219, 2236, 2239, 2246, 2285, 2300, 2331, 2344, 2353, 2360, 2364, 2380, 2433, 2459, 2460, 2465, 2471, 2479, 2487, 2513, 2523, 2530, 2569, 2599, 2608, 2623, 2657, 2659, 2670, 2672, 2680, 2740, 2753, 2762, 2763, 2796, 2802, 2807, 2822, 2834, 2895, 2913, 2929, 2977, 2980, 2989, 2994, 3050, 3148, 4974, 5550, 5969, 5, 6, 7, 23, 43, 44, 48, 66, 81, 82, 94, 99, 106, 113, 115, 118, 125, 128, 138, 139, 141, 146, 162, 165, 169, 174, 179, 187, 188, 191, 193, 196, 197, 198, 199, 224, 236, 241, 257, 271, 276, 282, 283, 284, 295, 299, 306, 310, 314, 319, 341, 342, 357, 371, 374, 385, 403, 404, 405, 408, 411, 412, 416, 419, 420, 431, 439, 451, 457, 463, 483, 491, 492, 502, 506, 512, 513, 519, 530, 539, 552, 555, 564, 566, 579, 587, 589, 594, 606, 615, 617, 619, 641, 656, 666, 671, 683, 697, 698, 704, 708, 709, 711, 730, 742, 756, 759, 761, 773, 792, 793, 800, 801, 802, 810, 811, 813, 815, 816, 833, 839, 840, 842, 844, 845, 846, 847, 850, 851, 852, 853, 854, 859, 860, 862, 864, 865, 868, 869, 870, 871, 872, 873, 874, 876, 880, 882, 883, 884, 886, 887, 889, 893, 894, 895, 898, 899, 900, 903, 915, 916, 917, 919, 926, 927, 929, 930, 939, 942, 952, 959, 960, 962, 966, 967, 968, 970, 971, 980, 981, 987, 990, 993, 1000, 1002, 1003, 1005, 1010, 1014, 1017, 1019, 1021, 1032, 1074, 1104, 1106, 1122, 1126, 1140, 1144, 1174, 1236, 1245, 1254, 1265, 1274, 1278, 1281, 1296, 1308, 1309, 1340, 1345, 1351, 1366, 1380, 1441, 1442, 1457, 1461, 1462, 1474, 1485, 1486, 1498, 1500, 1512, 1513, 1540, 1549, 1554, 1560, 1567, 1571, 1597, 1603, 1609, 1615, 1616, 1618, 1620, 1633, 1636, 1673, 1698, 1714, 1734, 1747, 1755, 1760, 1781, 1783, 1792, 1796, 1815, 1826, 1856, 1885, 1900, 1920, 1924, 1937, 1966, 1970, 1971, 1990, 1993, 2012, 2015, 2056, 2058, 2063, 2084, 2089, 2090, 2093, 2101, 2109, 2126, 2133, 2144, 2149, 2153, 2160, 2170, 2172, 2174, 2187, 2188, 2189, 2204, 2207, 2213, 2216, 2220, 2221, 2226, 2235, 2244, 2249, 2252, 2254, 2260, 2262, 2263, 2266, 2280, 2284, 2288, 2292, 2293, 2296, 2308, 2312, 2317, 2318, 2321, 2325, 2328, 2332, 2333, 2337, 2342, 2343, 2348, 2355, 2368, 2373, 2377, 2381, 2385, 2386, 2393, 2401, 2408, 2423, 2425, 2426, 2428, 2434, 2439, 2445, 2452, 2453, 2454, 2464, 2470, 2474, 2476, 2485, 2486, 2488, 2490, 2493, 2496, 2518, 2525, 2529, 2548, 2549, 2553, 2558, 2566, 2567, 2570, 2573, 2578, 2579, 2582, 2583, 2591, 2594, 2604, 2605, 2611, 2612, 2613, 2618, 2626, 2635, 2638, 2643, 2663, 2666, 2678, 2690, 2696, 2705, 2709, 2712, 2718, 2724, 2725, 2736, 2738, 2741, 2744, 2749, 2750, 2760, 2773, 2775, 2776, 2780, 2786, 2791, 2792, 2801, 2812, 2815, 2831, 2833, 2837, 2842, 2845, 2848, 2850, 2854, 2857, 2861, 2871, 2873, 2900, 2904, 2907, 2910, 2917, 2925, 2933, 2935, 2945, 2949, 2951, 2955, 2961, 2965, 2966, 2969, 2970, 2971, 2978, 2979, 2982, 2992, 2995, 2998, 3005, 3007, 3008, 3025, 3030, 3031, 3034, 3036, 3040, 3042, 3052, 3079, 3111, 3131, 3180, 3182, 3218, 3233, 3250, 3293, 3318, 3331, 3332, 3346, 3378, 3395, 3419, 3425, 3436, 3439, 3452, 3473, 3482, 3514, 3533, 3560, 3572, 3598, 3627, 3635, 3639, 3702, 3735, 3736, 3756, 3774, 3802, 3821, 3850, 3874, 3890, 3897, 3906, 3911, 3924, 3943, 3949, 3958, 3979, 4011, 4036, 4063, 4069, 4093, 4101, 4102, 4109, 4165, 4198, 4253, 4258, 4301, 4368, 4413, 4520, 4605, 4644, 4647, 4649, 4673, 4677, 4679, 4715, 4742, 4759, 4806, 4815, 4822, 4844, 4866, 4872, 4880, 4881, 4887, 4893, 4925, 4926, 4942, 4981, 4984, 4989, 4998, 4999, 5057, 5064, 5067, 5074, 5101, 5147, 5154, 5163, 5184, 5204, 5252, 5255, 5274, 5299, 5328, 5352, 5360, 5388, 5395, 5405, 5466, 5549, 5559, 5638, 5705, 5749, 5895, 5920, 5930, 5937, 5967, 5977, 6105, 6110, 6132, 6187, 6191, 6356, 6415, 6471, 6675, 6688, 6691, 6692, 6701, 6721, 6725, 6766, 6773, 6790, 6846, 6857, 6878, 6879, 6885, 6905, 6924, 6985, 7012, 2, 3, 16, 19, 25, 30, 32, 38, 42, 50, 52, 55, 56, 71, 78, 83, 87, 98, 102, 104, 105, 114, 142, 158, 160, 166, 170, 181, 205, 215, 218, 222, 227, 232, 234, 256, 280, 287, 290, 294, 308, 330, 354, 358, 369, 379, 380, 394, 417, 434, 441, 444, 449, 455, 460, 477, 482, 495, 508, 511, 514, 516, 524, 550, 563, 567, 575, 600, 607, 612, 618, 624, 636, 640, 644, 646, 647, 648, 662, 665, 668, 669, 674, 696, 706, 727, 735, 740, 743, 744, 748, 749, 755, 764, 808, 834, 857, 879, 905, 928, 938, 943, 946, 954, 961, 996, 997, 1020, 1022, 1024, 1030, 1031, 1034, 1040, 1043, 1048, 1054, 1055, 1057, 1059, 1063, 1064, 1069, 1087, 1088, 1099, 1105, 1110, 1111, 1112, 1115, 1125, 1142, 1163, 1168, 1170, 1180, 1184, 1186, 1191, 1192, 1204, 1207, 1216, 1219, 1221, 1242, 1244, 1275, 1279, 1280, 1287, 1306, 1311, 1314, 1316, 1325, 1328, 1330, 1335, 1336, 1341, 1347, 1348, 1350, 1360, 1364, 1365, 1373, 1375, 1377, 1382, 1390, 1392, 1399, 1408, 1413, 1414, 1417, 1418, 1433, 1435, 1440, 1448, 1467, 1469, 1471, 1473, 1481, 1501, 1503, 1509, 1522, 1523, 1528, 1543, 1552, 1562, 1565, 1576, 1583, 1585, 1588, 1590, 1601, 1614, 1617, 1619, 1621, 1623, 1629, 1641, 1649, 1651, 1653, 1656, 1662, 1666, 1667, 1672, 1692, 1696, 1703, 1707, 1710, 1711, 1713, 1715, 1719, 1721, 1728, 1748, 1767, 1785, 1790, 1800, 1803, 1820, 1824, 1830, 1834, 1836, 1843, 1859, 1889, 1890, 1907, 1918, 1921, 1948, 1963, 1975, 1981, 1983, 1992, 2000, 2002, 2003, 2014, 2022, 2025, 2029, 2030, 2032, 2035, 2039, 2041, 2042, 2049, 2050, 2053, 2054, 2067, 2068, 2071, 2080, 2085, 2086, 2087, 2097, 2099, 2104, 2110, 2111, 2117, 2120, 2121, 2124, 2127, 2128, 2130, 2139, 2147, 2150, 2167, 2168, 2179, 2190, 2194, 2202, 2214, 2217, 2218, 2224, 2227, 2230, 2232, 2234, 2238, 2243, 2248, 2253, 2259, 2261, 2267, 2268, 2274, 2287, 2314, 2320, 2327, 2339, 2340, 2365, 2366, 2367, 2369, 2371, 2382, 2390, 2395, 2398, 2404, 2409, 2413, 2418, 2427, 2435, 2436, 2443, 2450, 2458, 2468, 2478, 2483, 2499, 2509, 2510, 2521, 2522, 2528, 2531, 2534, 2536, 2545, 2556, 2560, 2561, 2562, 2565, 2577, 2590, 2592, 2602, 2603, 2607, 2619, 2620, 2621, 2625, 2628, 2634, 2645, 2650, 2658, 2662, 2674, 2683, 2685, 2689, 2694, 2708, 2710, 2722, 2727, 2728, 2729, 2730, 2734, 2748, 2758, 2770, 2781, 2793, 2809, 2814, 2817, 2825, 2827, 2830, 2832, 2835, 2840, 2853, 2860, 2862, 2864, 2874, 2875, 2876, 2882, 2884, 2886, 2887, 2890, 2891, 2896, 2899, 2903, 2906, 2912, 2922, 2923, 2928, 2930, 2931, 2940, 2943, 2960, 2967, 2973, 3000, 3004, 3017, 3018, 3023, 3035, 3047, 3054, 3059, 3061, 3063, 3083, 3124, 3142, 3162, 3163, 3168, 3185, 3193, 3214, 3221, 3232, 3235, 3256, 3268, 3302, 3304, 3305, 3345, 3348, 3350, 3383, 3396, 3400, 3401, 3405, 3447, 3487, 3504, 3509, 3532, 3579, 3581, 3584, 3601, 3617, 3655, 3663, 3684, 3686, 3688, 3694, 3703, 3715, 3749, 3768, 3785, 3800, 3832, 3894, 3901, 3912, 3926, 3931, 3947, 3954, 3957, 3970, 3986, 3989, 4009, 4014, 4023, 4057, 4059, 4065, 4094, 4189, 4270, 4397, 4496, 4505, 4553, 4561, 4688, 4863, 4876, 4956, 4972, 5114, 5130, 5175, 5220, 5261, 5271, 5302, 5340, 5593, 5727, 5756, 5786, 6077, 6219, 6509, 6515, 6853, 6866, 6869, 6931, 6938, 6961, 6965, 6987, 6997, 7000, 1, 9, 10, 12, 14, 15, 18, 21, 22, 28, 29, 31, 34, 40, 51, 57, 58, 61, 63, 68, 69, 70, 79, 85, 90, 101, 103, 112, 117, 120, 124, 129, 131, 132, 133, 150, 154, 171, 172, 183, 202, 203, 206, 207, 209, 211, 214, 217, 230, 238, 243, 247, 249, 250, 270, 275, 281, 285, 296, 303, 304, 305, 322, 323, 324, 325, 326, 349, 364, 366, 372, 386, 392, 410, 414, 425, 453, 459, 464, 467, 468, 479, 480, 487, 493, 501, 521, 522, 536, 541, 544, 545, 558, 559, 560, 562, 574, 576, 583, 585, 591, 592, 601, 609, 610, 611, 626, 635, 637, 638, 672, 676, 678, 692, 695, 700, 715, 719, 721, 722, 729, 732, 736, 746, 762, 806, 809, 814, 821, 825, 841, 863, 1033, 1046, 1051, 1053, 1060, 1072, 1073, 1077, 1078, 1082, 1085, 1096, 1100, 1114, 1117, 1118, 1120, 1123, 1127, 1129, 1130, 1132, 1136, 1141, 1146, 1147, 1150, 1151, 1156, 1166, 1173, 1175, 1176, 1179, 1181, 1183, 1185, 1187, 1188, 1190, 1195, 1198, 1201, 1208, 1214, 1217, 1218, 1230, 1231, 1237, 1252, 1255, 1264, 1267, 1270, 1282, 1284, 1289, 1291, 1293, 1299, 1304, 1305, 1312, 1327, 1333, 1354, 1359, 1361, 1362, 1379, 1383, 1396, 1397, 1401, 1405, 1407, 1410, 1419, 1429, 1432, 1447, 1449, 1459, 1463, 1480, 1484, 1493, 1496, 1497, 1505, 1508, 1511, 1515, 1516, 1519, 1525, 1526, 1529, 1544, 1546, 1550, 1557, 1559, 1564, 1568, 1570, 1572, 1574, 1580, 1584, 1586, 1587, 1591, 1593, 1598, 1606, 1608, 1625, 1628, 1630, 1632, 1639, 1640, 1644, 1647, 1652, 1654, 1655, 1665, 1670, 1674, 1679, 1680, 1684, 1685, 1689, 1699, 1700, 1701, 1709, 1717, 1725, 1729, 1740, 1741, 1746, 1757, 1762, 1768, 1770, 1773, 1776, 1780, 1788, 1797, 1799, 1805, 1810, 1811, 1816, 1827, 1828, 1829, 1832, 1835, 1842, 1846, 1848, 1849, 1850, 1867, 1868, 1871, 1874, 1878, 1883, 1888, 1891, 1896, 1898, 1906, 1910, 1913, 1922, 1925, 1927, 1928, 1932, 1943, 1947, 1956, 1959, 1968, 1969, 1977, 1980, 1994, 2008, 2018, 2020, 2026, 2033, 2034, 2038, 2057, 2065, 2075, 2083, 2088, 2094, 2105, 2107, 2112, 2136, 2142, 2156, 2157, 2164, 2175, 2191, 2198, 2200, 2205, 2209, 2211, 2212, 2229, 2245, 2256, 2257, 2265, 2272, 2277, 2295, 2302, 2304, 2305, 2322, 2326, 2335, 2336, 2351, 2354, 2356, 2358, 2362, 2372, 2374, 2376, 2384, 2399, 2400, 2414, 2422, 2431, 2437, 2438, 2440, 2462, 2463, 2467, 2472, 2482, 2484, 2504, 2516, 2517, 2532, 2535, 2550, 2555, 2559, 2568, 2574, 2575, 2584, 2601, 2633, 2637, 2646, 2648, 2652, 2669, 2673, 2686, 2687, 2692, 2699, 2700, 2701, 2714, 2715, 2721, 2726, 2739, 2745, 2746, 2761, 2764, 2767, 2779, 2782, 2785, 2788, 2794, 2797, 2799, 2803, 2806, 2813, 2828, 2829, 2844, 2846, 2856, 2858, 2867, 2868, 2870, 2872, 2880, 2883, 2885, 2908, 2909, 2911, 2914, 2915, 2921, 2934, 2936, 2941, 2946, 2948, 2950, 2952, 2981, 3002, 3003, 3014, 3016, 3021, 3026, 3029, 3041, 3046, 3048, 3053, 3065, 3089, 3107, 3116, 3119, 3150, 3156, 3158, 3161, 3164, 3172, 3173, 3192, 3194, 3198, 3199, 3220, 3228, 3237, 3238, 3243, 3249, 3254, 3260, 3263, 3267, 3279, 3283, 3289, 3298, 3313, 3323, 3329, 3330, 3351, 3353, 3355, 3363, 3370, 3389, 3391, 3402, 3416, 3430, 3459, 3460, 3462, 3467, 3523, 3524, 3525, 3585, 3590, 3591, 3595, 3619, 3630, 3650, 3696, 3701, 3725, 3728, 3746, 3764, 3771, 3781, 3789, 3798, 3812, 3817, 3822, 3823, 3837, 3838, 3840, 3867, 3873, 3886, 3898, 3910, 3925, 3936, 3956, 3961, 3968, 3972, 3985, 3991, 3997, 4001, 4015, 4016, 4019, 4029, 4041, 4043, 4049, 4062, 4074, 4087, 4098, 4120, 4149, 4164, 4257, 4287, 4288, 4290, 4354, 4423, 4425, 4486, 4548, 4558, 4560, 4592, 4609, 4620, 4635, 4664, 4701, 4729, 4754, 4804, 4816, 4860, 4886, 4890, 4908, 4924, 4983, 4990, 4995, 5029, 5031, 5047, 5051, 5055, 5105, 5110, 5113, 5117, 5133, 5134, 5152, 5160, 5164, 5169, 5205, 5240, 5242, 5256, 5292, 5294, 5327, 5350, 5364, 5384, 5413, 5420, 5424, 5432, 5472, 5483, 5485, 5493, 5497, 5516, 5518, 5530, 5640, 5660, 5733, 5734, 5752, 5768, 5779, 5811, 5849, 5854, 5870, 5902, 5904, 5905, 5938, 5995, 6012, 6032, 6065, 6068, 6083, 6133, 6201, 6208, 6215, 6244, 6267, 6299, 6330, 6383, 6386, 6394, 6401, 6424, 6452, 6498, 6507, 6510, 6560, 6594, 6601, 6623, 6641, 6649, 6793, 6799, 6800, 6805, 6812, 6818, 6820, 6863, 6889, 6902, 6906, 6921, 6990, 37, 46, 47, 60, 74, 91, 95, 111, 122, 130, 151, 152, 157, 159, 175, 184, 195, 201, 204, 213, 219, 225, 228, 233, 242, 251, 288, 302, 307, 311, 329, 339, 348, 359, 388, 390, 395, 399, 400, 407, 422, 433, 440, 443, 445, 458, 466, 498, 505, 517, 540, 543, 548, 549, 553, 556, 568, 588, 625, 627, 629, 630, 652, 655, 661, 664, 679, 680, 686, 689, 703, 712, 713, 725, 731, 738, 741, 747, 760, 804, 819, 838, 843, 848, 855, 856, 875, 877, 881, 904, 1025, 1026, 1029, 1035, 1036, 1037, 1039, 1056, 1061, 1066, 1091, 1097, 1103, 1107, 1138, 1139, 1157, 1159, 1172, 1199, 1202, 1209, 1232, 1233, 1234, 1238, 1240, 1243, 1257, 1266, 1271, 1283, 1285, 1290, 1303, 1319, 1320, 1321, 1338, 1339, 1344, 1349, 1353, 1367, 1372, 1378, 1385, 1398, 1402, 1415, 1428, 1430, 1431, 1453, 1454, 1460, 1468, 1470, 1472, 1479, 1482, 1492, 1499, 1504, 1524, 1531, 1541, 1542, 1551, 1563, 1581, 1600, 1611, 1624, 1659, 1663, 1668, 1678, 1681, 1682, 1687, 1695, 1720, 1723, 1736, 1739, 1743, 1751, 1752, 1756, 1759, 1763, 1764, 1784, 1798, 1801, 1806, 1807, 1813, 1818, 1823, 1844, 1853, 1857, 1860, 1861, 1869, 1870, 1872, 1873, 1879, 1892, 1893, 1894, 1899, 1930, 1939, 1945, 1950, 1972, 1978, 1984, 1996, 2006, 2009, 2013, 2021, 2037, 2044, 2045, 2055, 2061, 2077, 2081, 2102, 2113, 2115, 2122, 2146, 2155, 2162, 2171, 2176, 2178, 2181, 2185, 2186, 2197, 2199, 2225, 2233, 2237, 2241, 2242, 2258, 2275, 2276, 2289, 2290, 2330, 2341, 2346, 2347, 2352, 2357, 2359, 2379, 2383, 2392, 2396, 2407, 2412, 2442, 2446, 2448, 2457, 2469, 2473, 2475, 2489, 2495, 2503, 2515, 2519, 2526, 2533, 2542, 2554, 2564, 2576, 2586, 2593, 2597, 2598, 2615, 2616, 2617, 2624, 2630, 2631, 2647, 2656, 2664, 2688, 2693, 2702, 2703, 2719, 2733, 2747, 2756, 2757, 2759, 2778, 2789, 2798, 2811, 2819, 2820, 2821, 2839, 2866, 2878, 2889, 2927, 2937, 2939, 2953, 2958, 2972, 2975, 2983, 2986, 2988, 2990, 2991, 2993, 3001, 3006, 3009, 3027, 3037, 3044, 3051, 3058, 3070, 3077, 3078, 3082, 3102, 3103, 3110, 3112, 3117, 3126, 3127, 3137, 3145, 3149, 3165, 3166, 3170, 3179, 3181, 3187, 3200, 3202, 3207, 3208, 3209, 3211, 3212, 3222, 3227, 3236, 3239, 3241, 3242, 3245, 3259, 3261, 3278, 3290, 3291, 3294, 3296, 3299, 3309, 3311, 3316, 3326, 3328, 3337, 3338, 3341, 3358, 3374, 3377, 3380, 3382, 3387, 3388, 3392, 3394, 3398, 3399, 3403, 3411, 3413, 3427, 3432, 3435, 3450, 3453, 3464, 3465, 3469, 3471, 3474, 3485, 3486, 3490, 3492, 3494, 3496, 3506, 3510, 3512, 3515, 3526, 3536, 3538, 3539, 3545, 3546, 3550, 3555, 3556, 3557, 3568, 3574, 3587, 3597, 3600, 3603, 3612, 3622, 3628, 3637, 3644, 3653, 3657, 3659, 3660, 3661, 3666, 3671, 3672, 3677, 3697, 3711, 3726, 3731, 3737, 3738, 3739, 3742, 3744, 3760, 3778, 3806, 3813, 3815, 3819, 3833, 3836, 3841, 3846, 3849, 3854, 3864, 3872, 3891, 3892, 3915, 3920, 3934, 3940, 3942, 3950, 3951, 3960, 3963, 3974, 3981, 3982, 4003, 4054, 4056, 4060, 4080, 4083, 4085, 4089, 4091, 4100, 4106, 4125, 4141, 4143, 4145, 4157, 4166, 4181, 4186, 4200, 4276, 4286, 4308, 4309, 4314, 4324, 4355, 4369, 4380, 4383, 4392, 4393, 4396, 4400, 4406, 4408, 4418, 4475, 4479, 4480, 4487, 4494, 4511, 4522, 4562, 4564, 4582, 4602, 4631, 4640, 4646, 4660, 4666, 4676, 4686, 4697, 4698, 4744, 4758, 4784, 4785, 4788, 4832, 4836, 4839, 4848, 4900, 4915, 4917, 4918, 4927, 4946, 4947, 4971, 4976, 4978, 4979, 4982, 4992, 5008, 5023, 5028, 5066, 5082, 5084, 5085, 5089, 5102, 5111, 5115, 5118, 5120, 5122, 5124, 5127, 5128, 5131, 5132, 5136, 5137, 5139, 5140, 5143, 5145, 5146, 5155, 5157, 5161, 5168, 5171, 5176, 5178, 5188, 5189, 5190, 5198, 5200, 5211, 5214, 5222, 5224, 5225, 5226, 5229, 5231, 5244, 5245, 5249, 5251, 5257, 5263, 5265, 5281, 5282, 5284, 5285, 5286, 5290, 5307, 5314, 5320, 5323, 5333, 5334, 5335, 5337, 5339, 5342, 5348, 5351, 5355, 5357, 5365, 5369, 5370, 5374, 5378, 5386, 5392, 5394, 5402, 5407, 5408, 5417, 5423, 5428, 5429, 5430, 5434, 5438, 5439, 5441, 5442, 5463, 5467, 5468, 5477, 5490, 5491, 5514, 5524, 5540, 5547, 5567, 5575, 5581, 5584, 5589, 5591, 5599, 5605, 5613, 5618, 5619, 5622, 5636, 5650, 5651, 5654, 5655, 5659, 5680, 5684, 5685, 5687, 5689, 5697, 5699, 5700, 5702, 5704, 5718, 5722, 5723, 5730, 5736, 5737, 5738, 5740, 5741, 5742, 5747, 5751, 5757, 5759, 5763, 5764, 5766, 5775, 5777, 5780, 5790, 5793, 5809, 5813, 5817, 5818, 5824, 5825, 5828, 5835, 5837, 5851, 5862, 5866, 5867, 5877, 5887, 5918, 5929, 5936, 5950, 5965, 5968, 5971, 5975, 5987, 5992, 6003, 6005, 6007, 6014, 6017, 6019, 6023, 6029, 6042, 6045, 6046, 6052, 6060, 6066, 6078, 6084, 6086, 6092, 6107, 6121, 6122, 6123, 6124, 6125, 6131, 6135, 6136, 6141, 6144, 6146, 6147, 6155, 6156, 6157, 6158, 6163, 6165, 6175, 6181, 6193, 6202, 6206, 6212, 6225, 6238, 6241, 6249, 6252, 6253, 6275, 6276, 6279, 6281, 6288, 6289, 6295, 6302, 6310, 6320, 6327, 6328, 6335, 6350, 6351, 6354, 6369, 6381, 6388, 6395, 6396, 6403, 6440, 6465, 6466, 6474, 6475, 6496, 6501, 6521, 6525, 6534, 6549, 6556, 6566, 6575, 6577, 6580, 6582, 6585, 6593, 6595, 6597, 6602, 6608, 6636, 6643, 6644, 6659, 6674, 6679, 6690, 6712, 6715, 6717, 6724, 6727, 6728, 6729, 6751, 6761, 6777, 6803, 6821, 6831, 6833, 6841, 6845, 6850, 6883, 6892, 6916, 6926, 6943, 6947, 6958, 6973, 6983, 6994, 6995, 6996, 7001, 7009, 20, 26, 33, 36, 41, 45, 49, 53, 59, 62, 109, 144, 153, 155, 163, 167, 176, 178, 189, 220, 223, 240, 248, 254, 255, 260, 297, 301, 312, 315, 317, 334, 345, 356, 360, 375, 406, 409, 427, 438, 448, 465, 474, 486, 488, 526, 528, 531, 551, 554, 561, 595, 608, 623, 634, 650, 675, 677, 682, 684, 693, 714, 753, 766, 767, 779, 829, 858, 1038, 1049, 1050, 1052, 1071, 1089, 1093, 1101, 1108, 1124, 1133, 1135, 1145, 1152, 1155, 1160, 1161, 1167, 1177, 1194, 1196, 1203, 1205, 1211, 1213, 1222, 1223, 1228, 1229, 1235, 1246, 1259, 1277, 1294, 1298, 1315, 1322, 1324, 1342, 1355, 1358, 1384, 1393, 1395, 1403, 1406, 1412, 1420, 1421, 1422, 1423, 1425, 1436, 1446, 1450, 1455, 1464, 1478, 1491, 1517, 1518, 1532, 1537, 1577, 1579, 1612, 1642, 1643, 1669, 1671, 1675, 1676, 1688, 1704, 1708, 1731, 1732, 1749, 1766, 1778, 1793, 1795, 1804, 1814, 1833, 1839, 1845, 1863, 1865, 1875, 1882, 1884, 1886, 1901, 1902, 1915, 1917, 1923, 1926, 1929, 1934, 1936, 1938, 1940, 1946, 1952, 1953, 1961, 1962, 1974, 1989, 1991, 1998, 1999, 2031, 2036, 2040, 2043, 2059, 2060, 2074, 2076, 2078, 2100, 2123, 2151, 2159, 2166, 2182, 2203, 2222, 2250, 2255, 2273, 2281, 2297, 2307, 2338, 2345, 2370, 2378, 2391, 2406, 2415, 2420, 2451, 2501, 2505, 2524, 2538, 2539, 2543, 2544, 2546, 2547, 2552, 2571, 2581, 2585, 2641, 2649, 2671, 2675, 2682, 2691, 2697, 2713, 2717, 2731, 2742, 2755, 2765, 2787, 2804, 2805, 2841, 2843, 2852, 2859, 2881, 2894, 2932, 2938, 2944, 2962, 2963, 2985, 3011, 3022, 3024, 3032, 3055, 3066, 3069, 3073, 3075, 3096, 3097, 3099, 3100, 3122, 3123, 3136, 3138, 3140, 3141, 3143, 3144, 3153, 3178, 3183, 3184, 3188, 3191, 3197, 3201, 3205, 3206, 3216, 3223, 3224, 3226, 3229, 3234, 3246, 3247, 3253, 3257, 3262, 3275, 3276, 3280, 3282, 3295, 3303, 3308, 3325, 3327, 3334, 3336, 3349, 3357, 3365, 3366, 3367, 3373, 3375, 3381, 3393, 3404, 3406, 3408, 3409, 3412, 3415, 3423, 3443, 3444, 3445, 3451, 3455, 3458, 3478, 3488, 3502, 3503, 3505, 3507, 3508, 3531, 3535, 3541, 3549, 3552, 3553, 3558, 3559, 3561, 3564, 3575, 3580, 3586, 3588, 3592, 3605, 3608, 3613, 3614, 3618, 3652, 3665, 3673, 3695, 3698, 3700, 3704, 3708, 3718, 3720, 3722, 3741, 3750, 3751, 3759, 3761, 3770, 3783, 3784, 3788, 3790, 3796, 3810, 3827, 3828, 3839, 3843, 3845, 3852, 3862, 3884, 3908, 3913, 3916, 3938, 3941, 3944, 3945, 3962, 3973, 3987, 4004, 4005, 4006, 4008, 4022, 4024, 4035, 4039, 4046, 4052, 4076, 4078, 4081, 4086, 4088, 4095, 4096, 4097, 4103, 4105, 4107, 4108, 4122, 4133, 4135, 4146, 4153, 4154, 4155, 4159, 4171, 4174, 4176, 4178, 4179, 4185, 4190, 4191, 4192, 4193, 4194, 4204, 4211, 4217, 4220, 4221, 4222, 4227, 4228, 4230, 4245, 4251, 4255, 4264, 4279, 4281, 4312, 4315, 4335, 4337, 4356, 4371, 4374, 4384, 4385, 4387, 4388, 4402, 4409, 4432, 4437, 4439, 4452, 4457, 4466, 4469, 4470, 4473, 4478, 4488, 4492, 4498, 4526, 4539, 4543, 4549, 4555, 4572, 4577, 4589, 4594, 4601, 4614, 4618, 4627, 4632, 4638, 4654, 4661, 4665, 4681, 4685, 4689, 4696, 4705, 4706, 4721, 4726, 4732, 4734, 4767, 4768, 4773, 4776, 4777, 4790, 4801, 4803, 4805, 4809, 4830, 4870, 4896, 4899, 4901, 4906, 4907, 4933, 4949, 4952, 4958, 4962, 4966, 4967, 4980, 5012, 5015, 5027, 5038, 5042, 5052, 5071, 5073, 5081, 5086, 5088, 5093, 5096, 5097, 5104, 5107, 5112, 5125, 5135, 5138, 5141, 5144, 5149, 5150, 5151, 5158, 5172, 5173, 5182, 5185, 5186, 5187, 5191, 5201, 5206, 5213, 5217, 5219, 5227, 5237, 5238, 5239, 5247, 5248, 5253, 5258, 5259, 5264, 5266, 5267, 5268, 5272, 5276, 5277, 5278, 5279, 5280, 5291, 5295, 5297, 5301, 5303, 5309, 5316, 5318, 5319, 5321, 5322, 5324, 5326, 5330, 5336, 5343, 5344, 5345, 5347, 5359, 5361, 5362, 5367, 5375, 5376, 5381, 5387, 5391, 5396, 5397, 5412, 5418, 5422, 5425, 5440, 5444, 5448, 5451, 5452, 5454, 5458, 5461, 5462, 5474, 5481, 5482, 5486, 5489, 5499, 5500, 5504, 5507, 5510, 5511, 5513, 5517, 5520, 5522, 5526, 5527, 5529, 5536, 5539, 5542, 5555, 5557, 5561, 5573, 5579, 5587, 5588, 5594, 5600, 5603, 5604, 5609, 5611, 5617, 5628, 5630, 5635, 5643, 5645, 5662, 5665, 5666, 5671, 5675, 5676, 5686, 5696, 5698, 5701, 5703, 5707, 5711, 5717, 5726, 5728, 5731, 5739, 5745, 5754, 5761, 5770, 5771, 5772, 5778, 5783, 5785, 5795, 5806, 5810, 5816, 5820, 5821, 5822, 5826, 5836, 5838, 5840, 5843, 5845, 5847, 5850, 5853, 5856, 5858, 5860, 5865, 5868, 5871, 5875, 5881, 5886, 5892, 5893, 5896, 5897, 5898, 5901, 5907, 5914, 5919, 5926, 5927, 5928, 5932, 5935, 5943, 5949, 5953, 5954, 5956, 5957, 5958, 5959, 5960, 5964, 5979, 5984, 5996, 6001, 6002, 6015, 6018, 6028, 6034, 6041, 6051, 6053, 6054, 6057, 6058, 6061, 6062, 6064, 6074, 6090, 6095, 6100, 6103, 6104, 6108, 6111, 6126, 6127, 6130, 6137, 6140, 6143, 6148, 6152, 6154, 6166, 6168, 6169, 6170, 6174, 6177, 6178, 6182, 6185, 6186, 6188, 6189, 6192, 6200, 6207, 6221, 6228, 6232, 6239, 6242, 6245, 6248, 6257, 6258, 6260, 6282, 6298, 6304, 6307, 6309, 6312, 6314, 6315, 6316, 6325, 6331, 6352, 6353, 6358, 6359, 6366, 6367, 6370, 6376, 6389, 6390, 6392, 6400, 6409, 6411, 6417, 6421, 6423, 6431, 6435, 6437, 6442, 6446, 6447, 6448, 6453, 6454, 6459, 6464, 6470, 6473, 6482, 6484, 6497, 6511, 6516, 6520, 6524, 6530, 6545, 6546, 6548, 6554, 6558, 6572, 6574, 6578, 6584, 6589, 6590, 6606, 6611, 6617, 6635, 6642, 6647, 6652, 6656, 6660, 6663, 6668, 6678, 6684, 6694, 6696, 6707, 6713, 6714, 6732, 6738, 6739, 6749, 6750, 6752, 6755, 6757, 6770, 6772, 6779, 6780, 6783, 6785, 6808, 6810, 6817, 6823, 6834, 6836, 6838, 6848, 6867, 6868, 6870, 6874, 6887, 6903, 6909, 6910, 6914, 6920, 6923, 6939, 6949, 6953, 6955, 6956, 6959, 6972, 6978, 6988, 6991, 6993, 7002, 64, 65, 72, 73, 80, 86, 89, 97, 108, 116, 119, 123, 137, 168, 177, 182, 190, 208, 216, 237, 239, 244, 259, 269, 272, 274, 286, 351, 355, 362, 377, 378, 397, 401, 424, 426, 429, 436, 437, 461, 462, 481, 525, 527, 533, 535, 542, 581, 604, 605, 631, 633, 639, 654, 691, 710, 718, 720, 724, 751, 763, 768, 771, 772, 780, 789, 828, 836, 861, 901, 906, 912, 913, 1027, 1068, 1080, 1090, 1109, 1113, 1131, 1137, 1149, 1158, 1178, 1225, 1226, 1247, 1250, 1253, 1256, 1263, 1268, 1269, 1288, 1295, 1302, 1317, 1323, 1356, 1363, 1368, 1371, 1374, 1388, 1400, 1409, 1439, 1443, 1458, 1520, 1527, 1534, 1575, 1578, 1589, 1599, 1638, 1645, 1657, 1660, 1683, 1690, 1691, 1702, 1716, 1718, 1733, 1745, 1754, 1758, 1774, 1775, 1809, 1817, 1819, 1841, 1855, 1858, 1876, 1895, 1903, 1914, 1919, 1931, 1935, 1942, 1944, 1957, 1976, 1986, 1987, 1997, 2001, 2005, 2010, 2024, 2047, 2062, 2066, 2079, 2082, 2103, 2148, 2169, 2206, 2228, 2251, 2286, 2299, 2306, 2315, 2319, 2329, 2349, 2361, 2375, 2389, 2405, 2432, 2444, 2447, 2449, 2477, 2492, 2587, 2622, 2667, 2668, 2679, 2684, 2698, 2751, 2752, 2766, 2769, 2774, 2784, 2790, 2824, 2826, 2847, 2851, 2855, 2902, 2919, 2924, 2997, 2999, 3010, 3039, 3057, 3062, 3067, 3071, 3081, 3086, 3087, 3093, 3095, 3106, 3108, 3109, 3114, 3115, 3118, 3129, 3130, 3132, 3133, 3135, 3152, 3155, 3160, 3169, 3171, 3174, 3190, 3204, 3240, 3255, 3258, 3264, 3265, 3269, 3270, 3271, 3274, 3281, 3287, 3315, 3324, 3333, 3335, 3339, 3344, 3352, 3360, 3371, 3385, 3417, 3418, 3420, 3424, 3428, 3429, 3431, 3440, 3441, 3442, 3446, 3461, 3484, 3491, 3511, 3530, 3540, 3542, 3544, 3548, 3566, 3570, 3571, 3573, 3576, 3582, 3583, 3602, 3606, 3620, 3624, 3625, 3633, 3636, 3651, 3656, 3670, 3674, 3680, 3685, 3706, 3707, 3716, 3717, 3724, 3753, 3754, 3769, 3773, 3775, 3776, 3779, 3786, 3793, 3797, 3803, 3804, 3808, 3820, 3835, 3842, 3863, 3866, 3870, 3881, 3887, 3889, 3896, 3902, 3909, 3917, 3921, 3946, 3948, 3953, 3966, 3980, 3988, 3990, 3992, 4018, 4026, 4027, 4028, 4040, 4042, 4055, 4064, 4070, 4073, 4075, 4077, 4082, 4084, 4090, 4092, 4111, 4113, 4114, 4115, 4116, 4123, 4124, 4126, 4129, 4132, 4134, 4138, 4142, 4150, 4152, 4158, 4167, 4172, 4202, 4206, 4208, 4210, 4213, 4224, 4239, 4246, 4249, 4256, 4259, 4265, 4267, 4273, 4282, 4285, 4293, 4295, 4297, 4303, 4307, 4310, 4317, 4318, 4329, 4340, 4349, 4357, 4359, 4365, 4378, 4386, 4390, 4411, 4415, 4420, 4421, 4427, 4431, 4435, 4441, 4442, 4444, 4446, 4450, 4453, 4461, 4464, 4467, 4471, 4472, 4481, 4483, 4485, 4500, 4506, 4507, 4512, 4517, 4518, 4529, 4533, 4538, 4541, 4554, 4568, 4569, 4571, 4573, 4579, 4584, 4593, 4597, 4600, 4606, 4608, 4611, 4630, 4639, 4642, 4657, 4659, 4669, 4671, 4674, 4680, 4687, 4690, 4704, 4707, 4708, 4728, 4735, 4737, 4743, 4752, 4756, 4757, 4763, 4764, 4802, 4821, 4824, 4826, 4841, 4849, 4850, 4851, 4852, 4856, 4857, 4858, 4859, 4861, 4862, 4873, 4884, 4916, 4928, 4943, 4957, 4963, 5014, 5016, 5017, 5019, 5035, 5037, 5040, 5044, 5053, 5054, 5056, 5075, 5077, 5080, 5090, 5099, 5103, 5108, 5116, 5129, 5142, 5153, 5156, 5165, 5166, 5167, 5170, 5174, 5179, 5181, 5183, 5192, 5193, 5194, 5196, 5197, 5207, 5216, 5218, 5221, 5223, 5228, 5230, 5232, 5233, 5235, 5269, 5283, 5289, 5300, 5304, 5305, 5312, 5317, 5329, 5331, 5338, 5341, 5349, 5353, 5356, 5358, 5366, 5368, 5377, 5380, 5382, 5383, 5385, 5389, 5403, 5410, 5411, 5416, 5427, 5431, 5435, 5436, 5443, 5445, 5446, 5447, 5453, 5455, 5456, 5457, 5459, 5460, 5464, 5465, 5478, 5479, 5492, 5494, 5502, 5503, 5505, 5509, 5512, 5519, 5521, 5523, 5528, 5531, 5532, 5533, 5537, 5541, 5543, 5544, 5552, 5553, 5563, 5566, 5569, 5583, 5590, 5602, 5625, 5626, 5631, 5639, 5642, 5644, 5646, 5648, 5652, 5656, 5667, 5677, 5678, 5681, 5682, 5690, 5693, 5694, 5709, 5715, 5729, 5732, 5743, 5746, 5748, 5750, 5753, 5765, 5769, 5781, 5807, 5814, 5815, 5832, 5839, 5846, 5857, 5861, 5863, 5872, 5873, 5876, 5903, 5906, 5916, 5923, 5933, 5934, 5942, 5955, 5961, 5963, 5972, 5974, 5978, 5982, 5983, 5988, 5989, 5998, 6006, 6008, 6011, 6024, 6025, 6027, 6035, 6037, 6048, 6055, 6056, 6072, 6075, 6079, 6085, 6094, 6109, 6113, 6115, 6117, 6120, 6129, 6150, 6172, 6179, 6180, 6183, 6194, 6196, 6197, 6198, 6213, 6214, 6217, 6218, 6222, 6224, 6229, 6237, 6240, 6243, 6246, 6256, 6261, 6266, 6273, 6277, 6280, 6284, 6286, 6291, 6293, 6300, 6301, 6306, 6311, 6318, 6322, 6323, 6329, 6332, 6342, 6346, 6349, 6365, 6397, 6398, 6407, 6410, 6425, 6432, 6439, 6443, 6445, 6449, 6450, 6451, 6460, 6463, 6468, 6492, 6493, 6494, 6502, 6508, 6514, 6517, 6526, 6528, 6532, 6541, 6564, 6579, 6583, 6587, 6588, 6603, 6609, 6610, 6612, 6615, 6618, 6621, 6625, 6627, 6633, 6648, 6665, 6666, 6669, 6685, 6695, 6698, 6709, 6711, 6735, 6736, 6737, 6740, 6745, 6746, 6748, 6756, 6767, 6769, 6787, 6794, 6798, 6801, 6815, 6822, 6824, 6829, 6837, 6840, 6854, 6856, 6881, 6884, 6895, 6896, 6899, 6901, 6912, 6934, 6944, 6948, 6960, 6964, 6966, 6967, 6970, 6975, 6976, 6989, 6999, 7008, 92, 134, 143, 180, 252, 267, 335, 336, 353, 361, 383, 418, 430, 447, 450, 473, 500, 529, 571, 578, 750, 777, 831, 832, 837, 907, 920, 922, 1023, 1065, 1067, 1075, 1083, 1084, 1086, 1098, 1128, 1148, 1154, 1164, 1165, 1210, 1220, 1251, 1261, 1286, 1300, 1307, 1326, 1329, 1337, 1343, 1386, 1389, 1394, 1424, 1438, 1451, 1456, 1465, 1510, 1514, 1530, 1533, 1538, 1569, 1582, 1610, 1631, 1634, 1637, 1646, 1650, 1693, 1697, 1722, 1726, 1727, 1730, 1737, 1787, 1789, 1821, 1825, 1854, 1862, 1880, 1904, 1911, 1912, 1949, 1954, 1958, 1960, 2028, 2095, 2108, 2114, 2116, 2129, 2131, 2132, 2173, 2183, 2323, 2387, 2397, 2402, 2411, 2416, 2419, 2429, 2430, 2480, 2502, 2514, 2527, 2541, 2557, 2563, 2572, 2580, 2588, 2595, 2629, 2655, 2676, 2681, 2695, 2706, 2723, 2732, 2743, 2772, 2816, 2818, 2838, 2849, 2863, 2869, 2893, 2901, 2920, 2926, 2954, 2957, 2964, 2976, 3028, 3068, 3074, 3076, 3080, 3085, 3090, 3157, 3159, 3167, 3175, 3189, 3215, 3217, 3219, 3272, 3285, 3292, 3300, 3301, 3310, 3321, 3354, 3356, 3362, 3368, 3379, 3390, 3414, 3421, 3426, 3448, 3463, 3477, 3479, 3481, 3501, 3513, 3517, 3518, 3528, 3551, 3567, 3569, 3596, 3599, 3607, 3611, 3621, 3629, 3631, 3632, 3648, 3658, 3668, 3669, 3679, 3682, 3687, 3690, 3699, 3712, 3713, 3727, 3734, 3755, 3758, 3762, 3763, 3772, 3782, 3795, 3801, 3809, 3831, 3834, 3857, 3859, 3868, 3869, 3877, 3882, 3895, 3903, 3904, 3933, 3935, 3939, 3952, 3967, 3971, 3984, 3993, 4000, 4020, 4034, 4044, 4048, 4050, 4066, 4067, 4068, 4110, 4117, 4118, 4121, 4130, 4131, 4140, 4160, 4161, 4163, 4182, 4184, 4195, 4196, 4199, 4205, 4207, 4215, 4216, 4231, 4236, 4242, 4243, 4247, 4250, 4254, 4266, 4269, 4274, 4278, 4280, 4291, 4311, 4313, 4319, 4322, 4330, 4331, 4333, 4338, 4344, 4347, 4348, 4350, 4358, 4373, 4375, 4376, 4389, 4395, 4398, 4401, 4405, 4407, 4416, 4417, 4422, 4426, 4454, 4456, 4460, 4465, 4468, 4489, 4499, 4501, 4504, 4509, 4510, 4524, 4525, 4527, 4528, 4530, 4535, 4547, 4552, 4576, 4590, 4599, 4607, 4621, 4624, 4629, 4633, 4643, 4645, 4648, 4651, 4656, 4663, 4672, 4675, 4678, 4693, 4694, 4699, 4700, 4711, 4713, 4719, 4720, 4724, 4741, 4753, 4760, 4769, 4796, 4808, 4825, 4828, 4835, 4837, 4838, 4853, 4871, 4903, 4913, 4921, 4950, 4959, 4960, 4961, 4964, 4970, 4985, 4993, 5001, 5005, 5006, 5011, 5039, 5046, 5060, 5076, 5078, 5083, 5091, 5100, 5109, 5123, 5159, 5162, 5195, 5202, 5203, 5215, 5243, 5262, 5270, 5287, 5296, 5310, 5325, 5346, 5372, 5379, 5400, 5401, 5406, 5409, 5414, 5415, 5433, 5437, 5470, 5471, 5473, 5475, 5480, 5484, 5498, 5508, 5534, 5535, 5545, 5551, 5554, 5556, 5558, 5568, 5586, 5595, 5597, 5598, 5614, 5615, 5616, 5620, 5621, 5632, 5633, 5647, 5661, 5663, 5664, 5691, 5710, 5716, 5721, 5724, 5725, 5735, 5755, 5758, 5767, 5773, 5774, 5776, 5782, 5784, 5789, 5791, 5792, 5796, 5798, 5804, 5827, 5830, 5833, 5834, 5841, 5844, 5852, 5855, 5859, 5874, 5880, 5883, 5884, 5889, 5890, 5891, 5910, 5913, 5924, 5939, 5940, 5941, 5944, 5946, 5947, 5948, 5962, 5973, 5976, 5986, 5993, 5997, 5999, 6009, 6016, 6020, 6022, 6030, 6031, 6033, 6047, 6049, 6050, 6067, 6069, 6071, 6073, 6081, 6088, 6093, 6096, 6097, 6102, 6106, 6116, 6118, 6138, 6151, 6153, 6167, 6184, 6190, 6203, 6231, 6234, 6235, 6250, 6251, 6255, 6271, 6278, 6285, 6290, 6294, 6297, 6313, 6319, 6324, 6343, 6362, 6368, 6372, 6373, 6377, 6378, 6387, 6391, 6393, 6404, 6408, 6413, 6429, 6433, 6444, 6456, 6457, 6462, 6469, 6480, 6488, 6495, 6504, 6505, 6506, 6513, 6518, 6527, 6536, 6537, 6538, 6544, 6557, 6561, 6569, 6570, 6573, 6576, 6591, 6592, 6598, 6604, 6605, 6634, 6638, 6640, 6661, 6662, 6671, 6673, 6677, 6682, 6683, 6697, 6703, 6705, 6710, 6716, 6741, 6742, 6743, 6744, 6754, 6760, 6765, 6782, 6784, 6795, 6802, 6804, 6809, 6811, 6819, 6828, 6830, 6842, 6844, 6864, 6871, 6877, 6880, 6888, 6891, 6894, 6908, 6911, 6922, 6937, 6982, 7004, 148, 200, 212, 221, 273, 279, 292, 293, 363, 368, 373, 387, 456, 469, 497, 504, 532, 590, 593, 602, 613, 632, 667, 687, 690, 717, 737, 774, 830, 885, 902, 1042, 1045, 1058, 1121, 1200, 1227, 1313, 1331, 1332, 1352, 1369, 1370, 1387, 1437, 1452, 1477, 1495, 1535, 1536, 1539, 1555, 1556, 1595, 1604, 1605, 1658, 1664, 1686, 1694, 1735, 1738, 1742, 1744, 1761, 1771, 1772, 1812, 1822, 1837, 1851, 1887, 1905, 1933, 1951, 1979, 1995, 2011, 2016, 2023, 2027, 2098, 2118, 2140, 2141, 2192, 2240, 2270, 2271, 2283, 2298, 2301, 2324, 2441, 2508, 2540, 2589, 2609, 2636, 2653, 2737, 2800, 2823, 2984, 3015, 3049, 3092, 3098, 3121, 3125, 3186, 3196, 3203, 3213, 3225, 3244, 3266, 3284, 3288, 3320, 3407, 3437, 3449, 3456, 3470, 3480, 3483, 3497, 3529, 3565, 3604, 3623, 3640, 3662, 3678, 3691, 3693, 3705, 3721, 3723, 3729, 3733, 3765, 3766, 3777, 3792, 3799, 3811, 3818, 3826, 3844, 3847, 3856, 3860, 3861, 3865, 3875, 3878, 3883, 3888, 3899, 3900, 3907, 3923, 3927, 3959, 3965, 3976, 3977, 3978, 3998, 4021, 4038, 4045, 4047, 4053, 4072, 4079, 4119, 4137, 4144, 4147, 4148, 4156, 4168, 4169, 4170, 4175, 4177, 4187, 4201, 4212, 4218, 4219, 4232, 4233, 4235, 4237, 4240, 4244, 4260, 4262, 4275, 4277, 4292, 4296, 4300, 4302, 4321, 4341, 4345, 4352, 4353, 4361, 4362, 4366, 4414, 4430, 4449, 4455, 4458, 4495, 4497, 4513, 4516, 4523, 4534, 4540, 4544, 4557, 4563, 4567, 4574, 4578, 4580, 4581, 4585, 4586, 4587, 4603, 4626, 4636, 4653, 4662, 4667, 4691, 4692, 4702, 4710, 4717, 4718, 4730, 4736, 4745, 4750, 4780, 4781, 4787, 4791, 4798, 4811, 4827, 4846, 4847, 4854, 4875, 4877, 4889, 4891, 4892, 4894, 4897, 4902, 4922, 4923, 4929, 4930, 4932, 4935, 4968, 4991, 4996, 5004, 5021, 5022, 5034, 5041, 5050, 5059, 5063, 5092, 5094, 5106, 5148, 5209, 5234, 5254, 5260, 5275, 5298, 5308, 5315, 5363, 5371, 5426, 5496, 5506, 5515, 5538, 5546, 5548, 5560, 5570, 5572, 5578, 5580, 5582, 5585, 5596, 5601, 5608, 5610, 5612, 5624, 5629, 5641, 5649, 5653, 5657, 5658, 5669, 5670, 5672, 5673, 5683, 5688, 5692, 5708, 5713, 5714, 5720, 5744, 5787, 5788, 5797, 5799, 5812, 5829, 5831, 5842, 5864, 5869, 5878, 5879, 5882, 5900, 5908, 5912, 5917, 5931, 5945, 5951, 5980, 5981, 5985, 5990, 5991, 5994, 6000, 6004, 6010, 6021, 6026, 6036, 6043, 6044, 6070, 6142, 6145, 6159, 6173, 6209, 6216, 6233, 6236, 6247, 6254, 6262, 6264, 6269, 6272, 6341, 6363, 6371, 6375, 6418, 6419, 6426, 6428, 6430, 6436, 6455, 6458, 6472, 6476, 6477, 6478, 6489, 6490, 6491, 6500, 6519, 6523, 6540, 6542, 6547, 6552, 6565, 6568, 6600, 6613, 6616, 6619, 6624, 6626, 6628, 6637, 6639, 6658, 6670, 6680, 6686, 6687, 6689, 6704, 6722, 6730, 6731, 6733, 6734, 6778, 6781, 6786, 6788, 6816, 6843, 6852, 6855, 6859, 6861, 6873, 6875, 6907, 6917, 6929, 6932, 6933, 6935, 6945, 6950, 6957, 6971, 6974, 6981, 6998, 7003, 7005, 7006, 7007, 107, 147, 156, 210, 231, 268, 313, 320, 332, 382, 398, 446, 475, 485, 490, 507, 596, 620, 653, 663, 688, 705, 707, 723, 1028, 1076, 1102, 1116, 1193, 1197, 1206, 1239, 1258, 1272, 1273, 1310, 1346, 1445, 1466, 1476, 1506, 1507, 1547, 1548, 1561, 1566, 1573, 1594, 1596, 1626, 1627, 1635, 1753, 1769, 1791, 1794, 1852, 1864, 1897, 1909, 1916, 2017, 2019, 2070, 2125, 2247, 2303, 2388, 2403, 2537, 2596, 2600, 2606, 2632, 2704, 2777, 2795, 2942, 3012, 3013, 3019, 3038, 3043, 3045, 3056, 3091, 3128, 3139, 3176, 3177, 3273, 3322, 3340, 3410, 3438, 3476, 3495, 3521, 3537, 3543, 3563, 3593, 3609, 3610, 3681, 3683, 3689, 3710, 3743, 3752, 3757, 3791, 3794, 3807, 3814, 3851, 3858, 3893, 3918, 3994, 3995, 4007, 4013, 4017, 4112, 4162, 4173, 4197, 4209, 4214, 4225, 4234, 4238, 4241, 4252, 4298, 4305, 4306, 4325, 4336, 4367, 4372, 4379, 4381, 4399, 4424, 4429, 4434, 4445, 4459, 4474, 4477, 4493, 4502, 4515, 4519, 4532, 4536, 4537, 4596, 4598, 4617, 4619, 4625, 4634, 4637, 4652, 4658, 4668, 4695, 4716, 4725, 4731, 4739, 4740, 4748, 4749, 4751, 4772, 4782, 4783, 4799, 4810, 4813, 4831, 4842, 4845, 4879, 4882, 4883, 4885, 4888, 4904, 4909, 4910, 4912, 4931, 4934, 4939, 4948, 4973, 5007, 5020, 5024, 5025, 5032, 5036, 5048, 5065, 5069, 5070, 5079, 5119, 5126, 5180, 5208, 5241, 5246, 5250, 5273, 5288, 5293, 5311, 5332, 5373, 5390, 5399, 5419, 5421, 5450, 5487, 5488, 5495, 5525, 5562, 5565, 5576, 5592, 5606, 5637, 5712, 5801, 5848, 5888, 5894, 5909, 5922, 5952, 6039, 6040, 6059, 6076, 6087, 6089, 6091, 6112, 6119, 6134, 6160, 6164, 6223, 6227, 6268, 6283, 6292, 6305, 6317, 6333, 6337, 6339, 6345, 6347, 6355, 6361, 6380, 6382, 6384, 6405, 6416, 6422, 6427, 6479, 6503, 6512, 6522, 6581, 6596, 6607, 6614, 6632, 6653, 6672, 6706, 6719, 6723, 6747, 6758, 6759, 6768, 6814, 6826, 6865, 6898, 6900, 6925, 6927, 6941, 6979, 6984, 6992, 76, 100, 164, 192, 194, 235, 264, 265, 318, 367, 393, 520, 537, 557, 572, 573, 577, 582, 584, 586, 658, 716, 822, 824, 826, 909, 921, 1044, 1062, 1081, 1143, 1162, 1171, 1241, 1334, 1376, 1434, 1487, 1782, 1964, 1973, 1988, 2106, 2208, 2223, 2291, 2294, 2417, 2456, 2466, 2481, 2512, 2614, 2654, 2677, 2735, 2771, 2783, 2877, 2892, 2947, 3064, 3104, 3105, 3134, 3154, 3251, 3286, 3306, 3312, 3317, 3319, 3361, 3384, 3386, 3489, 3498, 3499, 3534, 3547, 3641, 3645, 3649, 3675, 3714, 3719, 3740, 3747, 3780, 3805, 3853, 3871, 3983, 4002, 4032, 4033, 4058, 4188, 4203, 4261, 4283, 4289, 4294, 4316, 4327, 4334, 4364, 4382, 4394, 4403, 4412, 4447, 4484, 4490, 4508, 4570, 4588, 4612, 4682, 4683, 4712, 4722, 4733, 4747, 4761, 4762, 4771, 4779, 4793, 4797, 4800, 4818, 4840, 4843, 4864, 4865, 4878, 4895, 4898, 4919, 4941, 4951, 4954, 4969, 4977, 5000, 5002, 5013, 5033, 5072, 5199, 5212, 5306, 5469, 5476, 5577, 5627, 5634, 5674, 5679, 5706, 5719, 5794, 5800, 5819, 5899, 5966, 5970, 6038, 6063, 6099, 6128, 6139, 6210, 6259, 6274, 6334, 6360, 6379, 6402, 6533, 6539, 6551, 6563, 6645, 6646, 6650, 6667, 6753, 6791, 6797, 6825, 6839, 6847, 6858, 6860, 6872, 6876, 6897, 6913, 6915, 6930, 6942, 6952, 6962, 7010, 7013, 88, 309, 331, 337, 489, 509, 510, 534, 569, 570, 598, 599, 659, 660, 702, 914, 1070, 1095, 1182, 1212, 1215, 1391, 1712, 1840, 1847, 2004, 2051, 2163, 2231, 2421, 2497, 2644, 2651, 2661, 2810, 2888, 3120, 3195, 3231, 3343, 3347, 3369, 3422, 3454, 3468, 3522, 3577, 3615, 3626, 3638, 3664, 3667, 3732, 3824, 3830, 3848, 3855, 3880, 3919, 3932, 3937, 4010, 4030, 4136, 4226, 4229, 4304, 4323, 4342, 4343, 4346, 4351, 4377, 4404, 4436, 4438, 4491, 4545, 4556, 4566, 4622, 4641, 4670, 4727, 4738, 4755, 4770, 4774, 4786, 4795, 4855, 4905, 4955, 4986, 5087, 5098, 5177, 5313, 5449, 5501, 5564, 5574, 5623, 5802, 5803, 5911, 5921, 6013, 6176, 6195, 6211, 6230, 6287, 6308, 6321, 6357, 6441, 6461, 6553, 6567, 6622, 6629, 6630, 6664, 6676, 6693, 6699, 6708, 6776, 6807, 6832, 6886, 6928, 6936, 6946, 6969, 6977, 6980, 263, 376, 389, 494, 538, 685, 1169, 1248, 1260, 1411, 1483, 1677, 1967, 1982, 2007, 2134, 2309, 2310, 2394, 2410, 2455, 2506, 2511, 2642, 2711, 2897, 2898, 2974, 3113, 3151, 3230, 3252, 3493, 3516, 3520, 3562, 3654, 3787, 3825, 3829, 3876, 3928, 3929, 3930, 4071, 4104, 4127, 4128, 4139, 4180, 4263, 4339, 4391, 4419, 4433, 4463, 4476, 4482, 4542, 4546, 4551, 4559, 4575, 4583, 4778, 4794, 4814, 4820, 4834, 4936, 4938, 5009, 5010, 5062, 5805, 5808, 5915, 6098, 6101, 6149, 6204, 6205, 6265, 6270, 6303, 6412, 6414, 6486, 6562, 6586, 6813, 6954, 6986, 185, 186, 229, 327, 350, 478, 597, 614, 776, 1706, 1724, 1808, 1831, 1908, 2152, 2424, 2491, 2768, 2879, 2968, 3084, 3277, 3314, 3397, 3457, 3466, 3519, 3709, 3816, 3879, 3922, 4025, 4061, 4248, 4268, 4360, 4410, 4440, 4514, 4531, 4565, 4595, 4610, 4615, 4703, 4709, 4746, 4765, 4819, 4829, 4833, 4867, 4869, 4911, 4914, 4920, 4994, 5003, 5026, 5043, 5354, 5398, 5404, 5823, 6171, 6263, 6296, 6348, 6364, 6385, 6487, 6620, 6681, 6700, 6762, 6771, 6775, 6862, 6904, 149, 347, 384, 391, 910, 1134, 1153, 1521, 1648, 1661, 1881, 1965, 2119, 2143, 2313, 3146, 3364, 3472, 3616, 3634, 3748, 3955, 3964, 3975, 3999, 4151, 4428, 4443, 4521, 4613, 4628, 4655, 4874, 4940, 4945, 4987, 5018, 5049, 5210, 5668, 5695, 5760, 5762, 6114, 6226, 6406, 6420, 6434, 6467, 6550, 6655, 6796, 6890, 6919, 6940, 6951, 365, 523, 1047, 1357, 1489, 1494, 2069, 2135, 2987, 2996, 3147, 3359, 3914, 4223, 4272, 4320, 4370, 4462, 4616, 4684, 4868, 4953, 4997, 5236, 5393, 5885, 6344, 6374, 6438, 6599, 6918, 277, 328, 340, 435, 471, 651, 726, 1041, 1092, 1475, 1545, 1592, 1705, 1838, 2158, 2195, 2627, 2754, 2956, 3088, 3248, 3433, 3646, 3767, 4012, 4031, 4183, 4271, 4723, 4775, 4812, 4937, 4944, 4975, 6082, 6161, 6162, 6220, 6340, 6718, 6720, 6763, 6774, 6963, 245, 289, 645, 769, 1416, 1553, 1602, 1750, 1877, 2640, 2665, 3101, 3307, 3527, 3578, 3594, 3676, 4051, 4328, 4451, 4817, 6555, 6827, 253, 496, 565, 616, 657, 1224, 1297, 1444, 1613, 2091, 2193, 2264, 2278, 3297, 3554, 3885, 4792, 5061, 5571, 6399, 6485, 6789, 6835, 140, 173, 754, 1866, 2279, 2461, 3376, 3475, 3647, 4448, 4714, 5045, 5095, 6080, 6499, 6535, 739, 890, 1786, 3072, 4332, 4363, 5607, 6338, 6531, 6571, 421, 452, 518, 1426, 1427, 3210, 3342, 3434, 4988, 6483, 6631, 6654, 6806, 261, 316, 423, 442, 2918, 3060, 3372, 3500, 4623, 4650, 6199, 6481, 6726, 770, 878, 1490, 2707, 2865, 4503, 4591, 4604, 4789, 6559, 6764, 6849, 6893, 93, 428, 820, 1249, 1262, 3589, 4823, 6529, 6651, 1802, 2350, 4326, 1292, 2196, 3692, 5030, 5068, 580, 1301, 4807, 6326, 6336, 2165, 2334, 3642, 896, 1955, 5121, 6851, 454, 484, 503, 701, 758, 1558, 1607, 4965, 6882, 2905, 2836, 4299, 6702, 6968, 1941, 2096, 3745, 1985, 1404, 3730, 7011, 476, 752, 2064, 3094, 3969, 4766, 6657, 911, 5058, 381, 1276, 4550, 3996, 1119, 1502, 1622, 4284, 5925, 2639, 6543, 3643, 6792, 803, 818, 3905]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>843222</td>\n",
       "      <td>scikit-learn: machine learning in Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>843222</td>\n",
       "      <td>scikit-learn: machine learning in Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>843222</td>\n",
       "      <td>scikit-learn: machine learning in Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1555490</td>\n",
       "      <td>Applied Machine Learning in Python with scikit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>87338160</td>\n",
       "      <td>Machine Learning with Scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>111050726</td>\n",
       "      <td>Introductory Machine Learning in Python with S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>114791904</td>\n",
       "      <td>Machine Learning using python (scikit-learn)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>1555490</td>\n",
       "      <td>Applied Machine Learning in Python with scikit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38441254</td>\n",
       "      <td>Automated Machine Learning with scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>58676336</td>\n",
       "      <td>Machine Learning with Text in scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>84170448</td>\n",
       "      <td>Tutorials on Machine Learning with Scikit-Learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>147727066</td>\n",
       "      <td>Advanced Machine Learning with Scikit-learn pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>62497456</td>\n",
       "      <td>Machine Learning using Scikit-Learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>14819599</td>\n",
       "      <td>Machine Learning using scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>127122388</td>\n",
       "      <td>Fundamentals of Machine Learning with Scikit-L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>73592597</td>\n",
       "      <td>Mastering Machine Learning with scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>155359382</td>\n",
       "      <td>Machine Learning with Scikit-Learn and TensorFlow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>165835923</td>\n",
       "      <td>practical machine learning with Scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>99813486</td>\n",
       "      <td>Machine Learning tutorial with scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>30430764</td>\n",
       "      <td>iPython + scikit-learn for machine learning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>41616504</td>\n",
       "      <td>A machine learning project in Python using sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>70309099</td>\n",
       "      <td>Machine learning using python package scikit-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>110678736</td>\n",
       "      <td>Machine Learning Implementation with Scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>119686814</td>\n",
       "      <td>C√≥digos de prueba de Machine Learning con Pyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>14470709</td>\n",
       "      <td>scikit-learn with python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>103577321</td>\n",
       "      <td>Learning Scikit Learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>100234123</td>\n",
       "      <td>Python, scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>147357781</td>\n",
       "      <td>Learning scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>38441254</td>\n",
       "      <td>Automated Machine Learning with scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>58676336</td>\n",
       "      <td>Machine Learning with Text in scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>2658203</td>\n",
       "      <td>Matlab/Octave toolbox for deep learning. Inclu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>9863189</td>\n",
       "      <td>Old source for jakevdp.github.io. New source a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>55781523</td>\n",
       "      <td>This repository generates precompiled opencv-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>53145263</td>\n",
       "      <td>Using a paper from Google DeepMind I've develo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7011</th>\n",
       "      <td>61758076</td>\n",
       "      <td>Bi-directional Attention Flow (BiDAF) network ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>97159209</td>\n",
       "      <td>A comprehensive list of Deep Learning / Artifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>115483120</td>\n",
       "      <td>A research project that aims to detect Parkins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>97159209</td>\n",
       "      <td>A comprehensive list of Deep Learning / Artifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3094</th>\n",
       "      <td>97159209</td>\n",
       "      <td>A comprehensive list of Deep Learning / Artifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3969</th>\n",
       "      <td>112754789</td>\n",
       "      <td>The SAS Deep Learning Python (DLPy) package pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4766</th>\n",
       "      <td>99011249</td>\n",
       "      <td>This journey helps to build a complete end-to-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6657</th>\n",
       "      <td>86862739</td>\n",
       "      <td>This application demonstrates the deployment o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>127626092</td>\n",
       "      <td>Autism Detection APIThis project has 3 goals: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5058</th>\n",
       "      <td>98909530</td>\n",
       "      <td>This repository contains instructions for data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>125754555</td>\n",
       "      <td>The project aims at building a machine learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>3638964</td>\n",
       "      <td>Ansible is a radically simple IT automation pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4550</th>\n",
       "      <td>26385494</td>\n",
       "      <td>Notebooks for financial economics. Keywords:  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>130710498</td>\n",
       "      <td>personal practiceÔºà‰∏™‰∫∫ÁªÉ‰π†ÔºåÂÆûÁé∞‰∫ÜÊ∑±Â∫¶Â≠¶‰π†‰∏≠ÁöÑ‰∏Ä‰∫õÁÆóÊ≥ïÔºåÂåÖÊã¨ÔºöÂõõÁßçÂàùÂßãÂåñÊñπ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>19868085</td>\n",
       "      <td>Kalman Filter book using Jupyter Notebook. Foc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>22502757</td>\n",
       "      <td>MySQL Connector/Python is implementing the MyS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>22502757</td>\n",
       "      <td>MySQL Connector/Python is implementing the MyS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4284</th>\n",
       "      <td>19868085</td>\n",
       "      <td>Kalman Filter book using Jupyter Notebook. Foc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5925</th>\n",
       "      <td>60275653</td>\n",
       "      <td>Describes and solves some simple HACT models i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>53488315</td>\n",
       "      <td>Repo for my graduate data science machine lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6543</th>\n",
       "      <td>84884505</td>\n",
       "      <td>In this code we provide a full roadmap the dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3643</th>\n",
       "      <td>114274023</td>\n",
       "      <td>A deep learning method for event driven stock ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6792</th>\n",
       "      <td>145553672</td>\n",
       "      <td>‰∏≠Ëã±ÊñáÊïèÊÑüËØç„ÄÅËØ≠Ë®ÄÊ£ÄÊµã„ÄÅ‰∏≠Â§ñÊâãÊú∫/ÁîµËØùÂΩíÂ±ûÂú∞/ËøêËê•ÂïÜÊü•ËØ¢„ÄÅÂêçÂ≠óÊé®Êñ≠ÊÄßÂà´„ÄÅÊâãÊú∫Âè∑ÊäΩÂèñ„ÄÅË∫´‰ªΩËØÅÊäΩ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>103323816</td>\n",
       "      <td>This was my Master's project where i was invol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>103323816</td>\n",
       "      <td>This was my Master's project where i was invol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3905</th>\n",
       "      <td>114604751</td>\n",
       "      <td>Tumour is formed in human body by abnormal cel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7014 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                        description\n",
       "0        843222           scikit-learn: machine learning in Python\n",
       "1094     843222           scikit-learn: machine learning in Python\n",
       "2052     843222           scikit-learn: machine learning in Python\n",
       "27      1555490  Applied Machine Learning in Python with scikit...\n",
       "515    87338160                 Machine Learning with Scikit-learn\n",
       "642   111050726  Introductory Machine Learning in Python with S...\n",
       "649   114791904       Machine Learning using python (scikit-learn)\n",
       "2959    1555490  Applied Machine Learning in Python with scikit...\n",
       "4      38441254       Automated Machine Learning with scikit-learn\n",
       "13     58676336         Machine Learning with Text in scikit-learn\n",
       "39     84170448    Tutorials on Machine Learning with Scikit-Learn\n",
       "84    147727066  Advanced Machine Learning with Scikit-learn pa...\n",
       "110    62497456                Machine Learning using Scikit-Learn\n",
       "121    14819599                Machine Learning using scikit-learn\n",
       "126   127122388  Fundamentals of Machine Learning with Scikit-L...\n",
       "258    73592597       Mastering Machine Learning with scikit-learn\n",
       "262   155359382  Machine Learning with Scikit-Learn and TensorFlow\n",
       "333   165835923       practical machine learning with Scikit-learn\n",
       "396    99813486        Machine Learning tutorial with scikit-learn\n",
       "402    30430764       iPython + scikit-learn for machine learning.\n",
       "413    41616504  A machine learning project in Python using sci...\n",
       "733    70309099  Machine learning using python package scikit-l...\n",
       "734   110678736  Machine Learning Implementation with Scikit-learn\n",
       "908   119686814  C√≥digos de prueba de Machine Learning con Pyth...\n",
       "924    14470709                          scikit-learn with python \n",
       "945   103577321                              Learning Scikit Learn\n",
       "976   100234123                               Python, scikit-learn\n",
       "991   147357781                              Learning scikit-learn\n",
       "2154   38441254       Automated Machine Learning with scikit-learn\n",
       "2282   58676336         Machine Learning with Text in scikit-learn\n",
       "...         ...                                                ...\n",
       "3745    2658203  Matlab/Octave toolbox for deep learning. Inclu...\n",
       "1985    9863189  Old source for jakevdp.github.io. New source a...\n",
       "1404   55781523  This repository generates precompiled opencv-p...\n",
       "3730   53145263  Using a paper from Google DeepMind I've develo...\n",
       "7011   61758076  Bi-directional Attention Flow (BiDAF) network ...\n",
       "476    97159209  A comprehensive list of Deep Learning / Artifi...\n",
       "752   115483120  A research project that aims to detect Parkins...\n",
       "2064   97159209  A comprehensive list of Deep Learning / Artifi...\n",
       "3094   97159209  A comprehensive list of Deep Learning / Artifi...\n",
       "3969  112754789  The SAS Deep Learning Python (DLPy) package pr...\n",
       "4766   99011249  This journey helps to build a complete end-to-...\n",
       "6657   86862739  This application demonstrates the deployment o...\n",
       "911   127626092  Autism Detection APIThis project has 3 goals: ...\n",
       "5058   98909530  This repository contains instructions for data...\n",
       "381   125754555  The project aims at building a machine learnin...\n",
       "1276    3638964  Ansible is a radically simple IT automation pl...\n",
       "4550   26385494  Notebooks for financial economics. Keywords:  ...\n",
       "3996  130710498  personal practiceÔºà‰∏™‰∫∫ÁªÉ‰π†ÔºåÂÆûÁé∞‰∫ÜÊ∑±Â∫¶Â≠¶‰π†‰∏≠ÁöÑ‰∏Ä‰∫õÁÆóÊ≥ïÔºåÂåÖÊã¨ÔºöÂõõÁßçÂàùÂßãÂåñÊñπ...\n",
       "1119   19868085  Kalman Filter book using Jupyter Notebook. Foc...\n",
       "1502   22502757  MySQL Connector/Python is implementing the MyS...\n",
       "1622   22502757  MySQL Connector/Python is implementing the MyS...\n",
       "4284   19868085  Kalman Filter book using Jupyter Notebook. Foc...\n",
       "5925   60275653  Describes and solves some simple HACT models i...\n",
       "2639   53488315  Repo for my graduate data science machine lear...\n",
       "6543   84884505  In this code we provide a full roadmap the dep...\n",
       "3643  114274023  A deep learning method for event driven stock ...\n",
       "6792  145553672  ‰∏≠Ëã±ÊñáÊïèÊÑüËØç„ÄÅËØ≠Ë®ÄÊ£ÄÊµã„ÄÅ‰∏≠Â§ñÊâãÊú∫/ÁîµËØùÂΩíÂ±ûÂú∞/ËøêËê•ÂïÜÊü•ËØ¢„ÄÅÂêçÂ≠óÊé®Êñ≠ÊÄßÂà´„ÄÅÊâãÊú∫Âè∑ÊäΩÂèñ„ÄÅË∫´‰ªΩËØÅÊäΩ...\n",
       "803   103323816  This was my Master's project where i was invol...\n",
       "818   103323816  This was my Master's project where i was invol...\n",
       "3905  114604751  Tumour is formed in human body by abnormal cel...\n",
       "\n",
       "[7014 rows x 2 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_most_similar = [x[0] for x in sims]\n",
    "\n",
    "print(top_10_most_similar)\n",
    "\n",
    "repo_desc_df.iloc[top_10_most_similar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:49:16.508197Z",
     "start_time": "2019-03-27T01:49:16.338418Z"
    }
   },
   "outputs": [],
   "source": [
    "result = g.get_user('fchollet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:49:17.113656Z",
     "start_time": "2019-03-27T01:49:16.944371Z"
    }
   },
   "outputs": [],
   "source": [
    "chollet_response = requests.get('https://api.github.com/users/fchollet/repos').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:17:48.069080Z",
     "start_time": "2019-03-27T02:17:48.063845Z"
    }
   },
   "outputs": [],
   "source": [
    "chollet_data = [result.avatar_url, result.bio, result.blog, result.id, result.email, result.location]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:17:49.038015Z",
     "start_time": "2019-03-27T02:17:48.446Z"
    }
   },
   "outputs": [],
   "source": [
    "# fchollet\n",
    "# https://github.com/fchollet\n",
    "chollet_repo_descriptions = chollet_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:17:51.462664Z",
     "start_time": "2019-03-27T02:17:51.455405Z"
    }
   },
   "outputs": [],
   "source": [
    "chollet_repo_descriptions = [[x['id'],\n",
    "                             x['name'],\n",
    "                             x['description']]\n",
    "                             for x in chollet_response]\n",
    "\n",
    "chollet_df = pd.DataFrame(chollet_repo_descriptions)\n",
    "chollet_df.columns = ['id', 'name', 'description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T18:10:30.912035Z",
     "start_time": "2019-03-26T18:10:30.894789Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:17:53.134743Z",
     "start_time": "2019-03-27T02:17:53.131711Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = chollet_df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:04:54.407565Z",
     "start_time": "2019-03-27T02:04:54.400761Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Stores documents used by the TensorFlow develo...\n",
       "1    Keras code and weights files for popular deep ...\n",
       "2    Jupyter notebooks for the code samples of the ...\n",
       "3                    Keras Total Visualization project\n",
       "4          Blog with Keras news, tutorials, and demos.\n",
       "5    Directory of tutorials and open-source code re...\n",
       "6    Pure Python/Numpy implementation of the Nelder...\n",
       "7    An Open Source Machine Learning Framework for ...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:18:00.547402Z",
     "start_time": "2019-03-27T02:18:00.540810Z"
    }
   },
   "outputs": [],
   "source": [
    "l = vectorizer.transform(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:18:01.471273Z",
     "start_time": "2019-03-27T02:18:00.840Z"
    }
   },
   "outputs": [],
   "source": [
    "ch_nmf = nmf_model.transform(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:18:02.393815Z",
     "start_time": "2019-03-27T02:18:02.372635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>machine_learning</th>\n",
       "      <th>scikit_learn</th>\n",
       "      <th>jupyter_notebook</th>\n",
       "      <th>python_library</th>\n",
       "      <th>nlp</th>\n",
       "      <th>julia_package</th>\n",
       "      <th>kubernetes</th>\n",
       "      <th>deep_learning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stores documents used by the TensorFlow develo...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Keras code and weights files for popular deep ...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Keras Total Visualization project</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blog with Keras news, tutorials, and demos.</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Directory of tutorials and open-source code re...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pure Python/Numpy implementation of the Nelder...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>An Open Source Machine Learning Framework for ...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               index  machine_learning  \\\n",
       "0  Stores documents used by the TensorFlow develo...              0.00   \n",
       "1  Keras code and weights files for popular deep ...              0.01   \n",
       "2  Jupyter notebooks for the code samples of the ...              0.01   \n",
       "3                  Keras Total Visualization project              0.00   \n",
       "4        Blog with Keras news, tutorials, and demos.              0.00   \n",
       "5  Directory of tutorials and open-source code re...              0.01   \n",
       "6  Pure Python/Numpy implementation of the Nelder...              0.00   \n",
       "7  An Open Source Machine Learning Framework for ...              0.17   \n",
       "\n",
       "   scikit_learn  jupyter_notebook  python_library   nlp  julia_package  \\\n",
       "0          0.01              0.00            0.00  0.01           0.00   \n",
       "1          0.00              0.01            0.01  0.20           0.01   \n",
       "2          0.00              0.25            0.20  0.19           0.00   \n",
       "3          0.00              0.00            0.00  0.00           0.00   \n",
       "4          0.00              0.00            0.00  0.01           0.00   \n",
       "5          0.00              0.01            0.22  0.20           0.02   \n",
       "6          0.01              0.00            0.19  0.00           0.00   \n",
       "7          0.00              0.00            0.00  0.00           0.00   \n",
       "\n",
       "   kubernetes  deep_learning  \n",
       "0        0.00           0.02  \n",
       "1        0.01           0.01  \n",
       "2        0.00           0.00  \n",
       "3        0.00           0.02  \n",
       "4        0.00           0.01  \n",
       "5        0.01           0.00  \n",
       "6        0.00           0.00  \n",
       "7        0.01           0.00  "
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chollet_topic_df = pd.DataFrame(ch_nmf.round(2),\n",
    "             index = sample.values,\n",
    "             columns = [\"machine_learning\",\"scikit_learn\",\"jupyter_notebook\",\"python_library\",\"nlp\",\"julia_package\", \"kubernetes\", \"deep_learning\"])\n",
    "chollet_topic_df.reset_index()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:18:03.329353Z",
     "start_time": "2019-03-27T02:18:02.850Z"
    }
   },
   "outputs": [],
   "source": [
    "chollet_topic_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:18:03.333369Z",
     "start_time": "2019-03-27T02:18:03.311Z"
    }
   },
   "outputs": [],
   "source": [
    "H.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:18:04.236982Z",
     "start_time": "2019-03-27T02:18:04.067Z"
    }
   },
   "outputs": [],
   "source": [
    "H = H.rename(columns={'index': 'description'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:18:38.061132Z",
     "start_time": "2019-03-27T02:18:38.041478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>description</th>\n",
       "      <th>machine_learning</th>\n",
       "      <th>scikit_learn</th>\n",
       "      <th>jupyter_notebook</th>\n",
       "      <th>python_library</th>\n",
       "      <th>nlp</th>\n",
       "      <th>julia_package</th>\n",
       "      <th>kubernetes</th>\n",
       "      <th>deep_learning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stores documents used by the TensorFlow develo...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Keras code and weights files for popular deep ...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Keras Total Visualization project</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Blog with Keras news, tutorials, and demos.</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Directory of tutorials and open-source code re...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Pure Python/Numpy implementation of the Nelder...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>An Open Source Machine Learning Framework for ...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0                                        description  \\\n",
       "0        0  Stores documents used by the TensorFlow develo...   \n",
       "1        1  Keras code and weights files for popular deep ...   \n",
       "2        2  Jupyter notebooks for the code samples of the ...   \n",
       "3        3                  Keras Total Visualization project   \n",
       "4        4        Blog with Keras news, tutorials, and demos.   \n",
       "5        5  Directory of tutorials and open-source code re...   \n",
       "6        6  Pure Python/Numpy implementation of the Nelder...   \n",
       "7        7  An Open Source Machine Learning Framework for ...   \n",
       "\n",
       "   machine_learning  scikit_learn  jupyter_notebook  python_library   nlp  \\\n",
       "0              0.00          0.01              0.00            0.00  0.01   \n",
       "1              0.01          0.00              0.01            0.01  0.20   \n",
       "2              0.01          0.00              0.25            0.20  0.19   \n",
       "3              0.00          0.00              0.00            0.00  0.00   \n",
       "4              0.00          0.00              0.00            0.00  0.01   \n",
       "5              0.01          0.00              0.01            0.22  0.20   \n",
       "6              0.00          0.01              0.00            0.19  0.00   \n",
       "7              0.17          0.00              0.00            0.00  0.00   \n",
       "\n",
       "   julia_package  kubernetes  deep_learning  \n",
       "0           0.00        0.00           0.02  \n",
       "1           0.01        0.01           0.01  \n",
       "2           0.00        0.00           0.00  \n",
       "3           0.00        0.00           0.02  \n",
       "4           0.00        0.00           0.01  \n",
       "5           0.02        0.01           0.00  \n",
       "6           0.00        0.00           0.00  \n",
       "7           0.00        0.01           0.00  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chollet_topic_df = chollet_topic_df.reset_index().rename(columns={'index':'description'})\n",
    "chollet_topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:04:58.641070Z",
     "start_time": "2019-03-27T02:04:58.570Z"
    }
   },
   "outputs": [],
   "source": [
    "# chollet_topic_df['topic'] = chollet_topic_df.apply(lambda row: row.max(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:04:59.320038Z",
     "start_time": "2019-03-27T02:04:59.316914Z"
    }
   },
   "outputs": [],
   "source": [
    "# chollet_topic_df['topic_name'] ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:22:11.802666Z",
     "start_time": "2019-03-27T02:22:11.784687Z"
    }
   },
   "outputs": [],
   "source": [
    "# chollet_topic_df['topic'] = chollet_topic_df[chollet_topic_df.columns[1:]].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:22:12.743738Z",
     "start_time": "2019-03-27T02:22:12.189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>description</th>\n",
       "      <th>machine_learning</th>\n",
       "      <th>scikit_learn</th>\n",
       "      <th>jupyter_notebook</th>\n",
       "      <th>python_library</th>\n",
       "      <th>nlp</th>\n",
       "      <th>julia_package</th>\n",
       "      <th>kubernetes</th>\n",
       "      <th>deep_learning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stores documents used by the TensorFlow develo...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Keras code and weights files for popular deep ...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Keras Total Visualization project</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Blog with Keras news, tutorials, and demos.</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Directory of tutorials and open-source code re...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Pure Python/Numpy implementation of the Nelder...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>An Open Source Machine Learning Framework for ...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0                                        description  \\\n",
       "0        0  Stores documents used by the TensorFlow develo...   \n",
       "1        1  Keras code and weights files for popular deep ...   \n",
       "2        2  Jupyter notebooks for the code samples of the ...   \n",
       "3        3                  Keras Total Visualization project   \n",
       "4        4        Blog with Keras news, tutorials, and demos.   \n",
       "5        5  Directory of tutorials and open-source code re...   \n",
       "6        6  Pure Python/Numpy implementation of the Nelder...   \n",
       "7        7  An Open Source Machine Learning Framework for ...   \n",
       "\n",
       "   machine_learning  scikit_learn  jupyter_notebook  python_library   nlp  \\\n",
       "0              0.00          0.01              0.00            0.00  0.01   \n",
       "1              0.01          0.00              0.01            0.01  0.20   \n",
       "2              0.01          0.00              0.25            0.20  0.19   \n",
       "3              0.00          0.00              0.00            0.00  0.00   \n",
       "4              0.00          0.00              0.00            0.00  0.01   \n",
       "5              0.01          0.00              0.01            0.22  0.20   \n",
       "6              0.00          0.01              0.00            0.19  0.00   \n",
       "7              0.17          0.00              0.00            0.00  0.00   \n",
       "\n",
       "   julia_package  kubernetes  deep_learning  \n",
       "0           0.00        0.00           0.02  \n",
       "1           0.01        0.01           0.01  \n",
       "2           0.00        0.00           0.00  \n",
       "3           0.00        0.00           0.02  \n",
       "4           0.00        0.00           0.01  \n",
       "5           0.02        0.01           0.00  \n",
       "6           0.00        0.00           0.00  \n",
       "7           0.00        0.01           0.00  "
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chollet_topic_df.rename({'index': 'description'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:22:16.508027Z",
     "start_time": "2019-03-27T02:22:16.496674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.00571031, 0.00294522, 0.00149709, 0.00924963,\n",
       "        0.0006237 , 0.0019694 , 0.02231686],\n",
       "       [0.00530911, 0.00407025, 0.00621452, 0.01355474, 0.20132291,\n",
       "        0.00776761, 0.00723878, 0.00738104],\n",
       "       [0.00525101, 0.        , 0.24551242, 0.20203006, 0.19249606,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.00170917, 0.00183863, 0.00025369, 0.00419402,\n",
       "        0.00082093, 0.00027362, 0.02402569],\n",
       "       [0.        , 0.00262276, 0.00485558, 0.00147038, 0.00684076,\n",
       "        0.00154466, 0.00140575, 0.00968324],\n",
       "       [0.00931961, 0.0013896 , 0.00697552, 0.2193278 , 0.19930021,\n",
       "        0.01785355, 0.00753978, 0.        ],\n",
       "       [0.        , 0.00553441, 0.        , 0.19439256, 0.00144745,\n",
       "        0.00410594, 0.        , 0.        ],\n",
       "       [0.17059091, 0.        , 0.        , 0.00144301, 0.00110822,\n",
       "        0.0030741 , 0.00588604, 0.00249088]])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:23:17.130513Z",
     "start_time": "2019-03-27T02:23:17.110661Z"
    }
   },
   "outputs": [],
   "source": [
    "p = pairwise_distances(ch_nmf, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:50:32.874216Z",
     "start_time": "2019-03-27T01:50:32.859271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:50:27.772352Z",
     "start_time": "2019-03-27T01:50:27.759710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:50:28.173926Z",
     "start_time": "2019-03-27T01:50:28.150279Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.0),\n",
       " (3, 0.007083326878197232),\n",
       " (4, 0.013407461274424689),\n",
       " (7, 0.17211402975176376),\n",
       " (1, 0.19334160491950453),\n",
       " (6, 0.19440239224066452),\n",
       " (5, 0.29071833563492605),\n",
       " (2, 0.36495761417028066)]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = sorted(enumerate(p[0]), key=lambda item: item[1])\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:19:43.145654Z",
     "start_time": "2019-03-27T02:19:43.130405Z"
    }
   },
   "outputs": [],
   "source": [
    "most_similar = []\n",
    "\n",
    "for dist in p:\n",
    "    sim = sorted(enumerate(dist), key=lambda item: item[1])\n",
    "    most_similar.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T16:10:20.188216Z",
     "start_time": "2019-03-26T16:10:19.939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(most_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T16:10:20.192325Z",
     "start_time": "2019-03-26T16:10:20.108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.0)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T16:10:20.305203Z",
     "start_time": "2019-03-26T16:10:20.296323Z"
    }
   },
   "outputs": [],
   "source": [
    "first_repo_similarities = [x[0][0] for x in most_similar]\n",
    "second_repo_similarities = [x[1][0] for x in most_similar]\n",
    "third_repo_similarities = [x[2][0] for x in most_similar]\n",
    "fourth_repo_similarities = [x[3][0] for x in most_similar]\n",
    "fifth_repo_similarities = [x[4][0] for x in most_similar]\n",
    "sixth_repo_similarities = [x[5][0] for x in most_similar]\n",
    "seventh_repo_similarities = [x[6][0] for x in most_similar]\n",
    "eighth_repo_similarities = [x[7][0] for x in most_similar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:04:00.395531Z",
     "start_time": "2019-03-27T02:04:00.373529Z"
    }
   },
   "outputs": [],
   "source": [
    "repo_1 = pd.DataFrame(repo_desc_df.iloc[first_repo_similarities])\n",
    "repo_2 = pd.DataFrame(repo_desc_df.iloc[second_repo_similarities])\n",
    "repo_3 = pd.DataFrame(repo_desc_df.iloc[third_repo_similarities])\n",
    "repo_4 = pd.DataFrame(repo_desc_df.iloc[fourth_repo_similarities])\n",
    "repo_5 = pd.DataFrame(repo_desc_df.iloc[fifth_repo_similarities])\n",
    "repo_6 = pd.DataFrame(repo_desc_df.iloc[sixth_repo_similarities])\n",
    "repo_7 = pd.DataFrame(repo_desc_df.iloc[seventh_repo_similarities])\n",
    "repo_8 = pd.DataFrame(repo_desc_df.iloc[eighth_repo_similarities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T18:25:49.585544Z",
     "start_time": "2019-03-26T18:25:49.573813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38441254</td>\n",
       "      <td>Automated Machine Learning with scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38441254</td>\n",
       "      <td>Automated Machine Learning with scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33462633</td>\n",
       "      <td>Jupyter notebooks from the scikit-learn video ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38441254</td>\n",
       "      <td>Automated Machine Learning with scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104967369</td>\n",
       "      <td>:book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33462633</td>\n",
       "      <td>Jupyter notebooks from the scikit-learn video ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>843222</td>\n",
       "      <td>scikit-learn: machine learning in Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104967369</td>\n",
       "      <td>:book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                        description\n",
       "4   38441254       Automated Machine Learning with scikit-learn\n",
       "4   38441254       Automated Machine Learning with scikit-learn\n",
       "1   33462633  Jupyter notebooks from the scikit-learn video ...\n",
       "4   38441254       Automated Machine Learning with scikit-learn\n",
       "3  104967369              :book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£\n",
       "1   33462633  Jupyter notebooks from the scikit-learn video ...\n",
       "0     843222           scikit-learn: machine learning in Python\n",
       "3  104967369              :book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T00:56:41.173682Z",
     "start_time": "2019-03-27T00:56:41.127233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>843222</td>\n",
       "      <td>scikit-learn: machine learning in Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33462633</td>\n",
       "      <td>Jupyter notebooks from the scikit-learn video ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25257051</td>\n",
       "      <td>PySpark + Scikit-learn = Sparkit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104967369</td>\n",
       "      <td>:book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38441254</td>\n",
       "      <td>Automated Machine Learning with scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>54307265</td>\n",
       "      <td>Scikit-learn tutorial at SciPy2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42127722</td>\n",
       "      <td>Materials for my scikit-learn tutorial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60101534</td>\n",
       "      <td>scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                        description\n",
       "0     843222           scikit-learn: machine learning in Python\n",
       "1   33462633  Jupyter notebooks from the scikit-learn video ...\n",
       "2   25257051             PySpark + Scikit-learn = Sparkit-learn\n",
       "3  104967369              :book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£\n",
       "4   38441254       Automated Machine Learning with scikit-learn\n",
       "5   54307265                 Scikit-learn tutorial at SciPy2016\n",
       "6   42127722             Materials for my scikit-learn tutorial\n",
       "7   60101534                          scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:03:55.961586Z",
     "start_time": "2019-03-27T02:03:55.942318Z"
    }
   },
   "outputs": [],
   "source": [
    "repo_1 = pd.DataFrame(repo_desc_df.iloc[first_repo_similarities]).reset_index()\n",
    "repo_2 = pd.DataFrame(repo_desc_df.iloc[second_repo_similarities]).reset_index()\n",
    "repo_3 = pd.DataFrame(repo_desc_df.iloc[third_repo_similarities]).reset_index()\n",
    "repo_4 = pd.DataFrame(repo_desc_df.iloc[fourth_repo_similarities]).reset_index()\n",
    "repo_5 = pd.DataFrame(repo_desc_df.iloc[fifth_repo_similarities]).reset_index()\n",
    "repo_6 = pd.DataFrame(repo_desc_df.iloc[sixth_repo_similarities]).reset_index()\n",
    "repo_7 = pd.DataFrame(repo_desc_df.iloc[seventh_repo_similarities]).reset_index()\n",
    "repo_8 = pd.DataFrame(repo_desc_df.iloc[eighth_repo_similarities]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dict = {\n",
    "    'repo_1': repo_1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:03:51.553356Z",
     "start_time": "2019-03-27T02:03:51.539131Z"
    }
   },
   "outputs": [],
   "source": [
    "# relevant repo_ids\n",
    "repo_ids = (list(repo_1['id']) \n",
    "            + list(repo_2['id'])\n",
    "            + list(repo_3['id'])\n",
    "            + list(repo_4['id'])\n",
    "            + list(repo_5['id'])\n",
    "            + list(repo_6['id'])\n",
    "            + list(repo_7['id'])\n",
    "            + list(repo_8['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:03:52.448236Z",
     "start_time": "2019-03-27T02:03:51.901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[54307265, 38441254, 33462633, 42127722, 104967369, 843222, 25257051, 60101534]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = list(set(sorted(repo_ids)))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:02:27.989608Z",
     "start_time": "2019-03-27T02:02:27.951094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>machine_learning</th>\n",
       "      <th>scikit_learn</th>\n",
       "      <th>jupyter_notebook</th>\n",
       "      <th>python_library</th>\n",
       "      <th>nlp</th>\n",
       "      <th>julia_package</th>\n",
       "      <th>kubernetes</th>\n",
       "      <th>deep_learning</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scikit-learn: machine learning in Python</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jupyter notebooks from the scikit-learn video ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>jupyter_notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PySpark + Scikit-learn = Sparkit-learn</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automated Machine Learning with scikit-learn</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Scikit-learn tutorial at SciPy2016</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Materials for my scikit-learn tutorial</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Source code for the \"Learning scikit-learn: Ma...</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>machine_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Scikit-Learn tutorial material for Scipy 2015</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Simplified interface for TensorFlow (mimicking...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Tutorial on scikit-learn and IPython for paral...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Scikit-learn integration package for Apache Spark</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Machine Learning with Text in scikit-learn</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hidden Markov Models in Python, with scikit-le...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>python_library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Materials for my Pycon 2015 scikit-learn tutor...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Some sample IPython notebooks for scikit-learn</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dive into Machine Learning with Python Jupyter...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>jupyter_notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Scikit-Learn, NLTK, Spacy, Gensim, Textblob an...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Julia implementation of the scikit-learn API</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A scikit-learn compatible neural network libra...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Scikit-learn compatible tools using theano</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Scikit-learn tutorials for the Scipy 2013 conf...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>scikit-learn compatible projects</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Scikit-Learn tutorials</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>scikit-learn inspired API for CRFsuite</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Repository containing files for my PyCon 2014 ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Applied Machine Learning in Python with scikit...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Scikit-Learn Tutorial for PyData Seattle 2015</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Scikit-learn style model finetuning for NLP</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>scikit_learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6984</th>\n",
       "      <td>Curated list of Linguistic Resources for doing...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6985</th>\n",
       "      <td></td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>machine_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6986</th>\n",
       "      <td>List of projects related to Natural Language P...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>machine_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6988</th>\n",
       "      <td>NLP course at Chulalongkorn University</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>jupyter_notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>Some frequently used NLP blocks I implemented</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990</th>\n",
       "      <td>NLP Sandbox</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>machine_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6991</th>\n",
       "      <td>Vietnamese NLP Toolkit for Node</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>machine_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6992</th>\n",
       "      <td>Toy Python implementation of http://www-nlp.st...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>python_library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6993</th>\n",
       "      <td>tensorflowÂÆûÊàòÁªÉ‰π†ÔºåÂåÖÊã¨Âº∫ÂåñÂ≠¶‰π†„ÄÅÊé®ËçêÁ≥ªÁªü„ÄÅnlpÁ≠â</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>machine_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6994</th>\n",
       "      <td>Deep Learning Chinese Word Segment</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>NLPCC 2016 ÂæÆÂçöÂàÜËØçËØÑÊµãÈ°πÁõÆ</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>machine_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>Âêå‰πâËØçË°®ÔºåÂèç‰πâËØçË°®ÔºåÂê¶ÂÆöËØçË°®</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>machine_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>Áà¨Ëô´‰∏éÊú∫Âô®Â≠¶‰π†</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>machine_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>NLP Education Tools by YuZhen(www.yuzhenkeji.com)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>python_library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>NLP reading group at the University of Arizona</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7000</th>\n",
       "      <td>in progress</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>machine_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7001</th>\n",
       "      <td>Lectures for Udemy - INLP</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>machine_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7002</th>\n",
       "      <td>A NLP library for Russian language</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>julia_package</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7003</th>\n",
       "      <td>Study E-Book(ComputerVision DeepLearning Machi...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>python_library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7004</th>\n",
       "      <td>Python implementation of TextRank for text doc...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>python_library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7005</th>\n",
       "      <td>üí´  Models for the spaCy Natural Language Proce...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>python_library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7006</th>\n",
       "      <td>\"End-To-End Memory Networks\" in Tensorflow</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>deep_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7007</th>\n",
       "      <td>Deprecated in favor of https://github.com/face...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>python_library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7008</th>\n",
       "      <td>A very brief introduction to Natural Language ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>python_library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7009</th>\n",
       "      <td>Time-NLPÁöÑpython3ÁâàÊú¨ ‰∏≠ÊñáÊó∂Èó¥Ë°®ËææËØçËΩ¨Êç¢</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>machine_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7010</th>\n",
       "      <td>A companion repository for the \"Writing code f...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>python_library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7011</th>\n",
       "      <td>Bi-directional Attention Flow (BiDAF) network ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>deep_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7012</th>\n",
       "      <td></td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>machine_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7013</th>\n",
       "      <td>Tensorflow Tutorial files and Implementations ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>nlp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7014 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description  machine_learning  \\\n",
       "0              scikit-learn: machine learning in Python              0.17   \n",
       "1     Jupyter notebooks from the scikit-learn video ...              0.00   \n",
       "2                PySpark + Scikit-learn = Sparkit-learn              0.00   \n",
       "3                 :book: [ËØë] scikit-learnÔºàsklearnÔºâ ‰∏≠ÊñáÊñáÊ°£              0.00   \n",
       "4          Automated Machine Learning with scikit-learn              0.17   \n",
       "5                    Scikit-learn tutorial at SciPy2016              0.00   \n",
       "6                Materials for my scikit-learn tutorial              0.00   \n",
       "7                             scikit-learnÊú∫Âô®Â≠¶‰π†Â∫ì‰∏≠ÊñáÊñáÊ°£ÁøªËØëÈ°πÁõÆ              0.00   \n",
       "8     Source code for the \"Learning scikit-learn: Ma...              0.23   \n",
       "9         Scikit-Learn tutorial material for Scipy 2015              0.00   \n",
       "10    Simplified interface for TensorFlow (mimicking...              0.00   \n",
       "11    Tutorial on scikit-learn and IPython for paral...              0.17   \n",
       "12    Scikit-learn integration package for Apache Spark              0.00   \n",
       "13           Machine Learning with Text in scikit-learn              0.17   \n",
       "14    Hidden Markov Models in Python, with scikit-le...              0.00   \n",
       "15    Materials for my Pycon 2015 scikit-learn tutor...              0.00   \n",
       "16       Some sample IPython notebooks for scikit-learn              0.00   \n",
       "17    Dive into Machine Learning with Python Jupyter...              0.16   \n",
       "18    Scikit-Learn, NLTK, Spacy, Gensim, Textblob an...              0.00   \n",
       "19         Julia implementation of the scikit-learn API              0.00   \n",
       "20    A scikit-learn compatible neural network libra...              0.00   \n",
       "21           Scikit-learn compatible tools using theano              0.00   \n",
       "22    Scikit-learn tutorials for the Scipy 2013 conf...              0.00   \n",
       "23                     scikit-learn compatible projects              0.00   \n",
       "24                               Scikit-Learn tutorials              0.00   \n",
       "25               scikit-learn inspired API for CRFsuite              0.00   \n",
       "26    Repository containing files for my PyCon 2014 ...              0.00   \n",
       "27    Applied Machine Learning in Python with scikit...              0.17   \n",
       "28        Scikit-Learn Tutorial for PyData Seattle 2015              0.00   \n",
       "29          Scikit-learn style model finetuning for NLP              0.00   \n",
       "...                                                 ...               ...   \n",
       "6984  Curated list of Linguistic Resources for doing...              0.00   \n",
       "6985                                                                 0.00   \n",
       "6986  List of projects related to Natural Language P...              0.00   \n",
       "6987                                             Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ              0.00   \n",
       "6988             NLP course at Chulalongkorn University              0.00   \n",
       "6989      Some frequently used NLP blocks I implemented              0.00   \n",
       "6990                                        NLP Sandbox              0.00   \n",
       "6991                    Vietnamese NLP Toolkit for Node              0.00   \n",
       "6992  Toy Python implementation of http://www-nlp.st...              0.00   \n",
       "6993                    tensorflowÂÆûÊàòÁªÉ‰π†ÔºåÂåÖÊã¨Âº∫ÂåñÂ≠¶‰π†„ÄÅÊé®ËçêÁ≥ªÁªü„ÄÅnlpÁ≠â              0.00   \n",
       "6994                Deep Learning Chinese Word Segment               0.00   \n",
       "6995                                NLPCC 2016 ÂæÆÂçöÂàÜËØçËØÑÊµãÈ°πÁõÆ              0.00   \n",
       "6996                                     Âêå‰πâËØçË°®ÔºåÂèç‰πâËØçË°®ÔºåÂê¶ÂÆöËØçË°®              0.00   \n",
       "6997                                            Áà¨Ëô´‰∏éÊú∫Âô®Â≠¶‰π†              0.00   \n",
       "6998  NLP Education Tools by YuZhen(www.yuzhenkeji.com)              0.00   \n",
       "6999     NLP reading group at the University of Arizona              0.00   \n",
       "7000                                        in progress              0.00   \n",
       "7001                          Lectures for Udemy - INLP              0.00   \n",
       "7002                 A NLP library for Russian language              0.00   \n",
       "7003  Study E-Book(ComputerVision DeepLearning Machi...              0.00   \n",
       "7004  Python implementation of TextRank for text doc...              0.00   \n",
       "7005  üí´  Models for the spaCy Natural Language Proce...              0.00   \n",
       "7006         \"End-To-End Memory Networks\" in Tensorflow              0.00   \n",
       "7007  Deprecated in favor of https://github.com/face...              0.00   \n",
       "7008  A very brief introduction to Natural Language ...              0.00   \n",
       "7009                       Time-NLPÁöÑpython3ÁâàÊú¨ ‰∏≠ÊñáÊó∂Èó¥Ë°®ËææËØçËΩ¨Êç¢              0.00   \n",
       "7010  A companion repository for the \"Writing code f...              0.01   \n",
       "7011  Bi-directional Attention Flow (BiDAF) network ...              0.00   \n",
       "7012                                                                 0.00   \n",
       "7013  Tensorflow Tutorial files and Implementations ...              0.00   \n",
       "\n",
       "      scikit_learn  jupyter_notebook  python_library   nlp  julia_package  \\\n",
       "0             0.18              0.00            0.18  0.00           0.00   \n",
       "1             0.18              0.24            0.00  0.00           0.00   \n",
       "2             0.27              0.00            0.00  0.00           0.00   \n",
       "3             0.18              0.00            0.00  0.00           0.00   \n",
       "4             0.18              0.00            0.00  0.00           0.00   \n",
       "5             0.19              0.00            0.00  0.00           0.00   \n",
       "6             0.19              0.00            0.00  0.00           0.00   \n",
       "7             0.09              0.00            0.00  0.00           0.00   \n",
       "8             0.18              0.00            0.20  0.06           0.00   \n",
       "9             0.19              0.00            0.00  0.00           0.00   \n",
       "10            0.18              0.00            0.00  0.20           0.01   \n",
       "11            0.19              0.01            0.00  0.00           0.00   \n",
       "12            0.18              0.00            0.00  0.00           0.02   \n",
       "13            0.18              0.00            0.00  0.00           0.00   \n",
       "14            0.18              0.00            0.19  0.00           0.00   \n",
       "15            0.19              0.00            0.00  0.00           0.00   \n",
       "16            0.18              0.10            0.00  0.00           0.00   \n",
       "17            0.18              0.20            0.18  0.00           0.00   \n",
       "18            0.18              0.00            0.00  0.00           0.00   \n",
       "19            0.18              0.00            0.01  0.00           0.18   \n",
       "20            0.19              0.00            0.01  0.01           0.01   \n",
       "21            0.18              0.00            0.00  0.00           0.00   \n",
       "22            0.18              0.00            0.00  0.00           0.00   \n",
       "23            0.18              0.00            0.00  0.00           0.00   \n",
       "24            0.18              0.00            0.00  0.00           0.00   \n",
       "25            0.18              0.00            0.01  0.00           0.00   \n",
       "26            0.19              0.01            0.00  0.00           0.00   \n",
       "27            0.18              0.00            0.18  0.00           0.00   \n",
       "28            0.19              0.00            0.00  0.00           0.00   \n",
       "29            0.18              0.00            0.00  0.00           0.00   \n",
       "...            ...               ...             ...   ...            ...   \n",
       "6984          0.00              0.00            0.00  0.01           0.00   \n",
       "6985          0.00              0.00            0.00  0.00           0.00   \n",
       "6986          0.00              0.00            0.01  0.02           0.02   \n",
       "6987          0.00              0.00            0.00  0.00           0.00   \n",
       "6988          0.00              0.01            0.00  0.01           0.00   \n",
       "6989          0.00              0.00            0.00  0.01           0.00   \n",
       "6990          0.00              0.00            0.00  0.00           0.00   \n",
       "6991          0.00              0.00            0.00  0.00           0.00   \n",
       "6992          0.00              0.00            0.20  0.01           0.00   \n",
       "6993          0.00              0.00            0.00  0.00           0.00   \n",
       "6994          0.00              0.00            0.00  0.19           0.00   \n",
       "6995          0.00              0.00            0.00  0.00           0.00   \n",
       "6996          0.00              0.00            0.00  0.00           0.00   \n",
       "6997          0.00              0.00            0.00  0.00           0.00   \n",
       "6998          0.00              0.00            0.01  0.01           0.00   \n",
       "6999          0.00              0.00            0.00  0.01           0.00   \n",
       "7000          0.00              0.00            0.00  0.00           0.00   \n",
       "7001          0.00              0.00            0.00  0.00           0.00   \n",
       "7002          0.00              0.00            0.02  0.01           0.03   \n",
       "7003          0.00              0.00            0.20  0.01           0.00   \n",
       "7004          0.00              0.00            0.20  0.01           0.00   \n",
       "7005          0.01              0.00            0.03  0.02           0.03   \n",
       "7006          0.01              0.00            0.00  0.01           0.00   \n",
       "7007          0.00              0.00            0.01  0.00           0.00   \n",
       "7008          0.00              0.00            0.20  0.01           0.02   \n",
       "7009          0.00              0.00            0.00  0.00           0.00   \n",
       "7010          0.01              0.02            0.03  0.01           0.01   \n",
       "7011          0.00              0.00            0.00  0.00           0.00   \n",
       "7012          0.00              0.00            0.00  0.00           0.00   \n",
       "7013          0.02              0.00            0.00  0.12           0.01   \n",
       "\n",
       "      kubernetes  deep_learning             topic  \n",
       "0           0.00           0.00      scikit_learn  \n",
       "1           0.00           0.00  jupyter_notebook  \n",
       "2           0.00           0.00      scikit_learn  \n",
       "3           0.00           0.00      scikit_learn  \n",
       "4           0.00           0.00      scikit_learn  \n",
       "5           0.00           0.00      scikit_learn  \n",
       "6           0.00           0.00      scikit_learn  \n",
       "7           0.00           0.00      scikit_learn  \n",
       "8           0.00           0.00  machine_learning  \n",
       "9           0.00           0.00      scikit_learn  \n",
       "10          0.00           0.02               nlp  \n",
       "11          0.00           0.00      scikit_learn  \n",
       "12          0.01           0.00      scikit_learn  \n",
       "13          0.00           0.00      scikit_learn  \n",
       "14          0.00           0.00    python_library  \n",
       "15          0.00           0.00      scikit_learn  \n",
       "16          0.00           0.00      scikit_learn  \n",
       "17          0.00           0.00  jupyter_notebook  \n",
       "18          0.00           0.00      scikit_learn  \n",
       "19          0.00           0.00      scikit_learn  \n",
       "20          0.00           0.02      scikit_learn  \n",
       "21          0.00           0.18      scikit_learn  \n",
       "22          0.00           0.00      scikit_learn  \n",
       "23          0.00           0.00      scikit_learn  \n",
       "24          0.00           0.00      scikit_learn  \n",
       "25          0.00           0.00      scikit_learn  \n",
       "26          0.01           0.00      scikit_learn  \n",
       "27          0.00           0.00      scikit_learn  \n",
       "28          0.00           0.00      scikit_learn  \n",
       "29          0.00           0.02      scikit_learn  \n",
       "...          ...            ...               ...  \n",
       "6984        0.00           0.00               nlp  \n",
       "6985        0.00           0.00  machine_learning  \n",
       "6986        0.00           0.01               nlp  \n",
       "6987        0.00           0.00  machine_learning  \n",
       "6988        0.00           0.00  jupyter_notebook  \n",
       "6989        0.00           0.00               nlp  \n",
       "6990        0.00           0.00  machine_learning  \n",
       "6991        0.00           0.00  machine_learning  \n",
       "6992        0.00           0.00    python_library  \n",
       "6993        0.00           0.00  machine_learning  \n",
       "6994        0.00           0.00               nlp  \n",
       "6995        0.00           0.00  machine_learning  \n",
       "6996        0.00           0.00  machine_learning  \n",
       "6997        0.00           0.00  machine_learning  \n",
       "6998        0.00           0.00    python_library  \n",
       "6999        0.00           0.00               nlp  \n",
       "7000        0.00           0.00  machine_learning  \n",
       "7001        0.00           0.00  machine_learning  \n",
       "7002        0.00           0.00     julia_package  \n",
       "7003        0.00           0.00    python_library  \n",
       "7004        0.00           0.01    python_library  \n",
       "7005        0.00           0.01    python_library  \n",
       "7006        0.00           0.03     deep_learning  \n",
       "7007        0.01           0.00    python_library  \n",
       "7008        0.00           0.00    python_library  \n",
       "7009        0.00           0.00  machine_learning  \n",
       "7010        0.01           0.00    python_library  \n",
       "7011        0.01           0.02     deep_learning  \n",
       "7012        0.00           0.00  machine_learning  \n",
       "7013        0.01           0.03               nlp  \n",
       "\n",
       "[7014 rows x 10 columns]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = H.rename(columns={'index': 'description'})\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:02:31.742672Z",
     "start_time": "2019-03-27T02:02:31.717413Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_scores_chollet_df = chollet_df.merge(H, on='description').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:02:32.964818Z",
     "start_time": "2019-03-27T02:02:32.960097Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_scores_chollet_df['topic'] = topic_scores_chollet_df['topic'].str.replace('_', \" \").str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:59:22.119866Z",
     "start_time": "2019-03-27T01:59:22.093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>machine_learning</th>\n",
       "      <th>scikit_learn</th>\n",
       "      <th>jupyter_notebook</th>\n",
       "      <th>python_library</th>\n",
       "      <th>nlp</th>\n",
       "      <th>julia_package</th>\n",
       "      <th>kubernetes</th>\n",
       "      <th>deep_learning</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>64878964</td>\n",
       "      <td>deep-learning-models</td>\n",
       "      <td>Keras code and weights files for popular deep ...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>102523304</td>\n",
       "      <td>deep-learning-with-python-notebooks</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jupyter notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>102523304</td>\n",
       "      <td>deep-learning-with-python-notebooks</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jupyter notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>102523304</td>\n",
       "      <td>deep-learning-with-python-notebooks</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jupyter notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>64428695</td>\n",
       "      <td>keras-resources</td>\n",
       "      <td>Directory of tutorials and open-source code re...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Python library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>169159059</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>An Open Source Machine Learning Framework for ...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Machine learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         id                                 name  \\\n",
       "0      0   64878964                 deep-learning-models   \n",
       "1      1  102523304  deep-learning-with-python-notebooks   \n",
       "2      2  102523304  deep-learning-with-python-notebooks   \n",
       "3      3  102523304  deep-learning-with-python-notebooks   \n",
       "4      4   64428695                      keras-resources   \n",
       "5      5  169159059                           tensorflow   \n",
       "\n",
       "                                         description  machine_learning  \\\n",
       "0  Keras code and weights files for popular deep ...              0.01   \n",
       "1  Jupyter notebooks for the code samples of the ...              0.01   \n",
       "2  Jupyter notebooks for the code samples of the ...              0.01   \n",
       "3  Jupyter notebooks for the code samples of the ...              0.01   \n",
       "4  Directory of tutorials and open-source code re...              0.01   \n",
       "5  An Open Source Machine Learning Framework for ...              0.17   \n",
       "\n",
       "   scikit_learn  jupyter_notebook  python_library   nlp  julia_package  \\\n",
       "0           0.0              0.01            0.01  0.20           0.01   \n",
       "1           0.0              0.25            0.20  0.19           0.00   \n",
       "2           0.0              0.25            0.20  0.19           0.00   \n",
       "3           0.0              0.25            0.20  0.19           0.00   \n",
       "4           0.0              0.01            0.22  0.20           0.02   \n",
       "5           0.0              0.00            0.00  0.00           0.00   \n",
       "\n",
       "   kubernetes  deep_learning             topic  \n",
       "0        0.01           0.01               Nlp  \n",
       "1        0.00           0.00  Jupyter notebook  \n",
       "2        0.00           0.00  Jupyter notebook  \n",
       "3        0.00           0.00  Jupyter notebook  \n",
       "4        0.01           0.00    Python library  \n",
       "5        0.01           0.00  Machine learning  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_scores_chollet_df\n",
    "# topic_scores_chollet_df.drop(['index', 'level_0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:02:36.587956Z",
     "start_time": "2019-03-27T02:02:36.564376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>machine_learning</th>\n",
       "      <th>scikit_learn</th>\n",
       "      <th>jupyter_notebook</th>\n",
       "      <th>python_library</th>\n",
       "      <th>nlp</th>\n",
       "      <th>julia_package</th>\n",
       "      <th>kubernetes</th>\n",
       "      <th>deep_learning</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scikit-learn: machine learning in Python</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Scikit learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jupyter notebooks from the scikit-learn video ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jupyter notebook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  machine_learning  \\\n",
       "0           scikit-learn: machine learning in Python              0.17   \n",
       "1  Jupyter notebooks from the scikit-learn video ...              0.00   \n",
       "\n",
       "   scikit_learn  jupyter_notebook  python_library  nlp  julia_package  \\\n",
       "0          0.18              0.00            0.18  0.0            0.0   \n",
       "1          0.18              0.24            0.00  0.0            0.0   \n",
       "\n",
       "   kubernetes  deep_learning             topic  \n",
       "0         0.0            0.0      Scikit learn  \n",
       "1         0.0            0.0  Jupyter notebook  "
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H['topic'] = H['topic'].str.replace('_', \" \").str.capitalize()\n",
    "H.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:02:37.527329Z",
     "start_time": "2019-03-27T02:02:37.401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>description</th>\n",
       "      <th>machine_learning</th>\n",
       "      <th>scikit_learn</th>\n",
       "      <th>jupyter_notebook</th>\n",
       "      <th>python_library</th>\n",
       "      <th>nlp</th>\n",
       "      <th>julia_package</th>\n",
       "      <th>kubernetes</th>\n",
       "      <th>deep_learning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stores documents used by the TensorFlow develo...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Keras code and weights files for popular deep ...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Keras Total Visualization project</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Blog with Keras news, tutorials, and demos.</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Directory of tutorials and open-source code re...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Pure Python/Numpy implementation of the Nelder...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>An Open Source Machine Learning Framework for ...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0                                        description  \\\n",
       "0        0  Stores documents used by the TensorFlow develo...   \n",
       "1        1  Keras code and weights files for popular deep ...   \n",
       "2        2  Jupyter notebooks for the code samples of the ...   \n",
       "3        3                  Keras Total Visualization project   \n",
       "4        4        Blog with Keras news, tutorials, and demos.   \n",
       "5        5  Directory of tutorials and open-source code re...   \n",
       "6        6  Pure Python/Numpy implementation of the Nelder...   \n",
       "7        7  An Open Source Machine Learning Framework for ...   \n",
       "\n",
       "   machine_learning  scikit_learn  jupyter_notebook  python_library   nlp  \\\n",
       "0              0.00          0.01              0.00            0.00  0.01   \n",
       "1              0.01          0.00              0.01            0.01  0.20   \n",
       "2              0.01          0.00              0.25            0.20  0.19   \n",
       "3              0.00          0.00              0.00            0.00  0.00   \n",
       "4              0.00          0.00              0.00            0.00  0.01   \n",
       "5              0.01          0.00              0.01            0.22  0.20   \n",
       "6              0.00          0.01              0.00            0.19  0.00   \n",
       "7              0.17          0.00              0.00            0.00  0.00   \n",
       "\n",
       "   julia_package  kubernetes  deep_learning  \n",
       "0           0.00        0.00           0.02  \n",
       "1           0.01        0.01           0.01  \n",
       "2           0.00        0.00           0.00  \n",
       "3           0.00        0.00           0.02  \n",
       "4           0.00        0.00           0.01  \n",
       "5           0.02        0.01           0.00  \n",
       "6           0.00        0.00           0.00  \n",
       "7           0.00        0.01           0.00  "
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chollet_topic_df['topic'] = chollet_topic_df['topic'].str.replace('_', \" \").str.capitalize()\n",
    "chollet_topic_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:02:38.355607Z",
     "start_time": "2019-03-27T02:02:37.795739Z"
    }
   },
   "outputs": [],
   "source": [
    "repos = pd.read_pickle('all_repos_concat_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:03:44.045490Z",
     "start_time": "2019-03-27T02:03:44.037966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 843222,\n",
       " 'node_id': 'MDEwOlJlcG9zaXRvcnk4NDMyMjI=',\n",
       " 'name': 'scikit-learn',\n",
       " 'full_name': 'scikit-learn/scikit-learn',\n",
       " 'private': False,\n",
       " 'owner': {'login': 'scikit-learn',\n",
       "  'id': 365630,\n",
       "  'node_id': 'MDEyOk9yZ2FuaXphdGlvbjM2NTYzMA==',\n",
       "  'avatar_url': 'https://avatars2.githubusercontent.com/u/365630?v=4',\n",
       "  'gravatar_id': '',\n",
       "  'url': 'https://api.github.com/users/scikit-learn',\n",
       "  'html_url': 'https://github.com/scikit-learn',\n",
       "  'followers_url': 'https://api.github.com/users/scikit-learn/followers',\n",
       "  'following_url': 'https://api.github.com/users/scikit-learn/following{/other_user}',\n",
       "  'gists_url': 'https://api.github.com/users/scikit-learn/gists{/gist_id}',\n",
       "  'starred_url': 'https://api.github.com/users/scikit-learn/starred{/owner}{/repo}',\n",
       "  'subscriptions_url': 'https://api.github.com/users/scikit-learn/subscriptions',\n",
       "  'organizations_url': 'https://api.github.com/users/scikit-learn/orgs',\n",
       "  'repos_url': 'https://api.github.com/users/scikit-learn/repos',\n",
       "  'events_url': 'https://api.github.com/users/scikit-learn/events{/privacy}',\n",
       "  'received_events_url': 'https://api.github.com/users/scikit-learn/received_events',\n",
       "  'type': 'Organization',\n",
       "  'site_admin': False},\n",
       " 'html_url': 'https://github.com/scikit-learn/scikit-learn',\n",
       " 'description': 'scikit-learn: machine learning in Python',\n",
       " 'fork': False,\n",
       " 'url': 'https://api.github.com/repos/scikit-learn/scikit-learn',\n",
       " 'forks_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/forks',\n",
       " 'keys_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/keys{/key_id}',\n",
       " 'collaborators_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/collaborators{/collaborator}',\n",
       " 'teams_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/teams',\n",
       " 'hooks_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/hooks',\n",
       " 'issue_events_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/issues/events{/number}',\n",
       " 'events_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/events',\n",
       " 'assignees_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/assignees{/user}',\n",
       " 'branches_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/branches{/branch}',\n",
       " 'tags_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/tags',\n",
       " 'blobs_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/git/blobs{/sha}',\n",
       " 'git_tags_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/git/tags{/sha}',\n",
       " 'git_refs_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/git/refs{/sha}',\n",
       " 'trees_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/git/trees{/sha}',\n",
       " 'statuses_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/statuses/{sha}',\n",
       " 'languages_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/languages',\n",
       " 'stargazers_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/stargazers',\n",
       " 'contributors_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/contributors',\n",
       " 'subscribers_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/subscribers',\n",
       " 'subscription_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/subscription',\n",
       " 'commits_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/commits{/sha}',\n",
       " 'git_commits_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/git/commits{/sha}',\n",
       " 'comments_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/comments{/number}',\n",
       " 'issue_comment_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments{/number}',\n",
       " 'contents_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/contents/{+path}',\n",
       " 'compare_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/compare/{base}...{head}',\n",
       " 'merges_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/merges',\n",
       " 'archive_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/{archive_format}{/ref}',\n",
       " 'downloads_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/downloads',\n",
       " 'issues_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/issues{/number}',\n",
       " 'pulls_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/pulls{/number}',\n",
       " 'milestones_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/milestones{/number}',\n",
       " 'notifications_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/notifications{?since,all,participating}',\n",
       " 'labels_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/labels{/name}',\n",
       " 'releases_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/releases{/id}',\n",
       " 'deployments_url': 'https://api.github.com/repos/scikit-learn/scikit-learn/deployments',\n",
       " 'created_at': '2010-08-17T09:43:38Z',\n",
       " 'updated_at': '2019-03-17T17:07:47Z',\n",
       " 'pushed_at': '2019-03-17T18:21:20Z',\n",
       " 'git_url': 'git://github.com/scikit-learn/scikit-learn.git',\n",
       " 'ssh_url': 'git@github.com:scikit-learn/scikit-learn.git',\n",
       " 'clone_url': 'https://github.com/scikit-learn/scikit-learn.git',\n",
       " 'svn_url': 'https://github.com/scikit-learn/scikit-learn',\n",
       " 'homepage': 'http://scikit-learn.org',\n",
       " 'size': 101480,\n",
       " 'stargazers_count': 33879,\n",
       " 'watchers_count': 33879,\n",
       " 'language': 'Python',\n",
       " 'has_issues': True,\n",
       " 'has_projects': True,\n",
       " 'has_downloads': True,\n",
       " 'has_wiki': True,\n",
       " 'has_pages': False,\n",
       " 'forks_count': 16621,\n",
       " 'mirror_url': None,\n",
       " 'archived': False,\n",
       " 'open_issues_count': 1905,\n",
       " 'license': {'key': 'other',\n",
       "  'name': 'Other',\n",
       "  'spdx_id': 'NOASSERTION',\n",
       "  'url': None,\n",
       "  'node_id': 'MDc6TGljZW5zZTA='},\n",
       " 'forks': 16621,\n",
       " 'open_issues': 1905,\n",
       " 'watchers': 33879,\n",
       " 'default_branch': 'master',\n",
       " 'permissions': {'admin': False, 'push': False, 'pull': True},\n",
       " 'organization': {'login': 'scikit-learn',\n",
       "  'id': 365630,\n",
       "  'node_id': 'MDEyOk9yZ2FuaXphdGlvbjM2NTYzMA==',\n",
       "  'avatar_url': 'https://avatars2.githubusercontent.com/u/365630?v=4',\n",
       "  'gravatar_id': '',\n",
       "  'url': 'https://api.github.com/users/scikit-learn',\n",
       "  'html_url': 'https://github.com/scikit-learn',\n",
       "  'followers_url': 'https://api.github.com/users/scikit-learn/followers',\n",
       "  'following_url': 'https://api.github.com/users/scikit-learn/following{/other_user}',\n",
       "  'gists_url': 'https://api.github.com/users/scikit-learn/gists{/gist_id}',\n",
       "  'starred_url': 'https://api.github.com/users/scikit-learn/starred{/owner}{/repo}',\n",
       "  'subscriptions_url': 'https://api.github.com/users/scikit-learn/subscriptions',\n",
       "  'organizations_url': 'https://api.github.com/users/scikit-learn/orgs',\n",
       "  'repos_url': 'https://api.github.com/users/scikit-learn/repos',\n",
       "  'events_url': 'https://api.github.com/users/scikit-learn/events{/privacy}',\n",
       "  'received_events_url': 'https://api.github.com/users/scikit-learn/received_events',\n",
       "  'type': 'Organization',\n",
       "  'site_admin': False},\n",
       " 'network_count': 16621,\n",
       " 'subscribers_count': 2215}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict = {}\n",
    "repos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:02:43.477599Z",
     "start_time": "2019-03-27T02:02:43.300879Z"
    }
   },
   "outputs": [],
   "source": [
    "repos_df = pd.DataFrame(repos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:02:44.263747Z",
     "start_time": "2019-03-27T02:02:43.942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['archive_url', 'archived', 'assignees_url', 'blobs_url', 'branches_url',\n",
       "       'clone_url', 'collaborators_url', 'comments_url', 'commits_url',\n",
       "       'compare_url', 'contents_url', 'contributors_url', 'created_at',\n",
       "       'default_branch', 'deployments_url', 'description', 'downloads_url',\n",
       "       'events_url', 'fork', 'forks', 'forks_count', 'forks_url', 'full_name',\n",
       "       'git_commits_url', 'git_refs_url', 'git_tags_url', 'git_url',\n",
       "       'has_downloads', 'has_issues', 'has_pages', 'has_projects', 'has_wiki',\n",
       "       'homepage', 'hooks_url', 'html_url', 'id', 'issue_comment_url',\n",
       "       'issue_events_url', 'issues_url', 'keys_url', 'labels_url', 'language',\n",
       "       'languages_url', 'license', 'merges_url', 'milestones_url',\n",
       "       'mirror_url', 'name', 'network_count', 'node_id', 'notifications_url',\n",
       "       'open_issues', 'open_issues_count', 'organization', 'owner',\n",
       "       'permissions', 'private', 'pulls_url', 'pushed_at', 'releases_url',\n",
       "       'size', 'ssh_url', 'stargazers_count', 'stargazers_url', 'statuses_url',\n",
       "       'subscribers_count', 'subscribers_url', 'subscription_url', 'svn_url',\n",
       "       'tags_url', 'teams_url', 'trees_url', 'updated_at', 'url', 'watchers',\n",
       "       'watchers_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:02:44.866568Z",
     "start_time": "2019-03-27T02:02:44.847770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>machine_learning</th>\n",
       "      <th>scikit_learn</th>\n",
       "      <th>jupyter_notebook</th>\n",
       "      <th>python_library</th>\n",
       "      <th>nlp</th>\n",
       "      <th>julia_package</th>\n",
       "      <th>kubernetes</th>\n",
       "      <th>deep_learning</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>153352191</td>\n",
       "      <td>community</td>\n",
       "      <td>Stores documents used by the TensorFlow develo...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Python library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>64878964</td>\n",
       "      <td>deep-learning-models</td>\n",
       "      <td>Keras code and weights files for popular deep ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>102523304</td>\n",
       "      <td>deep-learning-with-python-notebooks</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>37793722</td>\n",
       "      <td>hualos</td>\n",
       "      <td>Keras Total Visualization project</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Kubernetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>50265227</td>\n",
       "      <td>keras-blog</td>\n",
       "      <td>Blog with Keras news, tutorials, and demos.</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.43</td>\n",
       "      <td>Deep learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>64428695</td>\n",
       "      <td>keras-resources</td>\n",
       "      <td>Directory of tutorials and open-source code re...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jupyter notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>31916946</td>\n",
       "      <td>nelder-mead</td>\n",
       "      <td>Pure Python/Numpy implementation of the Nelder...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Scikit learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>169159059</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>An Open Source Machine Learning Framework for ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Julia package</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         id                                 name  \\\n",
       "0      0  153352191                            community   \n",
       "1      1   64878964                 deep-learning-models   \n",
       "2      2  102523304  deep-learning-with-python-notebooks   \n",
       "3      3   37793722                               hualos   \n",
       "4      4   50265227                           keras-blog   \n",
       "5      5   64428695                      keras-resources   \n",
       "6      6   31916946                          nelder-mead   \n",
       "7      7  169159059                           tensorflow   \n",
       "\n",
       "                                         description  machine_learning  \\\n",
       "0  Stores documents used by the TensorFlow develo...              0.00   \n",
       "1  Keras code and weights files for popular deep ...              0.00   \n",
       "2  Jupyter notebooks for the code samples of the ...              1.18   \n",
       "3                  Keras Total Visualization project              0.00   \n",
       "4        Blog with Keras news, tutorials, and demos.              0.00   \n",
       "5  Directory of tutorials and open-source code re...              0.00   \n",
       "6  Pure Python/Numpy implementation of the Nelder...              0.00   \n",
       "7  An Open Source Machine Learning Framework for ...              0.00   \n",
       "\n",
       "   scikit_learn  jupyter_notebook  python_library   nlp  julia_package  \\\n",
       "0          0.00              0.00            1.57  0.00           0.00   \n",
       "1          0.00              0.00            0.00  1.36           0.00   \n",
       "2          0.00              0.00            0.00  0.00           0.00   \n",
       "3          0.00              0.00            0.00  0.00           0.00   \n",
       "4          0.00              0.00            0.00  0.00           0.00   \n",
       "5          0.00              1.14            0.00  0.00           0.00   \n",
       "6          1.42              0.00            0.00  0.00           0.00   \n",
       "7          0.00              0.00            0.00  0.00           1.41   \n",
       "\n",
       "   kubernetes  deep_learning             topic  \n",
       "0        0.00           0.00    Python library  \n",
       "1        0.00           0.00               Nlp  \n",
       "2        0.00           0.00  Machine learning  \n",
       "3        1.36           0.00        Kubernetes  \n",
       "4        0.00           1.43     Deep learning  \n",
       "5        0.00           0.00  Jupyter notebook  \n",
       "6        0.00           0.00      Scikit learn  \n",
       "7        0.00           0.00     Julia package  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_scores_chollet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:02:45.928723Z",
     "start_time": "2019-03-27T02:02:45.835859Z"
    }
   },
   "outputs": [],
   "source": [
    "repos_merged_df = topic_scores_chollet_df.merge(repos_df, on='description').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:02:46.744229Z",
     "start_time": "2019-03-27T02:02:46.492Z"
    }
   },
   "outputs": [],
   "source": [
    "repos_merged_df['id_x'].drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:02:47.195070Z",
     "start_time": "2019-03-27T02:02:47.175778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>description</th>\n",
       "      <th>html_url</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64878964</td>\n",
       "      <td>deep-learning-models</td>\n",
       "      <td>Keras code and weights files for popular deep ...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-models</td>\n",
       "      <td>Nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102523304</td>\n",
       "      <td>deep-learning-with-python-notebooks</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-with...</td>\n",
       "      <td>Machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64428695</td>\n",
       "      <td>keras-resources</td>\n",
       "      <td>Directory of tutorials and open-source code re...</td>\n",
       "      <td>https://github.com/fchollet/keras-resources</td>\n",
       "      <td>Jupyter notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>169159059</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>An Open Source Machine Learning Framework for ...</td>\n",
       "      <td>https://github.com/tensorflow/tensorflow</td>\n",
       "      <td>Julia package</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_x                               name_x  \\\n",
       "0   64878964                 deep-learning-models   \n",
       "1  102523304  deep-learning-with-python-notebooks   \n",
       "4   64428695                      keras-resources   \n",
       "5  169159059                           tensorflow   \n",
       "\n",
       "                                         description  \\\n",
       "0  Keras code and weights files for popular deep ...   \n",
       "1  Jupyter notebooks for the code samples of the ...   \n",
       "4  Directory of tutorials and open-source code re...   \n",
       "5  An Open Source Machine Learning Framework for ...   \n",
       "\n",
       "                                            html_url             topic  \n",
       "0   https://github.com/fchollet/deep-learning-models               Nlp  \n",
       "1  https://github.com/fchollet/deep-learning-with...  Machine learning  \n",
       "4        https://github.com/fchollet/keras-resources  Jupyter notebook  \n",
       "5           https://github.com/tensorflow/tensorflow     Julia package  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_merged_df_1 = repos_merged_df[['id_x','name_x', 'description', 'html_url', 'topic']].drop_duplicates()\n",
    "repos_merged_df_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:02:50.600046Z",
     "start_time": "2019-03-27T02:02:50.581293Z"
    }
   },
   "outputs": [],
   "source": [
    "# ['archive_url', 'archived', 'assignees_url', 'blobs_url', 'branches_url',\n",
    "#        'clone_url', 'collaborators_url', 'comments_url', 'commits_url',\n",
    "#        'compare_url', 'contents_url', 'contributors_url', 'created_at',\n",
    "#        'default_branch', 'deployments_url', 'description', 'downloads_url',\n",
    "#        'events_url', 'fork', 'forks', 'forks_count', 'forks_url', 'full_name',\n",
    "#        'git_commits_url', 'git_refs_url', 'git_tags_url', 'git_url',\n",
    "#        'has_downloads', 'has_issues', 'has_pages', 'has_projects', 'has_wiki',\n",
    "#        'homepage', 'hooks_url', 'html_url', 'id', 'issue_comment_url',\n",
    "#        'issue_events_url', 'issues_url', 'keys_url', 'labels_url', 'language',\n",
    "#        'languages_url', 'license', 'merges_url', 'milestones_url',\n",
    "#        'mirror_url', 'name', 'network_count', 'node_id', 'notifications_url',\n",
    "#        'open_issues', 'open_issues_count', 'organization', 'owner',\n",
    "#        'permissions', 'private', 'pulls_url', 'pushed_at', 'releases_url',\n",
    "#        'size', 'ssh_url', 'stargazers_count', 'stargazers_url', 'statuses_url',\n",
    "#        'subscribers_count', 'subscribers_url', 'subscription_url', 'svn_url',\n",
    "#        'tags_url', 'teams_url', 'trees_url', 'updated_at', 'url', 'watchers',\n",
    "#        'watchers_count'],\n",
    "\n",
    "#langauge\n",
    "#updates_at, pushed_at, created_at\n",
    "# sum waters_count, watchers, subscribers_count, stargazers_count, , size, network_count, forks_count, \n",
    "repos_merged_grouped_sum_df = repos_merged_df.groupby(['id_x', 'name_x', 'topic', 'description', 'html_url'])['watchers_count', 'watchers', 'subscribers_count', 'stargazers_count', 'size', 'network_count', 'forks_count'].sum().reset_index()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:02:54.144583Z",
     "start_time": "2019-03-27T02:02:54.128516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>topic</th>\n",
       "      <th>description</th>\n",
       "      <th>html_url</th>\n",
       "      <th>watchers_count</th>\n",
       "      <th>watchers</th>\n",
       "      <th>subscribers_count</th>\n",
       "      <th>stargazers_count</th>\n",
       "      <th>size</th>\n",
       "      <th>network_count</th>\n",
       "      <th>forks_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64428695</td>\n",
       "      <td>keras-resources</td>\n",
       "      <td>Python library</td>\n",
       "      <td>Directory of tutorials and open-source code re...</td>\n",
       "      <td>https://github.com/fchollet/keras-resources</td>\n",
       "      <td>2707</td>\n",
       "      <td>2707</td>\n",
       "      <td>217</td>\n",
       "      <td>2707</td>\n",
       "      <td>37</td>\n",
       "      <td>770</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64878964</td>\n",
       "      <td>deep-learning-models</td>\n",
       "      <td>Nlp</td>\n",
       "      <td>Keras code and weights files for popular deep ...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-models</td>\n",
       "      <td>4763</td>\n",
       "      <td>4763</td>\n",
       "      <td>271</td>\n",
       "      <td>4763</td>\n",
       "      <td>45</td>\n",
       "      <td>1499</td>\n",
       "      <td>1499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102523304</td>\n",
       "      <td>deep-learning-with-python-notebooks</td>\n",
       "      <td>Jupyter notebook</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-with...</td>\n",
       "      <td>55413</td>\n",
       "      <td>55413</td>\n",
       "      <td>3537</td>\n",
       "      <td>55413</td>\n",
       "      <td>61992</td>\n",
       "      <td>25488</td>\n",
       "      <td>25488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>169159059</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>Machine learning</td>\n",
       "      <td>An Open Source Machine Learning Framework for ...</td>\n",
       "      <td>https://github.com/tensorflow/tensorflow</td>\n",
       "      <td>122588</td>\n",
       "      <td>122588</td>\n",
       "      <td>8616</td>\n",
       "      <td>122588</td>\n",
       "      <td>326116</td>\n",
       "      <td>72737</td>\n",
       "      <td>72737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_x                               name_x             topic  \\\n",
       "0   64428695                      keras-resources    Python library   \n",
       "1   64878964                 deep-learning-models               Nlp   \n",
       "2  102523304  deep-learning-with-python-notebooks  Jupyter notebook   \n",
       "3  169159059                           tensorflow  Machine learning   \n",
       "\n",
       "                                         description  \\\n",
       "0  Directory of tutorials and open-source code re...   \n",
       "1  Keras code and weights files for popular deep ...   \n",
       "2  Jupyter notebooks for the code samples of the ...   \n",
       "3  An Open Source Machine Learning Framework for ...   \n",
       "\n",
       "                                            html_url  watchers_count  \\\n",
       "0        https://github.com/fchollet/keras-resources            2707   \n",
       "1   https://github.com/fchollet/deep-learning-models            4763   \n",
       "2  https://github.com/fchollet/deep-learning-with...           55413   \n",
       "3           https://github.com/tensorflow/tensorflow          122588   \n",
       "\n",
       "   watchers  subscribers_count  stargazers_count    size  network_count  \\\n",
       "0      2707                217              2707      37            770   \n",
       "1      4763                271              4763      45           1499   \n",
       "2     55413               3537             55413   61992          25488   \n",
       "3    122588               8616            122588  326116          72737   \n",
       "\n",
       "   forks_count  \n",
       "0          770  \n",
       "1         1499  \n",
       "2        25488  \n",
       "3        72737  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_merged_grouped_sum_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:02:57.174360Z",
     "start_time": "2019-03-27T02:02:57.170712Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'id', 'description', 'name']\n",
    "import json as json\n",
    "\n",
    "a= repos_merged_grouped_sum_df.to_json()\n",
    "b= repos_merged_df_1.to_json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:02:58.112126Z",
     "start_time": "2019-03-27T02:02:57.439Z"
    }
   },
   "outputs": [],
   "source": [
    "# json.dumps(a,'repos_merged_grouped_sum_df')\n",
    "json.dumps(b,'repos_merged_df_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:02:58.266264Z",
     "start_time": "2019-03-27T02:02:58.260215Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('repos_merged_grouped_sum_df.json', 'w') as outfile:\n",
    "    json.dump(a, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:02:59.125810Z",
     "start_time": "2019-03-27T02:02:58.697Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('repos_merged_df_1.json', 'w') as outfile:\n",
    "    json.dump(b, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:02:59.129850Z",
     "start_time": "2019-03-27T02:02:59.115Z"
    }
   },
   "outputs": [],
   "source": [
    "repos_merged_df[['name_x','description', 'topic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:03:26.213829Z",
     "start_time": "2019-03-27T02:03:26.199092Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first_repo_similarities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-bdbdc28e97d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrepo_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_desc_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfirst_repo_similarities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrepo_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_desc_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msecond_repo_similarities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrepo_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_desc_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthird_repo_similarities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrepo_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_desc_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfourth_repo_similarities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrepo_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_desc_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfifth_repo_similarities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'first_repo_similarities' is not defined"
     ]
    }
   ],
   "source": [
    "repo_1 = pd.DataFrame(repo_desc_df.iloc[first_repo_similarities])\n",
    "repo_2 = pd.DataFrame(repo_desc_df.iloc[second_repo_similarities])\n",
    "repo_3 = pd.DataFrame(repo_desc_df.iloc[third_repo_similarities])\n",
    "repo_4 = pd.DataFrame(repo_desc_df.iloc[fourth_repo_similarities])\n",
    "repo_5 = pd.DataFrame(repo_desc_df.iloc[fifth_repo_similarities])\n",
    "repo_6 = pd.DataFrame(repo_desc_df.iloc[sixth_repo_similarities])\n",
    "repo_7 = pd.DataFrame(repo_desc_df.iloc[seventh_repo_similarities])\n",
    "repo_8 = pd.DataFrame(repo_desc_df.iloc[eighth_repo_similarities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:03:08.377401Z",
     "start_time": "2019-03-27T02:03:08.352277Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'repo_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-1ad06223e483>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrepo_1_merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepo_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepos_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrepo_2_merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepo_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepos_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrepo_3_merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepo_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepos_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrepo_4_merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepo_4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepos_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrepo_5_merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepo_5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepos_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'repo_1' is not defined"
     ]
    }
   ],
   "source": [
    "repo_1_merged = repo_1.merge(repos_df, on='id').reset_index()\n",
    "repo_2_merged = repo_2.merge(repos_df, on='id').reset_index()\n",
    "repo_3_merged = repo_3.merge(repos_df, on='id').reset_index()\n",
    "repo_4_merged = repo_4.merge(repos_df, on='id').reset_index()\n",
    "repo_5_merged = repo_5.merge(repos_df, on='id').reset_index()\n",
    "repo_6_merged = repo_6.merge(repos_df, on='id').reset_index()\n",
    "repo_7_merged = repo_7.merge(repos_df, on='id').reset_index()\n",
    "repo_8_merged = repo_8.merge(repos_df, on='id').reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T00:58:29.810850Z",
     "start_time": "2019-03-27T00:58:29.773669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>description_x</th>\n",
       "      <th>archive_url</th>\n",
       "      <th>archived</th>\n",
       "      <th>assignees_url</th>\n",
       "      <th>blobs_url</th>\n",
       "      <th>branches_url</th>\n",
       "      <th>clone_url</th>\n",
       "      <th>...</th>\n",
       "      <th>subscribers_url</th>\n",
       "      <th>subscription_url</th>\n",
       "      <th>svn_url</th>\n",
       "      <th>tags_url</th>\n",
       "      <th>teams_url</th>\n",
       "      <th>trees_url</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>url</th>\n",
       "      <th>watchers</th>\n",
       "      <th>watchers_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3893</td>\n",
       "      <td>50589459</td>\n",
       "      <td>CS231n: Convolutional Neural Networks for Vis...</td>\n",
       "      <td>https://api.github.com/repos/NLeSC/deep-learni...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://api.github.com/repos/NLeSC/deep-learni...</td>\n",
       "      <td>https://api.github.com/repos/NLeSC/deep-learni...</td>\n",
       "      <td>https://api.github.com/repos/NLeSC/deep-learni...</td>\n",
       "      <td>https://github.com/NLeSC/deep-learning-assignm...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/NLeSC/deep-learni...</td>\n",
       "      <td>https://api.github.com/repos/NLeSC/deep-learni...</td>\n",
       "      <td>https://github.com/NLeSC/deep-learning-assignm...</td>\n",
       "      <td>https://api.github.com/repos/NLeSC/deep-learni...</td>\n",
       "      <td>https://api.github.com/repos/NLeSC/deep-learni...</td>\n",
       "      <td>https://api.github.com/repos/NLeSC/deep-learni...</td>\n",
       "      <td>2019-02-01T12:02:11Z</td>\n",
       "      <td>https://api.github.com/repos/NLeSC/deep-learni...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3210</td>\n",
       "      <td>144329231</td>\n",
       "      <td>This repository contains small projects relate...</td>\n",
       "      <td>https://api.github.com/repos/SkalskiP/ILearnDe...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/SkalskiP/ILearnDe...</td>\n",
       "      <td>https://api.github.com/repos/SkalskiP/ILearnDe...</td>\n",
       "      <td>https://api.github.com/repos/SkalskiP/ILearnDe...</td>\n",
       "      <td>https://github.com/SkalskiP/ILearnDeepLearning...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/SkalskiP/ILearnDe...</td>\n",
       "      <td>https://api.github.com/repos/SkalskiP/ILearnDe...</td>\n",
       "      <td>https://github.com/SkalskiP/ILearnDeepLearning.py</td>\n",
       "      <td>https://api.github.com/repos/SkalskiP/ILearnDe...</td>\n",
       "      <td>https://api.github.com/repos/SkalskiP/ILearnDe...</td>\n",
       "      <td>https://api.github.com/repos/SkalskiP/ILearnDe...</td>\n",
       "      <td>2019-03-12T03:56:01Z</td>\n",
       "      <td>https://api.github.com/repos/SkalskiP/ILearnDe...</td>\n",
       "      <td>395</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4095</td>\n",
       "      <td>102523304</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-with...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-with...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>2019-03-11T17:20:36Z</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>6152</td>\n",
       "      <td>6152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4095</td>\n",
       "      <td>102523304</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-with...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-with...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>2019-03-13T01:05:58Z</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>6157</td>\n",
       "      <td>6157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4095</td>\n",
       "      <td>102523304</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-with...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-with...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>2019-03-13T15:29:41Z</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>6162</td>\n",
       "      <td>6162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2926</td>\n",
       "      <td>118356657</td>\n",
       "      <td>This project explores the use of ML in the leg...</td>\n",
       "      <td>https://api.github.com/repos/chibueze07/Machin...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/chibueze07/Machin...</td>\n",
       "      <td>https://api.github.com/repos/chibueze07/Machin...</td>\n",
       "      <td>https://api.github.com/repos/chibueze07/Machin...</td>\n",
       "      <td>https://github.com/chibueze07/Machine-Learning...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/chibueze07/Machin...</td>\n",
       "      <td>https://api.github.com/repos/chibueze07/Machin...</td>\n",
       "      <td>https://github.com/chibueze07/Machine-Learning...</td>\n",
       "      <td>https://api.github.com/repos/chibueze07/Machin...</td>\n",
       "      <td>https://api.github.com/repos/chibueze07/Machin...</td>\n",
       "      <td>https://api.github.com/repos/chibueze07/Machin...</td>\n",
       "      <td>2019-02-08T13:08:21Z</td>\n",
       "      <td>https://api.github.com/repos/chibueze07/Machin...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6861</td>\n",
       "      <td>124240220</td>\n",
       "      <td>fastNLP: A Modularized and Extensible NLP Fram...</td>\n",
       "      <td>https://api.github.com/repos/fastnlp/fastNLP/{...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/fastnlp/fastNLP/a...</td>\n",
       "      <td>https://api.github.com/repos/fastnlp/fastNLP/g...</td>\n",
       "      <td>https://api.github.com/repos/fastnlp/fastNLP/b...</td>\n",
       "      <td>https://github.com/fastnlp/fastNLP.git</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/fastnlp/fastNLP/s...</td>\n",
       "      <td>https://api.github.com/repos/fastnlp/fastNLP/s...</td>\n",
       "      <td>https://github.com/fastnlp/fastNLP</td>\n",
       "      <td>https://api.github.com/repos/fastnlp/fastNLP/tags</td>\n",
       "      <td>https://api.github.com/repos/fastnlp/fastNLP/t...</td>\n",
       "      <td>https://api.github.com/repos/fastnlp/fastNLP/g...</td>\n",
       "      <td>2019-03-13T11:16:08Z</td>\n",
       "      <td>https://api.github.com/repos/fastnlp/fastNLP</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3399</td>\n",
       "      <td>89452848</td>\n",
       "      <td>Code repository for Python Deep Learning, publ...</td>\n",
       "      <td>https://api.github.com/repos/PacktPublishing/P...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/PacktPublishing/P...</td>\n",
       "      <td>https://api.github.com/repos/PacktPublishing/P...</td>\n",
       "      <td>https://api.github.com/repos/PacktPublishing/P...</td>\n",
       "      <td>https://github.com/PacktPublishing/Python-Deep...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/PacktPublishing/P...</td>\n",
       "      <td>https://api.github.com/repos/PacktPublishing/P...</td>\n",
       "      <td>https://github.com/PacktPublishing/Python-Deep...</td>\n",
       "      <td>https://api.github.com/repos/PacktPublishing/P...</td>\n",
       "      <td>https://api.github.com/repos/PacktPublishing/P...</td>\n",
       "      <td>https://api.github.com/repos/PacktPublishing/P...</td>\n",
       "      <td>2019-03-04T17:21:52Z</td>\n",
       "      <td>https://api.github.com/repos/PacktPublishing/P...</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1524</td>\n",
       "      <td>675835</td>\n",
       "      <td>Tutorial material on the scientific Python eco...</td>\n",
       "      <td>https://api.github.com/repos/scipy-lectures/sc...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/scipy-lectures/sc...</td>\n",
       "      <td>https://api.github.com/repos/scipy-lectures/sc...</td>\n",
       "      <td>https://api.github.com/repos/scipy-lectures/sc...</td>\n",
       "      <td>https://github.com/scipy-lectures/scipy-lectur...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/scipy-lectures/sc...</td>\n",
       "      <td>https://api.github.com/repos/scipy-lectures/sc...</td>\n",
       "      <td>https://github.com/scipy-lectures/scipy-lectur...</td>\n",
       "      <td>https://api.github.com/repos/scipy-lectures/sc...</td>\n",
       "      <td>https://api.github.com/repos/scipy-lectures/sc...</td>\n",
       "      <td>https://api.github.com/repos/scipy-lectures/sc...</td>\n",
       "      <td>2019-03-11T20:57:25Z</td>\n",
       "      <td>https://api.github.com/repos/scipy-lectures/sc...</td>\n",
       "      <td>2074</td>\n",
       "      <td>2074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1524</td>\n",
       "      <td>675835</td>\n",
       "      <td>Tutorial material on the scientific Python eco...</td>\n",
       "      <td>https://api.github.com/repos/scipy-lectures/sc...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/scipy-lectures/sc...</td>\n",
       "      <td>https://api.github.com/repos/scipy-lectures/sc...</td>\n",
       "      <td>https://api.github.com/repos/scipy-lectures/sc...</td>\n",
       "      <td>https://github.com/scipy-lectures/scipy-lectur...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/scipy-lectures/sc...</td>\n",
       "      <td>https://api.github.com/repos/scipy-lectures/sc...</td>\n",
       "      <td>https://github.com/scipy-lectures/scipy-lectur...</td>\n",
       "      <td>https://api.github.com/repos/scipy-lectures/sc...</td>\n",
       "      <td>https://api.github.com/repos/scipy-lectures/sc...</td>\n",
       "      <td>https://api.github.com/repos/scipy-lectures/sc...</td>\n",
       "      <td>2019-03-11T20:57:25Z</td>\n",
       "      <td>https://api.github.com/repos/scipy-lectures/sc...</td>\n",
       "      <td>2074</td>\n",
       "      <td>2074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2198</td>\n",
       "      <td>69576253</td>\n",
       "      <td>Samples for Google Cloud Machine Learning Engine</td>\n",
       "      <td>https://api.github.com/repos/GoogleCloudPlatfo...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/GoogleCloudPlatfo...</td>\n",
       "      <td>https://api.github.com/repos/GoogleCloudPlatfo...</td>\n",
       "      <td>https://api.github.com/repos/GoogleCloudPlatfo...</td>\n",
       "      <td>https://github.com/GoogleCloudPlatform/cloudml...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/GoogleCloudPlatfo...</td>\n",
       "      <td>https://api.github.com/repos/GoogleCloudPlatfo...</td>\n",
       "      <td>https://github.com/GoogleCloudPlatform/cloudml...</td>\n",
       "      <td>https://api.github.com/repos/GoogleCloudPlatfo...</td>\n",
       "      <td>https://api.github.com/repos/GoogleCloudPlatfo...</td>\n",
       "      <td>https://api.github.com/repos/GoogleCloudPlatfo...</td>\n",
       "      <td>2019-03-12T15:08:47Z</td>\n",
       "      <td>https://api.github.com/repos/GoogleCloudPlatfo...</td>\n",
       "      <td>917</td>\n",
       "      <td>917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows √ó 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    level_0  index         id  \\\n",
       "0         0   3893   50589459   \n",
       "1         1   3210  144329231   \n",
       "2         2   4095  102523304   \n",
       "3         3   4095  102523304   \n",
       "4         4   4095  102523304   \n",
       "5         5   2926  118356657   \n",
       "6         6   6861  124240220   \n",
       "7         7   3399   89452848   \n",
       "8         8   1524     675835   \n",
       "9         9   1524     675835   \n",
       "10       10   2198   69576253   \n",
       "\n",
       "                                        description_x  \\\n",
       "0    CS231n: Convolutional Neural Networks for Vis...   \n",
       "1   This repository contains small projects relate...   \n",
       "2   Jupyter notebooks for the code samples of the ...   \n",
       "3   Jupyter notebooks for the code samples of the ...   \n",
       "4   Jupyter notebooks for the code samples of the ...   \n",
       "5   This project explores the use of ML in the leg...   \n",
       "6   fastNLP: A Modularized and Extensible NLP Fram...   \n",
       "7   Code repository for Python Deep Learning, publ...   \n",
       "8   Tutorial material on the scientific Python eco...   \n",
       "9   Tutorial material on the scientific Python eco...   \n",
       "10   Samples for Google Cloud Machine Learning Engine   \n",
       "\n",
       "                                          archive_url  archived  \\\n",
       "0   https://api.github.com/repos/NLeSC/deep-learni...      True   \n",
       "1   https://api.github.com/repos/SkalskiP/ILearnDe...     False   \n",
       "2   https://api.github.com/repos/fchollet/deep-lea...     False   \n",
       "3   https://api.github.com/repos/fchollet/deep-lea...     False   \n",
       "4   https://api.github.com/repos/fchollet/deep-lea...     False   \n",
       "5   https://api.github.com/repos/chibueze07/Machin...     False   \n",
       "6   https://api.github.com/repos/fastnlp/fastNLP/{...     False   \n",
       "7   https://api.github.com/repos/PacktPublishing/P...     False   \n",
       "8   https://api.github.com/repos/scipy-lectures/sc...     False   \n",
       "9   https://api.github.com/repos/scipy-lectures/sc...     False   \n",
       "10  https://api.github.com/repos/GoogleCloudPlatfo...     False   \n",
       "\n",
       "                                        assignees_url  \\\n",
       "0   https://api.github.com/repos/NLeSC/deep-learni...   \n",
       "1   https://api.github.com/repos/SkalskiP/ILearnDe...   \n",
       "2   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "3   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "4   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "5   https://api.github.com/repos/chibueze07/Machin...   \n",
       "6   https://api.github.com/repos/fastnlp/fastNLP/a...   \n",
       "7   https://api.github.com/repos/PacktPublishing/P...   \n",
       "8   https://api.github.com/repos/scipy-lectures/sc...   \n",
       "9   https://api.github.com/repos/scipy-lectures/sc...   \n",
       "10  https://api.github.com/repos/GoogleCloudPlatfo...   \n",
       "\n",
       "                                            blobs_url  \\\n",
       "0   https://api.github.com/repos/NLeSC/deep-learni...   \n",
       "1   https://api.github.com/repos/SkalskiP/ILearnDe...   \n",
       "2   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "3   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "4   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "5   https://api.github.com/repos/chibueze07/Machin...   \n",
       "6   https://api.github.com/repos/fastnlp/fastNLP/g...   \n",
       "7   https://api.github.com/repos/PacktPublishing/P...   \n",
       "8   https://api.github.com/repos/scipy-lectures/sc...   \n",
       "9   https://api.github.com/repos/scipy-lectures/sc...   \n",
       "10  https://api.github.com/repos/GoogleCloudPlatfo...   \n",
       "\n",
       "                                         branches_url  \\\n",
       "0   https://api.github.com/repos/NLeSC/deep-learni...   \n",
       "1   https://api.github.com/repos/SkalskiP/ILearnDe...   \n",
       "2   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "3   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "4   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "5   https://api.github.com/repos/chibueze07/Machin...   \n",
       "6   https://api.github.com/repos/fastnlp/fastNLP/b...   \n",
       "7   https://api.github.com/repos/PacktPublishing/P...   \n",
       "8   https://api.github.com/repos/scipy-lectures/sc...   \n",
       "9   https://api.github.com/repos/scipy-lectures/sc...   \n",
       "10  https://api.github.com/repos/GoogleCloudPlatfo...   \n",
       "\n",
       "                                            clone_url      ...        \\\n",
       "0   https://github.com/NLeSC/deep-learning-assignm...      ...         \n",
       "1   https://github.com/SkalskiP/ILearnDeepLearning...      ...         \n",
       "2   https://github.com/fchollet/deep-learning-with...      ...         \n",
       "3   https://github.com/fchollet/deep-learning-with...      ...         \n",
       "4   https://github.com/fchollet/deep-learning-with...      ...         \n",
       "5   https://github.com/chibueze07/Machine-Learning...      ...         \n",
       "6              https://github.com/fastnlp/fastNLP.git      ...         \n",
       "7   https://github.com/PacktPublishing/Python-Deep...      ...         \n",
       "8   https://github.com/scipy-lectures/scipy-lectur...      ...         \n",
       "9   https://github.com/scipy-lectures/scipy-lectur...      ...         \n",
       "10  https://github.com/GoogleCloudPlatform/cloudml...      ...         \n",
       "\n",
       "                                      subscribers_url  \\\n",
       "0   https://api.github.com/repos/NLeSC/deep-learni...   \n",
       "1   https://api.github.com/repos/SkalskiP/ILearnDe...   \n",
       "2   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "3   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "4   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "5   https://api.github.com/repos/chibueze07/Machin...   \n",
       "6   https://api.github.com/repos/fastnlp/fastNLP/s...   \n",
       "7   https://api.github.com/repos/PacktPublishing/P...   \n",
       "8   https://api.github.com/repos/scipy-lectures/sc...   \n",
       "9   https://api.github.com/repos/scipy-lectures/sc...   \n",
       "10  https://api.github.com/repos/GoogleCloudPlatfo...   \n",
       "\n",
       "                                     subscription_url  \\\n",
       "0   https://api.github.com/repos/NLeSC/deep-learni...   \n",
       "1   https://api.github.com/repos/SkalskiP/ILearnDe...   \n",
       "2   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "3   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "4   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "5   https://api.github.com/repos/chibueze07/Machin...   \n",
       "6   https://api.github.com/repos/fastnlp/fastNLP/s...   \n",
       "7   https://api.github.com/repos/PacktPublishing/P...   \n",
       "8   https://api.github.com/repos/scipy-lectures/sc...   \n",
       "9   https://api.github.com/repos/scipy-lectures/sc...   \n",
       "10  https://api.github.com/repos/GoogleCloudPlatfo...   \n",
       "\n",
       "                                              svn_url  \\\n",
       "0   https://github.com/NLeSC/deep-learning-assignm...   \n",
       "1   https://github.com/SkalskiP/ILearnDeepLearning.py   \n",
       "2   https://github.com/fchollet/deep-learning-with...   \n",
       "3   https://github.com/fchollet/deep-learning-with...   \n",
       "4   https://github.com/fchollet/deep-learning-with...   \n",
       "5   https://github.com/chibueze07/Machine-Learning...   \n",
       "6                  https://github.com/fastnlp/fastNLP   \n",
       "7   https://github.com/PacktPublishing/Python-Deep...   \n",
       "8   https://github.com/scipy-lectures/scipy-lectur...   \n",
       "9   https://github.com/scipy-lectures/scipy-lectur...   \n",
       "10  https://github.com/GoogleCloudPlatform/cloudml...   \n",
       "\n",
       "                                             tags_url  \\\n",
       "0   https://api.github.com/repos/NLeSC/deep-learni...   \n",
       "1   https://api.github.com/repos/SkalskiP/ILearnDe...   \n",
       "2   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "3   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "4   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "5   https://api.github.com/repos/chibueze07/Machin...   \n",
       "6   https://api.github.com/repos/fastnlp/fastNLP/tags   \n",
       "7   https://api.github.com/repos/PacktPublishing/P...   \n",
       "8   https://api.github.com/repos/scipy-lectures/sc...   \n",
       "9   https://api.github.com/repos/scipy-lectures/sc...   \n",
       "10  https://api.github.com/repos/GoogleCloudPlatfo...   \n",
       "\n",
       "                                            teams_url  \\\n",
       "0   https://api.github.com/repos/NLeSC/deep-learni...   \n",
       "1   https://api.github.com/repos/SkalskiP/ILearnDe...   \n",
       "2   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "3   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "4   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "5   https://api.github.com/repos/chibueze07/Machin...   \n",
       "6   https://api.github.com/repos/fastnlp/fastNLP/t...   \n",
       "7   https://api.github.com/repos/PacktPublishing/P...   \n",
       "8   https://api.github.com/repos/scipy-lectures/sc...   \n",
       "9   https://api.github.com/repos/scipy-lectures/sc...   \n",
       "10  https://api.github.com/repos/GoogleCloudPlatfo...   \n",
       "\n",
       "                                            trees_url            updated_at  \\\n",
       "0   https://api.github.com/repos/NLeSC/deep-learni...  2019-02-01T12:02:11Z   \n",
       "1   https://api.github.com/repos/SkalskiP/ILearnDe...  2019-03-12T03:56:01Z   \n",
       "2   https://api.github.com/repos/fchollet/deep-lea...  2019-03-11T17:20:36Z   \n",
       "3   https://api.github.com/repos/fchollet/deep-lea...  2019-03-13T01:05:58Z   \n",
       "4   https://api.github.com/repos/fchollet/deep-lea...  2019-03-13T15:29:41Z   \n",
       "5   https://api.github.com/repos/chibueze07/Machin...  2019-02-08T13:08:21Z   \n",
       "6   https://api.github.com/repos/fastnlp/fastNLP/g...  2019-03-13T11:16:08Z   \n",
       "7   https://api.github.com/repos/PacktPublishing/P...  2019-03-04T17:21:52Z   \n",
       "8   https://api.github.com/repos/scipy-lectures/sc...  2019-03-11T20:57:25Z   \n",
       "9   https://api.github.com/repos/scipy-lectures/sc...  2019-03-11T20:57:25Z   \n",
       "10  https://api.github.com/repos/GoogleCloudPlatfo...  2019-03-12T15:08:47Z   \n",
       "\n",
       "                                                  url watchers watchers_count  \n",
       "0   https://api.github.com/repos/NLeSC/deep-learni...       14             14  \n",
       "1   https://api.github.com/repos/SkalskiP/ILearnDe...      395            395  \n",
       "2   https://api.github.com/repos/fchollet/deep-lea...     6152           6152  \n",
       "3   https://api.github.com/repos/fchollet/deep-lea...     6157           6157  \n",
       "4   https://api.github.com/repos/fchollet/deep-lea...     6162           6162  \n",
       "5   https://api.github.com/repos/chibueze07/Machin...       20             20  \n",
       "6        https://api.github.com/repos/fastnlp/fastNLP      264            264  \n",
       "7   https://api.github.com/repos/PacktPublishing/P...       55             55  \n",
       "8   https://api.github.com/repos/scipy-lectures/sc...     2074           2074  \n",
       "9   https://api.github.com/repos/scipy-lectures/sc...     2074           2074  \n",
       "10  https://api.github.com/repos/GoogleCloudPlatfo...      917            917  \n",
       "\n",
       "[11 rows x 79 columns]"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_3_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T00:58:39.638406Z",
     "start_time": "2019-03-27T00:58:39.611244Z"
    }
   },
   "outputs": [],
   "source": [
    "repo_1_merged = repo_1_merged[~repo_1_merged['archive_url'].str.contains('fchollet') == True]\n",
    "repo_2_merged = repo_2_merged[~repo_2_merged['archive_url'].str.contains('fchollet') == True]\n",
    "repo_3_merged = repo_3_merged[~repo_3_merged['archive_url'].str.contains('fchollet') == True]\n",
    "repo_4_merged = repo_4_merged[~repo_4_merged['archive_url'].str.contains('fchollet') == True]\n",
    "repo_5_merged = repo_5_merged[~repo_5_merged['archive_url'].str.contains('fchollet') == True]\n",
    "repo_6_merged = repo_6_merged[~repo_6_merged['archive_url'].str.contains('fchollet') == True]\n",
    "repo_7_merged = repo_7_merged[~repo_7_merged['archive_url'].str.contains('fchollet') == True]\n",
    "repo_8_merged = repo_8_merged[~repo_8_merged['archive_url'].str.contains('fchollet') == True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['archive_url'].isin(['fchollet'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T00:58:42.166265Z",
     "start_time": "2019-03-27T00:58:42.148879Z"
    }
   },
   "outputs": [],
   "source": [
    "c_1 = repo_1_merged.to_json()\n",
    "c_2 = repo_2_merged.to_json()\n",
    "c_3 = repo_3_merged.to_json()\n",
    "c_4 = repo_4_merged.to_json()\n",
    "c_5 = repo_5_merged.to_json()\n",
    "c_6 = repo_6_merged.to_json()\n",
    "c_7 = repo_7_merged.to_json()\n",
    "c_8 = repo_8_merged.to_json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T21:51:34.120607Z",
     "start_time": "2019-03-26T21:51:34.111863Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('repo_1_sim.json', 'w') as outfile:\n",
    "    json.dump(c_1, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T21:51:36.005067Z",
     "start_time": "2019-03-26T21:51:36.000068Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('repo_2_sim.json', 'w') as outfile:\n",
    "    json.dump(c_2, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T21:51:37.598670Z",
     "start_time": "2019-03-26T21:51:37.592369Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('repo_3_sim.json', 'w') as outfile:\n",
    "    json.dump(c_3, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T21:51:39.310488Z",
     "start_time": "2019-03-26T21:51:39.306084Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('repo_4_sim.json', 'w') as outfile:\n",
    "    json.dump(c_4, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T21:51:40.959861Z",
     "start_time": "2019-03-26T21:51:40.954975Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('repo_5_sim.json', 'w') as outfile:\n",
    "    json.dump(c_5, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T21:51:42.688416Z",
     "start_time": "2019-03-26T21:51:42.683875Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('repo_6_sim.json', 'w') as outfile:\n",
    "    json.dump(c_6, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T21:51:44.297545Z",
     "start_time": "2019-03-26T21:51:44.287931Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('repo_7_sim.json', 'w') as outfile:\n",
    "    json.dump(c_7, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T21:51:46.097978Z",
     "start_time": "2019-03-26T21:51:46.091782Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('repo_8_sim.json', 'w') as outfile:\n",
    "    json.dump(c_8, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T21:35:47.734818Z",
     "start_time": "2019-03-26T21:35:46.808Z"
    }
   },
   "outputs": [],
   "source": [
    "repo_1_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T20:53:35.965441Z",
     "start_time": "2019-03-26T20:53:35.949Z"
    }
   },
   "outputs": [],
   "source": [
    "repo_1_merged[['name_x', 'description', 'html_url', 'topic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T21:13:09.865033Z",
     "start_time": "2019-03-26T21:13:09.819411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>index</th>\n",
       "      <th>id_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>machine_learning</th>\n",
       "      <th>scikit_learn</th>\n",
       "      <th>jupyter_notebook</th>\n",
       "      <th>python_library</th>\n",
       "      <th>...</th>\n",
       "      <th>subscribers_url</th>\n",
       "      <th>subscription_url</th>\n",
       "      <th>svn_url</th>\n",
       "      <th>tags_url</th>\n",
       "      <th>teams_url</th>\n",
       "      <th>trees_url</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>url</th>\n",
       "      <th>watchers</th>\n",
       "      <th>watchers_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>76567679</td>\n",
       "      <td>The deeplearning algorithms implemented by ten...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>64878964</td>\n",
       "      <td>Keras code and weights files for popular deep ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64878964.0</td>\n",
       "      <td>deep-learning-models</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-models</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>2019-03-12T18:22:08Z</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>4763.0</td>\n",
       "      <td>4763.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>102523304</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102523304.0</td>\n",
       "      <td>deep-learning-with-python-notebooks</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-with...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>2019-03-11T17:20:36Z</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>6152.0</td>\n",
       "      <td>6152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>102523304</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>102523304.0</td>\n",
       "      <td>deep-learning-with-python-notebooks</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-with...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>2019-03-13T01:05:58Z</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>6157.0</td>\n",
       "      <td>6157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>102523304</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>102523304.0</td>\n",
       "      <td>deep-learning-with-python-notebooks</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-with...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>2019-03-13T15:29:41Z</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>6162.0</td>\n",
       "      <td>6162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>102523304</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>102523304.0</td>\n",
       "      <td>deep-learning-with-python-notebooks</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-with...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>2019-03-11T17:20:36Z</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>6152.0</td>\n",
       "      <td>6152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>102523304</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>102523304.0</td>\n",
       "      <td>deep-learning-with-python-notebooks</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-with...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>2019-03-13T01:05:58Z</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>6157.0</td>\n",
       "      <td>6157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>102523304</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>102523304.0</td>\n",
       "      <td>deep-learning-with-python-notebooks</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-with...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>2019-03-13T15:29:41Z</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>6162.0</td>\n",
       "      <td>6162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>102523304</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>102523304.0</td>\n",
       "      <td>deep-learning-with-python-notebooks</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-with...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>2019-03-11T17:20:36Z</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>6152.0</td>\n",
       "      <td>6152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>102523304</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>102523304.0</td>\n",
       "      <td>deep-learning-with-python-notebooks</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-with...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>2019-03-13T01:05:58Z</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>6157.0</td>\n",
       "      <td>6157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>102523304</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>102523304.0</td>\n",
       "      <td>deep-learning-with-python-notebooks</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-with...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>2019-03-13T15:29:41Z</td>\n",
       "      <td>https://api.github.com/repos/fchollet/deep-lea...</td>\n",
       "      <td>6162.0</td>\n",
       "      <td>6162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>84625248</td>\n",
       "      <td>A project illustrating the capabilities of ML ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>115299896</td>\n",
       "      <td>pytorch neural combinatorial optimization</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>64428695</td>\n",
       "      <td>Directory of tutorials and open-source code re...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64428695.0</td>\n",
       "      <td>keras-resources</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/keras-re...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/keras-re...</td>\n",
       "      <td>https://github.com/fchollet/keras-resources</td>\n",
       "      <td>https://api.github.com/repos/fchollet/keras-re...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/keras-re...</td>\n",
       "      <td>https://api.github.com/repos/fchollet/keras-re...</td>\n",
       "      <td>2019-03-12T15:14:52Z</td>\n",
       "      <td>https://api.github.com/repos/fchollet/keras-re...</td>\n",
       "      <td>2707.0</td>\n",
       "      <td>2707.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>7648106</td>\n",
       "      <td>python 2.7 tutorial ‰∏≠ÊñáÁâàÊú¨</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>45717250</td>\n",
       "      <td>An Open Source Machine Learning Framework for ...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>169159059.0</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>https://github.com/tensorflow/tensorflow</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>2019-03-13T00:15:57Z</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>122588.0</td>\n",
       "      <td>122588.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows √ó 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    level_0         id                                        description  \\\n",
       "0         0   76567679  The deeplearning algorithms implemented by ten...   \n",
       "1         1   64878964  Keras code and weights files for popular deep ...   \n",
       "2         2  102523304  Jupyter notebooks for the code samples of the ...   \n",
       "3         3  102523304  Jupyter notebooks for the code samples of the ...   \n",
       "4         4  102523304  Jupyter notebooks for the code samples of the ...   \n",
       "5         5  102523304  Jupyter notebooks for the code samples of the ...   \n",
       "6         6  102523304  Jupyter notebooks for the code samples of the ...   \n",
       "7         7  102523304  Jupyter notebooks for the code samples of the ...   \n",
       "8         8  102523304  Jupyter notebooks for the code samples of the ...   \n",
       "9         9  102523304  Jupyter notebooks for the code samples of the ...   \n",
       "10       10  102523304  Jupyter notebooks for the code samples of the ...   \n",
       "11       11   84625248  A project illustrating the capabilities of ML ...   \n",
       "12       12  115299896          pytorch neural combinatorial optimization   \n",
       "13       13   64428695  Directory of tutorials and open-source code re...   \n",
       "14       14    7648106                           python 2.7 tutorial ‰∏≠ÊñáÁâàÊú¨   \n",
       "15       15   45717250  An Open Source Machine Learning Framework for ...   \n",
       "\n",
       "    index         id_x                               name_x  machine_learning  \\\n",
       "0     NaN          NaN                                  NaN               NaN   \n",
       "1     0.0   64878964.0                 deep-learning-models              0.01   \n",
       "2     1.0  102523304.0  deep-learning-with-python-notebooks              0.01   \n",
       "3     2.0  102523304.0  deep-learning-with-python-notebooks              0.01   \n",
       "4     3.0  102523304.0  deep-learning-with-python-notebooks              0.01   \n",
       "5     4.0  102523304.0  deep-learning-with-python-notebooks              0.01   \n",
       "6     5.0  102523304.0  deep-learning-with-python-notebooks              0.01   \n",
       "7     6.0  102523304.0  deep-learning-with-python-notebooks              0.01   \n",
       "8     7.0  102523304.0  deep-learning-with-python-notebooks              0.01   \n",
       "9     8.0  102523304.0  deep-learning-with-python-notebooks              0.01   \n",
       "10    9.0  102523304.0  deep-learning-with-python-notebooks              0.01   \n",
       "11    NaN          NaN                                  NaN               NaN   \n",
       "12    NaN          NaN                                  NaN               NaN   \n",
       "13   10.0   64428695.0                      keras-resources              0.01   \n",
       "14    NaN          NaN                                  NaN               NaN   \n",
       "15   11.0  169159059.0                           tensorflow              0.17   \n",
       "\n",
       "    scikit_learn  jupyter_notebook  python_library      ...        \\\n",
       "0            NaN               NaN             NaN      ...         \n",
       "1            0.0              0.01            0.01      ...         \n",
       "2            0.0              0.25            0.20      ...         \n",
       "3            0.0              0.25            0.20      ...         \n",
       "4            0.0              0.25            0.20      ...         \n",
       "5            0.0              0.25            0.20      ...         \n",
       "6            0.0              0.25            0.20      ...         \n",
       "7            0.0              0.25            0.20      ...         \n",
       "8            0.0              0.25            0.20      ...         \n",
       "9            0.0              0.25            0.20      ...         \n",
       "10           0.0              0.25            0.20      ...         \n",
       "11           NaN               NaN             NaN      ...         \n",
       "12           NaN               NaN             NaN      ...         \n",
       "13           0.0              0.01            0.22      ...         \n",
       "14           NaN               NaN             NaN      ...         \n",
       "15           0.0              0.00            0.00      ...         \n",
       "\n",
       "                                      subscribers_url  \\\n",
       "0                                                 NaN   \n",
       "1   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "2   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "3   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "4   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "5   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "6   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "7   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "8   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "9   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "10  https://api.github.com/repos/fchollet/deep-lea...   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13  https://api.github.com/repos/fchollet/keras-re...   \n",
       "14                                                NaN   \n",
       "15  https://api.github.com/repos/tensorflow/tensor...   \n",
       "\n",
       "                                     subscription_url  \\\n",
       "0                                                 NaN   \n",
       "1   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "2   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "3   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "4   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "5   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "6   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "7   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "8   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "9   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "10  https://api.github.com/repos/fchollet/deep-lea...   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13  https://api.github.com/repos/fchollet/keras-re...   \n",
       "14                                                NaN   \n",
       "15  https://api.github.com/repos/tensorflow/tensor...   \n",
       "\n",
       "                                              svn_url  \\\n",
       "0                                                 NaN   \n",
       "1    https://github.com/fchollet/deep-learning-models   \n",
       "2   https://github.com/fchollet/deep-learning-with...   \n",
       "3   https://github.com/fchollet/deep-learning-with...   \n",
       "4   https://github.com/fchollet/deep-learning-with...   \n",
       "5   https://github.com/fchollet/deep-learning-with...   \n",
       "6   https://github.com/fchollet/deep-learning-with...   \n",
       "7   https://github.com/fchollet/deep-learning-with...   \n",
       "8   https://github.com/fchollet/deep-learning-with...   \n",
       "9   https://github.com/fchollet/deep-learning-with...   \n",
       "10  https://github.com/fchollet/deep-learning-with...   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13        https://github.com/fchollet/keras-resources   \n",
       "14                                                NaN   \n",
       "15           https://github.com/tensorflow/tensorflow   \n",
       "\n",
       "                                             tags_url  \\\n",
       "0                                                 NaN   \n",
       "1   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "2   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "3   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "4   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "5   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "6   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "7   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "8   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "9   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "10  https://api.github.com/repos/fchollet/deep-lea...   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13  https://api.github.com/repos/fchollet/keras-re...   \n",
       "14                                                NaN   \n",
       "15  https://api.github.com/repos/tensorflow/tensor...   \n",
       "\n",
       "                                            teams_url  \\\n",
       "0                                                 NaN   \n",
       "1   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "2   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "3   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "4   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "5   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "6   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "7   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "8   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "9   https://api.github.com/repos/fchollet/deep-lea...   \n",
       "10  https://api.github.com/repos/fchollet/deep-lea...   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13  https://api.github.com/repos/fchollet/keras-re...   \n",
       "14                                                NaN   \n",
       "15  https://api.github.com/repos/tensorflow/tensor...   \n",
       "\n",
       "                                            trees_url            updated_at  \\\n",
       "0                                                 NaN                   NaN   \n",
       "1   https://api.github.com/repos/fchollet/deep-lea...  2019-03-12T18:22:08Z   \n",
       "2   https://api.github.com/repos/fchollet/deep-lea...  2019-03-11T17:20:36Z   \n",
       "3   https://api.github.com/repos/fchollet/deep-lea...  2019-03-13T01:05:58Z   \n",
       "4   https://api.github.com/repos/fchollet/deep-lea...  2019-03-13T15:29:41Z   \n",
       "5   https://api.github.com/repos/fchollet/deep-lea...  2019-03-11T17:20:36Z   \n",
       "6   https://api.github.com/repos/fchollet/deep-lea...  2019-03-13T01:05:58Z   \n",
       "7   https://api.github.com/repos/fchollet/deep-lea...  2019-03-13T15:29:41Z   \n",
       "8   https://api.github.com/repos/fchollet/deep-lea...  2019-03-11T17:20:36Z   \n",
       "9   https://api.github.com/repos/fchollet/deep-lea...  2019-03-13T01:05:58Z   \n",
       "10  https://api.github.com/repos/fchollet/deep-lea...  2019-03-13T15:29:41Z   \n",
       "11                                                NaN                   NaN   \n",
       "12                                                NaN                   NaN   \n",
       "13  https://api.github.com/repos/fchollet/keras-re...  2019-03-12T15:14:52Z   \n",
       "14                                                NaN                   NaN   \n",
       "15  https://api.github.com/repos/tensorflow/tensor...  2019-03-13T00:15:57Z   \n",
       "\n",
       "                                                  url  watchers watchers_count  \n",
       "0                                                 NaN       NaN            NaN  \n",
       "1   https://api.github.com/repos/fchollet/deep-lea...    4763.0         4763.0  \n",
       "2   https://api.github.com/repos/fchollet/deep-lea...    6152.0         6152.0  \n",
       "3   https://api.github.com/repos/fchollet/deep-lea...    6157.0         6157.0  \n",
       "4   https://api.github.com/repos/fchollet/deep-lea...    6162.0         6162.0  \n",
       "5   https://api.github.com/repos/fchollet/deep-lea...    6152.0         6152.0  \n",
       "6   https://api.github.com/repos/fchollet/deep-lea...    6157.0         6157.0  \n",
       "7   https://api.github.com/repos/fchollet/deep-lea...    6162.0         6162.0  \n",
       "8   https://api.github.com/repos/fchollet/deep-lea...    6152.0         6152.0  \n",
       "9   https://api.github.com/repos/fchollet/deep-lea...    6157.0         6157.0  \n",
       "10  https://api.github.com/repos/fchollet/deep-lea...    6162.0         6162.0  \n",
       "11                                                NaN       NaN            NaN  \n",
       "12                                                NaN       NaN            NaN  \n",
       "13  https://api.github.com/repos/fchollet/keras-re...    2707.0         2707.0  \n",
       "14                                                NaN       NaN            NaN  \n",
       "15  https://api.github.com/repos/tensorflow/tensor...  122588.0       122588.0  \n",
       "\n",
       "[16 rows x 90 columns]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_1_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T21:14:13.293843Z",
     "start_time": "2019-03-26T21:14:13.282958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>76567679</td>\n",
       "      <td>The deeplearning algorithms implemented by ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>64878964</td>\n",
       "      <td>Keras code and weights files for popular deep ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>102523304</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>84625248</td>\n",
       "      <td>A project illustrating the capabilities of ML ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>115299896</td>\n",
       "      <td>pytorch neural combinatorial optimization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3689</th>\n",
       "      <td>64428695</td>\n",
       "      <td>Directory of tutorials and open-source code re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>7648106</td>\n",
       "      <td>python 2.7 tutorial ‰∏≠ÊñáÁâàÊú¨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>45717250</td>\n",
       "      <td>An Open Source Machine Learning Framework for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                        description\n",
       "3100   76567679  The deeplearning algorithms implemented by ten...\n",
       "3076   64878964  Keras code and weights files for popular deep ...\n",
       "1071  102523304  Jupyter notebooks for the code samples of the ...\n",
       "717    84625248  A project illustrating the capabilities of ML ...\n",
       "3508  115299896          pytorch neural combinatorial optimization\n",
       "3689   64428695  Directory of tutorials and open-source code re...\n",
       "1279    7648106                           python 2.7 tutorial ‰∏≠ÊñáÁâàÊú¨\n",
       "2053   45717250  An Open Source Machine Learning Framework for ..."
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T21:28:05.896941Z",
     "start_time": "2019-03-26T21:28:05.890869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     76567679\n",
       "1     64878964\n",
       "2    102523304\n",
       "3     84625248\n",
       "4    115299896\n",
       "5     64428695\n",
       "6      7648106\n",
       "7     45717250\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_1['id']\n",
    "# = repos_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T22:36:36.192117Z",
     "start_time": "2019-03-26T22:36:36.149913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>description_x</th>\n",
       "      <th>archive_url</th>\n",
       "      <th>archived</th>\n",
       "      <th>assignees_url</th>\n",
       "      <th>blobs_url</th>\n",
       "      <th>branches_url</th>\n",
       "      <th>clone_url</th>\n",
       "      <th>...</th>\n",
       "      <th>subscribers_url</th>\n",
       "      <th>subscription_url</th>\n",
       "      <th>svn_url</th>\n",
       "      <th>tags_url</th>\n",
       "      <th>teams_url</th>\n",
       "      <th>trees_url</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>url</th>\n",
       "      <th>watchers</th>\n",
       "      <th>watchers_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3100</td>\n",
       "      <td>76567679</td>\n",
       "      <td>The deeplearning algorithms implemented by ten...</td>\n",
       "      <td>https://api.github.com/repos/xiaohu2015/DeepLe...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/xiaohu2015/DeepLe...</td>\n",
       "      <td>https://api.github.com/repos/xiaohu2015/DeepLe...</td>\n",
       "      <td>https://api.github.com/repos/xiaohu2015/DeepLe...</td>\n",
       "      <td>https://github.com/xiaohu2015/DeepLearning_tut...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/xiaohu2015/DeepLe...</td>\n",
       "      <td>https://api.github.com/repos/xiaohu2015/DeepLe...</td>\n",
       "      <td>https://github.com/xiaohu2015/DeepLearning_tut...</td>\n",
       "      <td>https://api.github.com/repos/xiaohu2015/DeepLe...</td>\n",
       "      <td>https://api.github.com/repos/xiaohu2015/DeepLe...</td>\n",
       "      <td>https://api.github.com/repos/xiaohu2015/DeepLe...</td>\n",
       "      <td>2019-03-12T08:56:40Z</td>\n",
       "      <td>https://api.github.com/repos/xiaohu2015/DeepLe...</td>\n",
       "      <td>734</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>717</td>\n",
       "      <td>84625248</td>\n",
       "      <td>A project illustrating the capabilities of ML ...</td>\n",
       "      <td>https://api.github.com/repos/aakash049/SciKit-...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/aakash049/SciKit-...</td>\n",
       "      <td>https://api.github.com/repos/aakash049/SciKit-...</td>\n",
       "      <td>https://api.github.com/repos/aakash049/SciKit-...</td>\n",
       "      <td>https://github.com/aakash049/SciKit-Play.git</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/aakash049/SciKit-...</td>\n",
       "      <td>https://api.github.com/repos/aakash049/SciKit-...</td>\n",
       "      <td>https://github.com/aakash049/SciKit-Play</td>\n",
       "      <td>https://api.github.com/repos/aakash049/SciKit-...</td>\n",
       "      <td>https://api.github.com/repos/aakash049/SciKit-...</td>\n",
       "      <td>https://api.github.com/repos/aakash049/SciKit-...</td>\n",
       "      <td>2017-07-31T12:46:13Z</td>\n",
       "      <td>https://api.github.com/repos/aakash049/SciKit-...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3508</td>\n",
       "      <td>115299896</td>\n",
       "      <td>pytorch neural combinatorial optimization</td>\n",
       "      <td>https://api.github.com/repos/higgsfield/np-har...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/higgsfield/np-har...</td>\n",
       "      <td>https://api.github.com/repos/higgsfield/np-har...</td>\n",
       "      <td>https://api.github.com/repos/higgsfield/np-har...</td>\n",
       "      <td>https://github.com/higgsfield/np-hard-deep-rei...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/higgsfield/np-har...</td>\n",
       "      <td>https://api.github.com/repos/higgsfield/np-har...</td>\n",
       "      <td>https://github.com/higgsfield/np-hard-deep-rei...</td>\n",
       "      <td>https://api.github.com/repos/higgsfield/np-har...</td>\n",
       "      <td>https://api.github.com/repos/higgsfield/np-har...</td>\n",
       "      <td>https://api.github.com/repos/higgsfield/np-har...</td>\n",
       "      <td>2019-03-12T14:24:51Z</td>\n",
       "      <td>https://api.github.com/repos/higgsfield/np-har...</td>\n",
       "      <td>167</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1279</td>\n",
       "      <td>7648106</td>\n",
       "      <td>python 2.7 tutorial ‰∏≠ÊñáÁâàÊú¨</td>\n",
       "      <td>https://api.github.com/repos/sixu05202004/pyth...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/sixu05202004/pyth...</td>\n",
       "      <td>https://api.github.com/repos/sixu05202004/pyth...</td>\n",
       "      <td>https://api.github.com/repos/sixu05202004/pyth...</td>\n",
       "      <td>https://github.com/sixu05202004/pythontutorial...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/sixu05202004/pyth...</td>\n",
       "      <td>https://api.github.com/repos/sixu05202004/pyth...</td>\n",
       "      <td>https://github.com/sixu05202004/pythontutorial</td>\n",
       "      <td>https://api.github.com/repos/sixu05202004/pyth...</td>\n",
       "      <td>https://api.github.com/repos/sixu05202004/pyth...</td>\n",
       "      <td>https://api.github.com/repos/sixu05202004/pyth...</td>\n",
       "      <td>2019-03-07T07:44:32Z</td>\n",
       "      <td>https://api.github.com/repos/sixu05202004/pyth...</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2053</td>\n",
       "      <td>45717250</td>\n",
       "      <td>An Open Source Machine Learning Framework for ...</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>https://github.com/tensorflow/tensorflow.git</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>https://github.com/tensorflow/tensorflow</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>2019-03-13T00:15:57Z</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>122588</td>\n",
       "      <td>122588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index         id  \\\n",
       "0        0   3100   76567679   \n",
       "5        5    717   84625248   \n",
       "6        6   3508  115299896   \n",
       "8        8   1279    7648106   \n",
       "9        9   2053   45717250   \n",
       "\n",
       "                                       description_x  \\\n",
       "0  The deeplearning algorithms implemented by ten...   \n",
       "5  A project illustrating the capabilities of ML ...   \n",
       "6          pytorch neural combinatorial optimization   \n",
       "8                           python 2.7 tutorial ‰∏≠ÊñáÁâàÊú¨   \n",
       "9  An Open Source Machine Learning Framework for ...   \n",
       "\n",
       "                                         archive_url  archived  \\\n",
       "0  https://api.github.com/repos/xiaohu2015/DeepLe...     False   \n",
       "5  https://api.github.com/repos/aakash049/SciKit-...     False   \n",
       "6  https://api.github.com/repos/higgsfield/np-har...     False   \n",
       "8  https://api.github.com/repos/sixu05202004/pyth...     False   \n",
       "9  https://api.github.com/repos/tensorflow/tensor...     False   \n",
       "\n",
       "                                       assignees_url  \\\n",
       "0  https://api.github.com/repos/xiaohu2015/DeepLe...   \n",
       "5  https://api.github.com/repos/aakash049/SciKit-...   \n",
       "6  https://api.github.com/repos/higgsfield/np-har...   \n",
       "8  https://api.github.com/repos/sixu05202004/pyth...   \n",
       "9  https://api.github.com/repos/tensorflow/tensor...   \n",
       "\n",
       "                                           blobs_url  \\\n",
       "0  https://api.github.com/repos/xiaohu2015/DeepLe...   \n",
       "5  https://api.github.com/repos/aakash049/SciKit-...   \n",
       "6  https://api.github.com/repos/higgsfield/np-har...   \n",
       "8  https://api.github.com/repos/sixu05202004/pyth...   \n",
       "9  https://api.github.com/repos/tensorflow/tensor...   \n",
       "\n",
       "                                        branches_url  \\\n",
       "0  https://api.github.com/repos/xiaohu2015/DeepLe...   \n",
       "5  https://api.github.com/repos/aakash049/SciKit-...   \n",
       "6  https://api.github.com/repos/higgsfield/np-har...   \n",
       "8  https://api.github.com/repos/sixu05202004/pyth...   \n",
       "9  https://api.github.com/repos/tensorflow/tensor...   \n",
       "\n",
       "                                           clone_url      ...        \\\n",
       "0  https://github.com/xiaohu2015/DeepLearning_tut...      ...         \n",
       "5       https://github.com/aakash049/SciKit-Play.git      ...         \n",
       "6  https://github.com/higgsfield/np-hard-deep-rei...      ...         \n",
       "8  https://github.com/sixu05202004/pythontutorial...      ...         \n",
       "9       https://github.com/tensorflow/tensorflow.git      ...         \n",
       "\n",
       "                                     subscribers_url  \\\n",
       "0  https://api.github.com/repos/xiaohu2015/DeepLe...   \n",
       "5  https://api.github.com/repos/aakash049/SciKit-...   \n",
       "6  https://api.github.com/repos/higgsfield/np-har...   \n",
       "8  https://api.github.com/repos/sixu05202004/pyth...   \n",
       "9  https://api.github.com/repos/tensorflow/tensor...   \n",
       "\n",
       "                                    subscription_url  \\\n",
       "0  https://api.github.com/repos/xiaohu2015/DeepLe...   \n",
       "5  https://api.github.com/repos/aakash049/SciKit-...   \n",
       "6  https://api.github.com/repos/higgsfield/np-har...   \n",
       "8  https://api.github.com/repos/sixu05202004/pyth...   \n",
       "9  https://api.github.com/repos/tensorflow/tensor...   \n",
       "\n",
       "                                             svn_url  \\\n",
       "0  https://github.com/xiaohu2015/DeepLearning_tut...   \n",
       "5           https://github.com/aakash049/SciKit-Play   \n",
       "6  https://github.com/higgsfield/np-hard-deep-rei...   \n",
       "8     https://github.com/sixu05202004/pythontutorial   \n",
       "9           https://github.com/tensorflow/tensorflow   \n",
       "\n",
       "                                            tags_url  \\\n",
       "0  https://api.github.com/repos/xiaohu2015/DeepLe...   \n",
       "5  https://api.github.com/repos/aakash049/SciKit-...   \n",
       "6  https://api.github.com/repos/higgsfield/np-har...   \n",
       "8  https://api.github.com/repos/sixu05202004/pyth...   \n",
       "9  https://api.github.com/repos/tensorflow/tensor...   \n",
       "\n",
       "                                           teams_url  \\\n",
       "0  https://api.github.com/repos/xiaohu2015/DeepLe...   \n",
       "5  https://api.github.com/repos/aakash049/SciKit-...   \n",
       "6  https://api.github.com/repos/higgsfield/np-har...   \n",
       "8  https://api.github.com/repos/sixu05202004/pyth...   \n",
       "9  https://api.github.com/repos/tensorflow/tensor...   \n",
       "\n",
       "                                           trees_url            updated_at  \\\n",
       "0  https://api.github.com/repos/xiaohu2015/DeepLe...  2019-03-12T08:56:40Z   \n",
       "5  https://api.github.com/repos/aakash049/SciKit-...  2017-07-31T12:46:13Z   \n",
       "6  https://api.github.com/repos/higgsfield/np-har...  2019-03-12T14:24:51Z   \n",
       "8  https://api.github.com/repos/sixu05202004/pyth...  2019-03-07T07:44:32Z   \n",
       "9  https://api.github.com/repos/tensorflow/tensor...  2019-03-13T00:15:57Z   \n",
       "\n",
       "                                                 url watchers watchers_count  \n",
       "0  https://api.github.com/repos/xiaohu2015/DeepLe...      734            734  \n",
       "5  https://api.github.com/repos/aakash049/SciKit-...        4              4  \n",
       "6  https://api.github.com/repos/higgsfield/np-har...      167            167  \n",
       "8  https://api.github.com/repos/sixu05202004/pyth...      184            184  \n",
       "9  https://api.github.com/repos/tensorflow/tensor...   122588         122588  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repo_1['id']\n",
    "\n",
    "repo_1_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T22:01:00.823239Z",
     "start_time": "2019-03-26T22:01:00.809831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>description</th>\n",
       "      <th>html_url</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64878964</td>\n",
       "      <td>deep-learning-models</td>\n",
       "      <td>Keras code and weights files for popular deep ...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-models</td>\n",
       "      <td>Nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102523304</td>\n",
       "      <td>deep-learning-with-python-notebooks</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-with...</td>\n",
       "      <td>Jupyter notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64428695</td>\n",
       "      <td>keras-resources</td>\n",
       "      <td>Directory of tutorials and open-source code re...</td>\n",
       "      <td>https://github.com/fchollet/keras-resources</td>\n",
       "      <td>Python library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>169159059</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>An Open Source Machine Learning Framework for ...</td>\n",
       "      <td>https://github.com/tensorflow/tensorflow</td>\n",
       "      <td>Machine learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id_x                               name_x  \\\n",
       "0    64878964                 deep-learning-models   \n",
       "1   102523304  deep-learning-with-python-notebooks   \n",
       "10   64428695                      keras-resources   \n",
       "11  169159059                           tensorflow   \n",
       "\n",
       "                                          description  \\\n",
       "0   Keras code and weights files for popular deep ...   \n",
       "1   Jupyter notebooks for the code samples of the ...   \n",
       "10  Directory of tutorials and open-source code re...   \n",
       "11  An Open Source Machine Learning Framework for ...   \n",
       "\n",
       "                                             html_url             topic  \n",
       "0    https://github.com/fchollet/deep-learning-models               Nlp  \n",
       "1   https://github.com/fchollet/deep-learning-with...  Jupyter notebook  \n",
       "10        https://github.com/fchollet/keras-resources    Python library  \n",
       "11           https://github.com/tensorflow/tensorflow  Machine learning  "
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_merged_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:58:44.711674Z",
     "start_time": "2019-03-27T01:58:44.698833Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'repos_merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-18a10b6006f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrepos_merged_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'repos_merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "repos_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T22:21:07.939280Z",
     "start_time": "2019-03-26T22:21:07.894615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>description</th>\n",
       "      <th>html_url</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64878964</td>\n",
       "      <td>deep-learning-models</td>\n",
       "      <td>Keras code and weights files for popular deep ...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-models</td>\n",
       "      <td>Nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102523304</td>\n",
       "      <td>deep-learning-with-python-notebooks</td>\n",
       "      <td>Jupyter notebooks for the code samples of the ...</td>\n",
       "      <td>https://github.com/fchollet/deep-learning-with...</td>\n",
       "      <td>Jupyter notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64428695</td>\n",
       "      <td>keras-resources</td>\n",
       "      <td>Directory of tutorials and open-source code re...</td>\n",
       "      <td>https://github.com/fchollet/keras-resources</td>\n",
       "      <td>Python library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>169159059</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>An Open Source Machine Learning Framework for ...</td>\n",
       "      <td>https://github.com/tensorflow/tensorflow</td>\n",
       "      <td>Machine learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id_x                               name_x  \\\n",
       "0    64878964                 deep-learning-models   \n",
       "1   102523304  deep-learning-with-python-notebooks   \n",
       "10   64428695                      keras-resources   \n",
       "11  169159059                           tensorflow   \n",
       "\n",
       "                                          description  \\\n",
       "0   Keras code and weights files for popular deep ...   \n",
       "1   Jupyter notebooks for the code samples of the ...   \n",
       "10  Directory of tutorials and open-source code re...   \n",
       "11  An Open Source Machine Learning Framework for ...   \n",
       "\n",
       "                                             html_url             topic  \n",
       "0    https://github.com/fchollet/deep-learning-models               Nlp  \n",
       "1   https://github.com/fchollet/deep-learning-with...  Jupyter notebook  \n",
       "10        https://github.com/fchollet/keras-resources    Python library  \n",
       "11           https://github.com/tensorflow/tensorflow  Machine learning  "
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_merged_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T22:23:25.863377Z",
     "start_time": "2019-03-26T22:23:25.856459Z"
    }
   },
   "outputs": [],
   "source": [
    "x9 = repos_merged_df_1.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T22:24:10.650838Z",
     "start_time": "2019-03-26T22:24:10.641148Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('repos_try_2.json', 'w') as outfile:\n",
    "    json.dump(x9, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T22:32:00.650548Z",
     "start_time": "2019-03-26T22:32:00.615955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[64878964, \"deep-learning-models\", \"Keras code and weights files for popular deep learning models.\", \"https://github.com/fchollet/deep-learning-models\", \"Nlp\"], [102523304, \"deep-learning-with-python-notebooks\", \"Jupyter notebooks for the code samples of the book \\\\\"Deep Learning with Python\\\\\"\", \"https://github.com/fchollet/deep-learning-with-python-notebooks\", \"Jupyter notebook\"], [64428695, \"keras-resources\", \"Directory of tutorials and open-source code repositories for working with Keras, the Python deep learning library\", \"https://github.com/fchollet/keras-resources\", \"Python library\"], [169159059, \"tensorflow\", \"An Open Source Machine Learning Framework for Everyone\", \"https://github.com/tensorflow/tensorflow\", \"Machine learning\"]]'"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(x9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:06:01.551505Z",
     "start_time": "2019-03-26T23:06:01.518051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>description_x</th>\n",
       "      <th>archive_url</th>\n",
       "      <th>archived</th>\n",
       "      <th>assignees_url</th>\n",
       "      <th>blobs_url</th>\n",
       "      <th>branches_url</th>\n",
       "      <th>clone_url</th>\n",
       "      <th>...</th>\n",
       "      <th>subscribers_url</th>\n",
       "      <th>subscription_url</th>\n",
       "      <th>svn_url</th>\n",
       "      <th>tags_url</th>\n",
       "      <th>teams_url</th>\n",
       "      <th>trees_url</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>url</th>\n",
       "      <th>watchers</th>\n",
       "      <th>watchers_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3100</td>\n",
       "      <td>76567679</td>\n",
       "      <td>The deeplearning algorithms implemented by ten...</td>\n",
       "      <td>https://api.github.com/repos/xiaohu2015/DeepLe...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/xiaohu2015/DeepLe...</td>\n",
       "      <td>https://api.github.com/repos/xiaohu2015/DeepLe...</td>\n",
       "      <td>https://api.github.com/repos/xiaohu2015/DeepLe...</td>\n",
       "      <td>https://github.com/xiaohu2015/DeepLearning_tut...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/xiaohu2015/DeepLe...</td>\n",
       "      <td>https://api.github.com/repos/xiaohu2015/DeepLe...</td>\n",
       "      <td>https://github.com/xiaohu2015/DeepLearning_tut...</td>\n",
       "      <td>https://api.github.com/repos/xiaohu2015/DeepLe...</td>\n",
       "      <td>https://api.github.com/repos/xiaohu2015/DeepLe...</td>\n",
       "      <td>https://api.github.com/repos/xiaohu2015/DeepLe...</td>\n",
       "      <td>2019-03-12T08:56:40Z</td>\n",
       "      <td>https://api.github.com/repos/xiaohu2015/DeepLe...</td>\n",
       "      <td>734</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>717</td>\n",
       "      <td>84625248</td>\n",
       "      <td>A project illustrating the capabilities of ML ...</td>\n",
       "      <td>https://api.github.com/repos/aakash049/SciKit-...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/aakash049/SciKit-...</td>\n",
       "      <td>https://api.github.com/repos/aakash049/SciKit-...</td>\n",
       "      <td>https://api.github.com/repos/aakash049/SciKit-...</td>\n",
       "      <td>https://github.com/aakash049/SciKit-Play.git</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/aakash049/SciKit-...</td>\n",
       "      <td>https://api.github.com/repos/aakash049/SciKit-...</td>\n",
       "      <td>https://github.com/aakash049/SciKit-Play</td>\n",
       "      <td>https://api.github.com/repos/aakash049/SciKit-...</td>\n",
       "      <td>https://api.github.com/repos/aakash049/SciKit-...</td>\n",
       "      <td>https://api.github.com/repos/aakash049/SciKit-...</td>\n",
       "      <td>2017-07-31T12:46:13Z</td>\n",
       "      <td>https://api.github.com/repos/aakash049/SciKit-...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3508</td>\n",
       "      <td>115299896</td>\n",
       "      <td>pytorch neural combinatorial optimization</td>\n",
       "      <td>https://api.github.com/repos/higgsfield/np-har...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/higgsfield/np-har...</td>\n",
       "      <td>https://api.github.com/repos/higgsfield/np-har...</td>\n",
       "      <td>https://api.github.com/repos/higgsfield/np-har...</td>\n",
       "      <td>https://github.com/higgsfield/np-hard-deep-rei...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/higgsfield/np-har...</td>\n",
       "      <td>https://api.github.com/repos/higgsfield/np-har...</td>\n",
       "      <td>https://github.com/higgsfield/np-hard-deep-rei...</td>\n",
       "      <td>https://api.github.com/repos/higgsfield/np-har...</td>\n",
       "      <td>https://api.github.com/repos/higgsfield/np-har...</td>\n",
       "      <td>https://api.github.com/repos/higgsfield/np-har...</td>\n",
       "      <td>2019-03-12T14:24:51Z</td>\n",
       "      <td>https://api.github.com/repos/higgsfield/np-har...</td>\n",
       "      <td>167</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1279</td>\n",
       "      <td>7648106</td>\n",
       "      <td>python 2.7 tutorial ‰∏≠ÊñáÁâàÊú¨</td>\n",
       "      <td>https://api.github.com/repos/sixu05202004/pyth...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/sixu05202004/pyth...</td>\n",
       "      <td>https://api.github.com/repos/sixu05202004/pyth...</td>\n",
       "      <td>https://api.github.com/repos/sixu05202004/pyth...</td>\n",
       "      <td>https://github.com/sixu05202004/pythontutorial...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/sixu05202004/pyth...</td>\n",
       "      <td>https://api.github.com/repos/sixu05202004/pyth...</td>\n",
       "      <td>https://github.com/sixu05202004/pythontutorial</td>\n",
       "      <td>https://api.github.com/repos/sixu05202004/pyth...</td>\n",
       "      <td>https://api.github.com/repos/sixu05202004/pyth...</td>\n",
       "      <td>https://api.github.com/repos/sixu05202004/pyth...</td>\n",
       "      <td>2019-03-07T07:44:32Z</td>\n",
       "      <td>https://api.github.com/repos/sixu05202004/pyth...</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2053</td>\n",
       "      <td>45717250</td>\n",
       "      <td>An Open Source Machine Learning Framework for ...</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>https://github.com/tensorflow/tensorflow.git</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>https://github.com/tensorflow/tensorflow</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>2019-03-13T00:15:57Z</td>\n",
       "      <td>https://api.github.com/repos/tensorflow/tensor...</td>\n",
       "      <td>122588</td>\n",
       "      <td>122588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index         id  \\\n",
       "0        0   3100   76567679   \n",
       "5        5    717   84625248   \n",
       "6        6   3508  115299896   \n",
       "8        8   1279    7648106   \n",
       "9        9   2053   45717250   \n",
       "\n",
       "                                       description_x  \\\n",
       "0  The deeplearning algorithms implemented by ten...   \n",
       "5  A project illustrating the capabilities of ML ...   \n",
       "6          pytorch neural combinatorial optimization   \n",
       "8                           python 2.7 tutorial ‰∏≠ÊñáÁâàÊú¨   \n",
       "9  An Open Source Machine Learning Framework for ...   \n",
       "\n",
       "                                         archive_url  archived  \\\n",
       "0  https://api.github.com/repos/xiaohu2015/DeepLe...     False   \n",
       "5  https://api.github.com/repos/aakash049/SciKit-...     False   \n",
       "6  https://api.github.com/repos/higgsfield/np-har...     False   \n",
       "8  https://api.github.com/repos/sixu05202004/pyth...     False   \n",
       "9  https://api.github.com/repos/tensorflow/tensor...     False   \n",
       "\n",
       "                                       assignees_url  \\\n",
       "0  https://api.github.com/repos/xiaohu2015/DeepLe...   \n",
       "5  https://api.github.com/repos/aakash049/SciKit-...   \n",
       "6  https://api.github.com/repos/higgsfield/np-har...   \n",
       "8  https://api.github.com/repos/sixu05202004/pyth...   \n",
       "9  https://api.github.com/repos/tensorflow/tensor...   \n",
       "\n",
       "                                           blobs_url  \\\n",
       "0  https://api.github.com/repos/xiaohu2015/DeepLe...   \n",
       "5  https://api.github.com/repos/aakash049/SciKit-...   \n",
       "6  https://api.github.com/repos/higgsfield/np-har...   \n",
       "8  https://api.github.com/repos/sixu05202004/pyth...   \n",
       "9  https://api.github.com/repos/tensorflow/tensor...   \n",
       "\n",
       "                                        branches_url  \\\n",
       "0  https://api.github.com/repos/xiaohu2015/DeepLe...   \n",
       "5  https://api.github.com/repos/aakash049/SciKit-...   \n",
       "6  https://api.github.com/repos/higgsfield/np-har...   \n",
       "8  https://api.github.com/repos/sixu05202004/pyth...   \n",
       "9  https://api.github.com/repos/tensorflow/tensor...   \n",
       "\n",
       "                                           clone_url      ...        \\\n",
       "0  https://github.com/xiaohu2015/DeepLearning_tut...      ...         \n",
       "5       https://github.com/aakash049/SciKit-Play.git      ...         \n",
       "6  https://github.com/higgsfield/np-hard-deep-rei...      ...         \n",
       "8  https://github.com/sixu05202004/pythontutorial...      ...         \n",
       "9       https://github.com/tensorflow/tensorflow.git      ...         \n",
       "\n",
       "                                     subscribers_url  \\\n",
       "0  https://api.github.com/repos/xiaohu2015/DeepLe...   \n",
       "5  https://api.github.com/repos/aakash049/SciKit-...   \n",
       "6  https://api.github.com/repos/higgsfield/np-har...   \n",
       "8  https://api.github.com/repos/sixu05202004/pyth...   \n",
       "9  https://api.github.com/repos/tensorflow/tensor...   \n",
       "\n",
       "                                    subscription_url  \\\n",
       "0  https://api.github.com/repos/xiaohu2015/DeepLe...   \n",
       "5  https://api.github.com/repos/aakash049/SciKit-...   \n",
       "6  https://api.github.com/repos/higgsfield/np-har...   \n",
       "8  https://api.github.com/repos/sixu05202004/pyth...   \n",
       "9  https://api.github.com/repos/tensorflow/tensor...   \n",
       "\n",
       "                                             svn_url  \\\n",
       "0  https://github.com/xiaohu2015/DeepLearning_tut...   \n",
       "5           https://github.com/aakash049/SciKit-Play   \n",
       "6  https://github.com/higgsfield/np-hard-deep-rei...   \n",
       "8     https://github.com/sixu05202004/pythontutorial   \n",
       "9           https://github.com/tensorflow/tensorflow   \n",
       "\n",
       "                                            tags_url  \\\n",
       "0  https://api.github.com/repos/xiaohu2015/DeepLe...   \n",
       "5  https://api.github.com/repos/aakash049/SciKit-...   \n",
       "6  https://api.github.com/repos/higgsfield/np-har...   \n",
       "8  https://api.github.com/repos/sixu05202004/pyth...   \n",
       "9  https://api.github.com/repos/tensorflow/tensor...   \n",
       "\n",
       "                                           teams_url  \\\n",
       "0  https://api.github.com/repos/xiaohu2015/DeepLe...   \n",
       "5  https://api.github.com/repos/aakash049/SciKit-...   \n",
       "6  https://api.github.com/repos/higgsfield/np-har...   \n",
       "8  https://api.github.com/repos/sixu05202004/pyth...   \n",
       "9  https://api.github.com/repos/tensorflow/tensor...   \n",
       "\n",
       "                                           trees_url            updated_at  \\\n",
       "0  https://api.github.com/repos/xiaohu2015/DeepLe...  2019-03-12T08:56:40Z   \n",
       "5  https://api.github.com/repos/aakash049/SciKit-...  2017-07-31T12:46:13Z   \n",
       "6  https://api.github.com/repos/higgsfield/np-har...  2019-03-12T14:24:51Z   \n",
       "8  https://api.github.com/repos/sixu05202004/pyth...  2019-03-07T07:44:32Z   \n",
       "9  https://api.github.com/repos/tensorflow/tensor...  2019-03-13T00:15:57Z   \n",
       "\n",
       "                                                 url watchers watchers_count  \n",
       "0  https://api.github.com/repos/xiaohu2015/DeepLe...      734            734  \n",
       "5  https://api.github.com/repos/aakash049/SciKit-...        4              4  \n",
       "6  https://api.github.com/repos/higgsfield/np-har...      167            167  \n",
       "8  https://api.github.com/repos/sixu05202004/pyth...      184            184  \n",
       "9  https://api.github.com/repos/tensorflow/tensor...   122588         122588  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_6_merged[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:48:25.050842Z",
     "start_time": "2019-03-27T01:48:24.885897Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'repo_2_merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-07d33c0c33b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrepo_2_merged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'repo_2_merged' is not defined"
     ]
    }
   ],
   "source": [
    "repo_2_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T00:58:54.663686Z",
     "start_time": "2019-03-27T00:58:54.658695Z"
    }
   },
   "outputs": [],
   "source": [
    "repo_2_final = repo_2_merged.values.tolist()\n",
    "repo_3_final = repo_3_merged.values.tolist()\n",
    "repo_6_final = repo_6_merged.values.tolist()\n",
    "repo_8_final = repo_8_merged.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T00:59:03.818151Z",
     "start_time": "2019-03-27T00:59:03.811335Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('repo_2_final.json', 'w') as outfile:\n",
    "    json.dump(repo_2_final, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T00:59:05.100245Z",
     "start_time": "2019-03-27T00:59:05.093382Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('repo_3_final.json', 'w') as outfile:\n",
    "    json.dump(repo_3_final, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T00:59:07.019337Z",
     "start_time": "2019-03-27T00:59:07.010946Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('repo_6_final.json', 'w') as outfile:\n",
    "    json.dump(repo_6_final, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T00:59:10.296513Z",
     "start_time": "2019-03-27T00:59:10.290841Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('repo_8_final.json', 'w') as outfile:\n",
    "    json.dump(repo_8_final, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:11:17.368859Z",
     "start_time": "2019-03-27T02:11:17.294513Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'repo_8_merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-1a177b5d8a83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrepo_8_merged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'repo_8_merged' is not defined"
     ]
    }
   ],
   "source": [
    "repo_8_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:04:02.053927Z",
     "start_time": "2019-03-27T01:04:01.976706Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'topic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'topic'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-551-639040f1460c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrepo_6_merged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'topic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'topic'"
     ]
    }
   ],
   "source": [
    "# repo_6_merged['topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T01:57:51.380996Z",
     "start_time": "2019-03-27T01:57:51.369867Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('all_repos_with_topics.pkl', 'wb') as outfile:\n",
    "    pickle.dump(H, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T02:13:28.730940Z",
     "start_time": "2019-03-27T02:13:28.716653Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-ea98466bb609>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'repo_8_final.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rw'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: load() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "b = json.load('repo_8_final.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
